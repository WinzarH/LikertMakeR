---
title: "LikertMakeR"
subtitle: "synthesise and correlate related rating-scale data"
author: Hume Winzar
date: January 2024    
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{LikertMakeR}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


# LikertMakeR

<p align="center">
  <img src="https://github.com/WinzarH/LikertMakeR/raw/main/vignettes/LikertMakeR_hex.png" width="250" alt="LikertMakeR logo">
</p>

**_LikertMakeR_** synthesises and correlates Likert-scale and related 
rating-scale data. 
You decide the mean and standard deviation, and (optionally) the correlations 
among vectors, and the package will generate data with those same predefined 
properties.  

The package generates a column of values that simulate the same properties 
as a rating scale. 
If multiple columns are generated, then you can use 
**_LikertMakeR_** to rearrange the values so that the new variables are 
correlated exactly in accord with a user-predefined correlation matrix.

## Purpose

The package should be useful for teaching in the Social Sciences, 
and for scholars who wish to "replicate" rating-scale data for further 
analysis and visualisation when only summary statistics have been reported. 

## Motivation

I was prompted to write the functions in _LikertMakeR_ after reviewing too 
many journal article submissions where authors presented questionnaire results 
with only means and standard deviations (often only the means), with no 
apparent understanding of the real distributions. 
Hopefully, this tool will help researchers, teachers, and other reviewers, 
to better think about rating-scale distributions, and the effects of variance, 
boundaries and number of items in a scale.

## Rating scale properties

A Likert scale is the mean, or sum, of several ordinal rating scales. 
Typically, they are bipolar (usually  "agree-disagree") responses to 
propositions that are determined to be moderately-to-highly correlated 
and that capture various facets of a construct.

Rating scales, such as Likert scales, are not continuous or unbounded.

For example, a 5-point Likert scale that is constructed with, say, five items 
(questions) will have a summed range of between 5 (all rated '1') and 25 
(all rated '5') with all integers in between, and the mean range will 
be '1' to '5' with intervals of 1/5=0.20. A 7-point Likert scale constructed 
from eight items will have a summed range between 8 (all rated '1') and 
56 (all rated '7') with all integers in between, and the mean range will 
be '1' to '7' with intervals of 1/8=0.125.

Rating-scale boundaries define minima and maxima for any scale values. 
If the mean is close to one boundary then data points will gather more 
closely to that boundary and the data will always be skewed.

____

# Using _LikertMakeR_

## Download and Install _LikertMakeR_

## from _CRAN_

  > ```
  >
  > # install the package
  > install.packages("LikertMakeR")
  > 
  > # load the package
  > library(LikertMakeR)
  >
  > ```

### development version from _GitHub_.

  > ```
  > 
  > library(devtools)
  > 
  > install_github("WinzarH/LikertMakeR")
  > 
  > # load the package
  > library(LikertMakeR)
  >
  > ```


```{r setup, include = FALSE}

  library(LikertMakeR)
```

## Generate synthetic rating-scale data

To synthesise a rating scale with **_LikertMakeR_**, the user must input 
the following parameters:

-   **_n_**: sample size

-   **_mean_**: desired mean

-   **_sd_**: desired standard deviation

-   **_lowerbound_**: desired lower bound

-   **_upperbound_**: desired upper bound

-   **_items_**: number of items making the scale - default = 1

-   **_seed_**: optional seed for reproducibility

**_LikertMakeR_** offers two different functions for synthesising a 
rating scale: **_lfast()_** and **_lexact()_**

____

### _lfast()_

-   **_lfast()_** draws a random sample from a scaled *Beta* distribution. 
It is very fast but does not guarantee exact mean and standard deviation. 
Recommended for relatively large sample sizes. 

#### _lfast()_ example

##### a four-item, five-point Likert scale

```{r}

x <- lfast(
  n = 512,
  mean = 2.5,
  sd = 0.75,
  lowerbound = 1,
  upperbound = 5,
  items = 4
)
```



```{r fig1, fig.height=3, fig.width=4, fig.align='center', echo = FALSE}

## distribution of x

hist(x,
  cex.axis = 0.5, cex.main = 0.75,
  breaks = seq(from = 1, to = 5, by = 0.25),
  col = "sky blue", xlab = NULL, ylab = NULL,
  main = paste("mu=", round(mean(x), 2), ", sd=", round(sd(x), 2))
)
```

##### an 11-point likelihood-of-purchase scale

```{r}

x <- lfast(256, 3, 2, 0, 10)
```


```{r fig2, fig.height=3, fig.width=4, fig.align='center', echo = FALSE}

hist(x,
  cex.axis = 0.5, cex.main = 0.75,
  breaks = seq(from = 0, to = 10, by = 1.0),
  col = "sky blue", xlab = NULL, ylab = NULL,
  main = paste("mu=", round(mean(x), 2), ", sd=", round(sd(x), 2))
)
```

____

### _lexact()_

**_lexact()_** attempts to produce a vector with exact first and second moments. 

If feasible, **_lexact()_** should produce data with moments that are 
correct to two decimal places. 
Infeasible cases occur when the requested standard deviation is too 
large for the combination of mean, n-items, and scale boundaries.

The optimisation process means that the function is considerably slower than 
**_lfast()_**: taking exponentially more time with the number of items, and 
linearly more time with the sample size.

_lexact()_ uses the *Differential Evolution* algorithm in the 
**_[DEoptim](https://cran.r-project.org/package=DEoptim)_** 
package to find appropriate values within the desired constraints. 
The [DEoptim](https://CRAN.R-project.org/package=DEoptim) package is described 
in Mullen, Ardia, Gil, Windover, & Cline (2011) <doi:10.18637/jss.v040.i06>.

#### _lexact()_ example #1

##### a four-item, five-point Likert scale

```{r}

x <- lexact(
  n = 128,
  mean = 2.5,
  sd = 0.75,
  lowerbound = 1,
  upperbound = 5,
  items = 4
)
```

```{r fig3, fig.height=3, fig.width=4, fig.align='center', echo = FALSE}

hist(x,
  cex.axis = 0.5, cex.main = 0.75,
  breaks = seq(from = 1, to = 5, by = 0.25),
  col = "sky blue", xlab = NULL, ylab = NULL,
  main = paste("mean=", round(mean(x), 2), ", sd=", round(sd(x), 2))
)
```

#### _lexact()_ example #2

##### 11-point likelihood-of-purchase scale

```{r}

x <- lexact(128, 3, 2, 0, 10)
```

```{r fig4,  fig.height=3, fig.width=4, fig.align='center', echo = FALSE}

hist(x,
  cex.axis = 0.5, cex.main = 0.75,
  breaks = c(0:10),
  col = "sky blue",
  xlab = NULL, ylab = NULL,
  main = paste("mu=", round(mean(x), 2), ", sd=", round(sd(x), 2))
)
```

____

## Correlating vectors of synthetic rating scales

**_LikertMakeR_** offers another function, **_lcor()_**, 
which rearranges the values in the columns of a data-set so that 
they are correlated at a specified level. It does not change the 
values - it swaps their positions within each column so that 
univariate statistics do not change, but their correlations with 
other vectors do.

**_lcor()_** systematically selects pairs of values in a column 
and swaps their places, and checks to see if this swap improves 
the correlation matrix. If the revised data-frame produces a 
correlation matrix closer to the target correlation matrix, 
then the swap is retained. 
Otherwise, the values are returned to their original places. 
This process is iterated across each column. 

To create the desired correlated data, the user must define the 
following data-frames:

-   **_data_**: a starter data set of rating-scales

-   **_target_**: the target correlation matrix

### _lcor()_ example

Let's generate some data: three 5-point Likert scales, 
each with five items.

##### generate uncorrelated synthetic data

```{r }
n <- 64
lowerbound <- 1
upperbound <- 5
items <- 5

mydat3 <- data.frame(
  x1 = lexact(n, 2.5, 0.75, lowerbound, upperbound, items),
  x2 = lexact(n, 3.0, 1.50, lowerbound, upperbound, items),
  x3 = lexact(n, 3.5, 1.00, lowerbound, upperbound, items)
)

```

The first 10 observations from this data-frame are:

```{r, echo = FALSE}

head(mydat3, 10)

```

And the first and second moments (to 3 decimal places) are:

```{r, echo = FALSE}

moments <- data.frame(
  mean = apply(mydat3, 2, mean) |> round(3),
  sd = apply(mydat3, 2, sd) |> round(3)
)

t(moments)

```

We can see that the data have first and second moments very close to what is expected. 

The synthetic data have low correlations:

```{r, echo = FALSE}

cor(mydat3) |> round(2)

```

##### a target correlation matrix

```{r}

## describe a target correlation matrix

tgt3 <- matrix(
  c(
    1.00, 0.85, 0.75,
    0.85, 1.00, 0.65,
    0.75, 0.65, 1.00
  ),
  nrow = 3
)
```

So now we have a data-frame with desired first and second moments, 
and a target correlation matrix.

##### applying the *lcor()* function.

```{r}

## apply lcor function

new3 <- lcor(mydat3, tgt3)

```

The first column of the new data-frame will not change, but values of the other 
columns are rearranged. 
The first 10 observations from this data-frame are:

```{r, echo = FALSE}

head(new3, 10)

```

And the new data frame is correlated close to our desired correlation matrix:

```{r, echo = FALSE}

cor(new3) |> round(3)

```

____

# Alternative methods & packages

_LikertMakeR_ is intended for synthesising & correlating 
rating-scale data with means, standard deviations, and 
correlations as close as possible to predefined parameters. 
If you don't need your data to be close to exact, then other 
options may be faster or more flexible. 

Different approaches include:

- sampling from a _truncated normal_ distribution
    
- sampling with a predetermined probability distribution
    
- marginal model specification
   

### sampling from a _truncated normal_ distribution 

Data are sampled from a normal distribution, and then truncated to suit 
the rating-scale boundaries, and rounded to set discrete values as we see 
in rating scales. 

See [Heiz (2021)](https://glaswasser.github.io/simulating-correlated-likert-scale-data/) 
for an excellent and short example using the following packages:

- [truncnorm](https://cran.r-project.org/package=truncnorm)
    
- [faux](https://cran.r-project.org/package=faux) 
 
- See also the _rLikert()_ function from the 
  [responsesR](https://github.com/markolalovic/responsesR) package, 
  [Lalovic (2021)](https://github.com/markolalovic/responsesR), for an 
  approach using optimal discretization and skew-normal distribution.
    
### sampling with a predetermined probability distribution

- the following code will generate a vector of values with approximately 
    the given probabilities. 
    Good for simulating a single item.
   
```{r, eval = FALSE}

     n <- 128
     sample(1:5, n, replace = TRUE,
       prob = c(0.1, 0.2, 0.4, 0.2, 0.1)
     )
```



### marginal model specification 

Marginal model specification extends the idea of a predefined probability 
distribution to multivariate and correlated data-frames.

- [SimCorrMix: Simulation of Correlated Data with Multiple Variable Types Including Continuous and Count Mixture Distributions](https://CRAN.R-project.org/package=SimCorrMix) on CRAN.
    
- [SimMultiCorrData: Simulation of Correlated Data with Multiple Variable Types]( https://CRAN.R-project.org/package=SimMultiCorrData) on CRAN.

- [lsasim: Functions to Facilitate the Simulation of Large Scale Assessment Data](https://CRAN.R-project.org/package=lsasim) on CRAN. 
See [Matta et al. (2018)](https://doi.org/10.1186/s40536-018-0068-8)

- [GenOrd:Simulation of Discrete Random Variables with Given Correlation Matrix and Marginal Distributions](https://CRAN.R-project.org/package=GenOrd) on CRAN.

- [SimCorMultRes: Simulates Correlated Multinomial Responses](https://cran.r-project.org/package=SimCorMultRes) on CRAN. 
See  [Touloumis (2016)](https://journal.r-project.org/archive/2016/RJ-2016-034/index.html)
    
- [covsim: VITA, IG and PLSIM Simulation for Given Covariance and Marginals](https://cran.r-project.org/package=covsim) on CRAN. 
See [Grønneberg et al. (2022)](https://www.jstatsoft.org/article/view/v102i03)

____

# References

Grønneberg, S., Foldnes, N., & Marcoulides, K. M. (2022).
covsim: An R Package for Simulating Non-Normal Data for Structural Equation Models Using Copulas. _Journal of Statistical Software_, 102(1), 1–45. <doi:10.18637/jss.v102.i03>

Heinz, A. (2021), Simulating Correlated Likert-Scale Data In R: 
3 Simple Steps (blog post)
<https://glaswasser.github.io/simulating-correlated-likert-scale-data/>

Lalovic, M. (2021), _responsesR_: Simulate Likert scale item responses 
(on GitHub)
<https://github.com/markolalovic/responsesR>

Matta, T.H., Rutkowski, L., Rutkowski, D. & Liaw, Y.L. (2018), 
lsasim: an R package for simulating large-scale assessment data. 
_Large-scale Assessments in Education_ 6, 15. 
<doi:10.1186/s40536-018-0068-8>

Mullen, K. M., Ardia, D., Gil, D. L., Windover, D., & Cline, J. (2011). 
DEoptim: An R Package for Global Optimization by Differential Evolution.
_Journal of Statistical Software_, 40(6), 1–26.
<doi:10.18637/jss.v040.i06>

Touloumis, A. (2016), Simulating Correlated Binary and Multinomial Responses 
under Marginal Model Specification: The SimCorMultRes Package, 
_The R Journal_ 8:2, 79-91. 
<doi:10.32614/RJ-2016-034>
