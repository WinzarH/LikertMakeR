[{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"sec-likertmaker","dir":"Articles","previous_headings":"","what":"LikertMakeR Validation","title":"LikertMakeR Scale Reproduction Validation","text":"paper reports study compares data produced using LikertMakeR original data published publicly-available source.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"abstract","dir":"Articles","previous_headings":"","what":"Abstract","title":"LikertMakeR Scale Reproduction Validation","text":"LikertMakeR::lfast() function generally produces surprisingly good replications existing data. Data distributions usually unimodal, multimodal (wiggly) data poorly represented. Highly leptokurtic data (pointy wide tails) also may poorly represented. exceptions likely occur one utility function included original sample data. , different groups respondents joined together.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"sec-validation-against-real-data","dir":"Articles","previous_headings":"","what":"Validation against real data","title":"LikertMakeR Scale Reproduction Validation","text":"One objective LikertMakeR package (Winzar 2022) “reproduce” “reverse engineer” rating-scale data analysis visualization summary statistics available. role, synthetic data accurately represent original data, meaning plausibly originate population. validate synthetic data, choose data set readily available, can filtered represent rating-scale data may commonly seen published reports. compare data variations : sample sizes, number items scale length scale item (1 5; 0 10; etc.) modality: extent distribution shows bumps something smooth hill.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"sec-spi","dir":"Articles","previous_headings":"Validation against real data","what":"SPI (SAPA Personality Inventory)","title":"LikertMakeR Scale Reproduction Validation","text":"convenience reproducibility, chose subsample SAPA Personality Inventory (Condon 2023) data available psych (Revelle 2024) psychtools (William Revelle 2024) packages R. data set holds 4000 observations 145 variables.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"variable_selection","dir":"Articles","previous_headings":"Validation against real data > SPI (SAPA Personality Inventory)","what":"Variable/ scale selection","title":"LikertMakeR Scale Reproduction Validation","text":"SPI based hierarchical framework assessing personality two levels. higher level familiar “Big Five” factors studied personality research since 1980s. SPI, five dimensions represented average fourteen 6-point agree-disagree items. , scale values scale 14 * 6 = 84 possible values.  lower level 27 factors, made averaging five 6-point items, sub-scales Big Five. give scales 5 * 6 = 30 possible values. List SPI Facets Finally, dimensions facets made averaging subsets 135 items (individual questions). item scale 1 * 6 = 6 possible values. Scale properties consideration","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"sec-measures-of-difference","dir":"Articles","previous_headings":"Validation against real data","what":"Measures of Difference","title":"LikertMakeR Scale Reproduction Validation","text":"function LikertMakeR::lfast() produces vector values predefined first second moments usually correct two decimal places. Vectors also exact minima & maxima, scale intervals. determine whether synthetic data different data produced original summary statistics, need something just equal mean standard deviation. need measures can accommodate third fourth moments (skewness kurtosis) well. , comparison accommodate occasional bimodal distributions may occur.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"sec-choice_of_test","dir":"Articles","previous_headings":"Validation against real data > Measures of Difference","what":"Choice of Test for Equal Distributions","title":"LikertMakeR Scale Reproduction Validation","text":"assess similarity synthetic data generated LikertMakeR real survey data, evaluate agreement empirical distributions using nonparametric two-sample tests. Several tests available comparing continuous distributions: Kolmogorov–Smirnov (KS) test focuses maximum vertical distance empirical cumulative distribution functions (ECDFs) two samples. KS test reduced sensitivity near centre distribution excessive sensitivity extreme values (Lilliefors 1967). Baumgartner–Weiß–Schindler (BWS) test (Baumgartner, Weiß, Schindler 1998) improves upon KS test incorporating differences across entire distribution, using rank-based test statistic derived integrated spacing differences. BWS test powerful either Kolmogorov-Smirnov test Wilcoxon test (Pav 2023), shown Baumgartner, Weiß, Schindler (1998). sensitive location shape differences generally greater power across variety alternatives (Neuhäuser 2001; Neuhäuser Ruxton 2009). Neuhäuser modification BWS test introduces weighting function emphasizes differences central region distribution reducing influence tails (Neuhäuser 2001). makes robust small discrepancies extremes — desirable property large samples minor tail mismatches can lead false positives (Neuhäuser 2005). Overall, researcher might want use BWS test see LikertMakeR::lfast() gives exact replication scale, use Neuhäuser test option see function produces “pretty good” dataframe. , present summary results tests study. Comparison BWS Neuhäuser Methods","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"research_design","dir":"Articles","previous_headings":"","what":"Research Design","title":"LikertMakeR Scale Reproduction Validation","text":"suspect accuracy data created LikertMakeR::lfast() affected : shape true distribution sample-size number discrete intervals scale , highly skewed multimodal distributions, smaller sample sizes, likely less well replicated synthetic data generated LikertMakeR::lfast().","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"sec-data_selection","dir":"Articles","previous_headings":"Research Design","what":"Data selection","title":"LikertMakeR Scale Reproduction Validation","text":"SPI dataset includes demographic information can filter 4000 observations sample-sizes likely find normal social research. Somewhat arbitrarily, decided use Age, Gender, Education filters.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"small_sample","dir":"Articles","previous_headings":"Research Design > Data selection","what":"Small sample","title":"LikertMakeR Scale Reproduction Validation","text":"Young highly-educated men filtering produced sample 19 observations.","code":"young_highly_educated_men <- spi |>   filter(age < 24 & sex == 1 & education == 7)  ## where, sex==1 = 'male' ##        education == 7 = 'postgraduate degree'"},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"medium_sample","dir":"Articles","previous_headings":"Research Design > Data selection","what":"Medium sample","title":"LikertMakeR Scale Reproduction Validation","text":"Young educated women filtering produced sample 99 observations.","code":"young_educated_women <- spi |>   filter(age < 24 & sex == 2 & education >= 5)  ## where, \"sex==2\" = 'female' ##        \"education >= 5\" = 'undergraduate degree or higher'"},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"large_sample","dir":"Articles","previous_headings":"Research Design > Data selection","what":"Large sample","title":"LikertMakeR Scale Reproduction Validation","text":"Young school-leavers filtering produced sample 314 observations.","code":"under_18_highschool <- spi |>   filter(age < 18 & education == 1)  ## where, \"education == 1\" = 'Less than 12 years schooling'"},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"procedure","dir":"Articles","previous_headings":"Research Design","what":"Procedure","title":"LikertMakeR Scale Reproduction Validation","text":"three samples small, medium large sample-sizes. small, 19 observations medium, 99 observations large, 314 observations three levels data aggregation: 5 dimensions, 14 items 27 factors, 5 items 135 individual items gives us (3 * (5 + 27 + 135) = 501) data subsets. combination sample data-level find mean standard deviation data subset, apply LikertMakeR::lfast function produce 2^10 = 1024 simulated dataframes compare true original dataframes SPI data. compare Empirical Cumulative Density Function (ECDF) simulated dataframe ECDF original dataframe using BWS Neuhäuser methods. 1000 tests 501 original dataframes able see accurate simulations .","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"original-data","dir":"Articles","previous_headings":"Research Design","what":"Original Data","title":"LikertMakeR Scale Reproduction Validation","text":"present charts summary information three levels data consideration. bar-charts measurement level combined kernel density estimates.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"spi-big-five-dimensions","dir":"Articles","previous_headings":"Research Design > Original Data","what":"SPI Big Five Dimensions","title":"LikertMakeR Scale Reproduction Validation","text":"Big Five measures average 14 six-point items. 14 * 6 = 84 potential values scale. Note , small sample size much sparse values larger sample. Otherwise, distributions tend unimodal, fairly smooth kernel density curves. Big 5 Dimensions three samples","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"spi-27-facets","dir":"Articles","previous_headings":"Research Design > Original Data","what":"SPI 27 Facets","title":"LikertMakeR Scale Reproduction Validation","text":"SPI facets average five six-point items, giving 5 * 6 = 30 potential values facet measure. , distributions tend unimodal, smooth kernel density curves. SPI facets three samples","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"selected-spi-items","dir":"Articles","previous_headings":"Research Design > Original Data","what":"Selected SPI items","title":"LikertMakeR Scale Reproduction Validation","text":"simulated data 135 individual items - many show meaningfully. present sample showed unusual results simulations. cases data either highly skewed, bimodal (least flat parts). Selected SPI items three samples","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"results","dir":"Articles","previous_headings":"","what":"Results","title":"LikertMakeR Scale Reproduction Validation","text":"following tables list dimension consideration proportion cases three samples ere ‘statistically significant’ (ρ\\rho < 0.05). Tables show BWS test / Neuhäuser test.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"big-five-dimensions-validity","dir":"Articles","previous_headings":"Results","what":"Big Five Dimensions validity","title":"LikertMakeR Scale Reproduction Validation","text":"Fourteen six-point items (84 levels scale) Proportion statistically-significant simulations (BWS/Neuhäuser) smooth kernel density estimates, saw , cases non-significant, suggesting data well-reproduced LikertMakeR::lfast() function.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"spi-facets-subscale-validity","dir":"Articles","previous_headings":"Results","what":"SPI Facets (Subscale) validity","title":"LikertMakeR Scale Reproduction Validation","text":"Five six-point items (30 potential values scale) Proportion statistically-significant simulations (BWS/Neuhäuser) BWS test applied larger sample, simulations significantly different original data. probably due smaller standard error produced larger sample. Interestingly, Neuhäuser test, less sensitive outliers, suggested simulations good representations original. facet, Introspection, stands one rarely accurately reproduced LikertMakeR::lfast() function, using BWS test, regardless sample size. facets worth exploring detail : Compassion, Humor, Intellect, SelfControl, EasyGoingness, Perfectionism. facets high rates significance mid-sample-size condition.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"focus-on-introspection-facet","dir":"Articles","previous_headings":"Results > SPI Facets (Subscale) validity","what":"Focus on “Introspection” facet","title":"LikertMakeR Scale Reproduction Validation","text":"following chart shows kernel density plots facet Introspection three samples. 1024 synthetic dataframes represented grey/black line, original “true” dataframe represented blue/cyan line. Introspection facet: Density plot small, medium large samples see synthetic data never match true data, especially middle large sample sizes. original, true, data highly left-skewed, nicely captured synthetic data. Note, however, true dataframe unimodal. kernel density estimate appears rough slightly multimodal. ’s wobbly.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"focus-on-compassion-facet","dir":"Articles","previous_headings":"Results > SPI Facets (Subscale) validity","what":"focus on “Compassion” facet","title":"LikertMakeR Scale Reproduction Validation","text":"following chart shows kernel density plots facet Compassion three samples. , 1024 synthetic dataframes represented grey/black line, original “true” dataframe represented blue/cyan line. Compassion facet: Kernel Density plots small, medium large samples factor BWS test showed cases synthetic data significantly different original data smaller sample. medium large samples, original data unimodal, BWS test suggests synthetic replications different original.","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"humor","dir":"Articles","previous_headings":"","what":"LikertMakeR Scale Reproduction Validation","title":"LikertMakeR Scale Reproduction Validation","text":"Humor facet: Kernel Density plots small, medium large samples","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"intellect","dir":"Articles","previous_headings":"","what":"LikertMakeR Scale Reproduction Validation","title":"LikertMakeR Scale Reproduction Validation","text":"Intellect facet: Kernel Density plots small, medium large samples","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"selfcontrol","dir":"Articles","previous_headings":"","what":"LikertMakeR Scale Reproduction Validation","title":"LikertMakeR Scale Reproduction Validation","text":"SelfControl facet: Kernel Density plots small, medium large samples","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"easygoingness","dir":"Articles","previous_headings":"","what":"LikertMakeR Scale Reproduction Validation","title":"LikertMakeR Scale Reproduction Validation","text":"EasyGoingness facet: Kernel Density plots small, medium large samples","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"perfectionism","dir":"Articles","previous_headings":"","what":"LikertMakeR Scale Reproduction Validation","title":"LikertMakeR Scale Reproduction Validation","text":"Perfectionism facet: Kernel Density plots small, medium large samples","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"spi-item-validity","dir":"Articles","previous_headings":"Results","what":"SPI Item validity","title":"LikertMakeR Scale Reproduction Validation","text":"scale single six-point item. almost cases, Baumgartner–Weiß–Schindler (BWS) test showed statistically significant difference actual data synthetic data. cases, however, Neuhäuser test, robust outliers, statistically significant. appendix table shows summary results three data sets 135 items, indicating proportion cases distribution comparison tests ‘statistically significant’ (ρ\\rho < 0.05). 37 135 items (27%) BWS test show proportion significant simulations less 80%. following sample item results three samples","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"original-data-histograms","dir":"Articles","previous_headings":"Results","what":"Original data histograms","title":"LikertMakeR Scale Reproduction Validation","text":"Selected items Selected items Selected items","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"q_1685-seldom-joke-around","dir":"Articles","previous_headings":"Results > Synthetic data density plots","what":"q_1685 ‘Seldom joke around’","title":"LikertMakeR Scale Reproduction Validation","text":"q_1685 ‘Seldom joke around’: Kernel Density plots small, medium large samples","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"q_1896-use-others-for-my-own-ends","dir":"Articles","previous_headings":"Results > Synthetic data density plots","what":"q_1896 ‘Use others for my own ends’","title":"LikertMakeR Scale Reproduction Validation","text":"q_1058 ‘Use others ends’: Kernel Density plots small, medium large samples","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"q_1989-worry-about-things","dir":"Articles","previous_headings":"Results > Synthetic data density plots","what":"q_1989 ‘Worry about things’","title":"LikertMakeR Scale Reproduction Validation","text":"q_1989 ‘Worry things’: Kernel Density plots small, medium large samples","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"q_755-enjoy-examining-myself-and-my-life","dir":"Articles","previous_headings":"Results > Synthetic data density plots","what":"q_755 ‘Enjoy examining myself and my life’","title":"LikertMakeR Scale Reproduction Validation","text":"q_755 ‘Enjoy examining life’: Kernel Density plots small, medium large samples","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"summary_results","dir":"Articles","previous_headings":"","what":"Summary Results","title":"LikertMakeR Scale Reproduction Validation","text":"Results much might expect:","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"unimodal-data-are-good-multimodal-less-so","dir":"Articles","previous_headings":"Summary Results","what":"Unimodal data are good, multimodal less so","title":"LikertMakeR Scale Reproduction Validation","text":"Multimodal data well-represented LikertMakeR::lfast() function, consistently generates unimodal data.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"larger-sample-sizes-produce-smoother-unimodal-data-distributions","dir":"Articles","previous_headings":"Summary Results","what":"Larger sample sizes produce smoother unimodal data distributions","title":"LikertMakeR Scale Reproduction Validation","text":"Original data small sample size 19-subjects group frequently multimodal, whereas original data medium-sized large-sized groups often unimodal.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"sample-size-alone-does-not-affect-accuracy-of-data-synthisis-","dir":"Articles","previous_headings":"Summary Results","what":"Sample size alone does not affect accuracy of data synthisis.","title":"LikertMakeR Scale Reproduction Validation","text":"seem much difference results different sample sizes.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"third-and-fourth-moments-can-affect-accurcy","dir":"Articles","previous_headings":"Summary Results","what":"Third and Fourth moments can affect accurcy","title":"LikertMakeR Scale Reproduction Validation","text":"Leptokurtic (pointy) distributions platykurtic (flatter) distributions seem affect results. shouldn’t surprised since generating algorithm focuses first (mean) second (standard deviation) moments.","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/articles/lfast_validation.html","id":"summary-results-for-individual-items","dir":"Articles","previous_headings":"Appendix","what":"Summary results for individual items","title":"LikertMakeR Scale Reproduction Validation","text":"Rating scale items ranging ‘1’ ‘6’ SPI data set, three samples different sizes. Proportion statistically-significant simulations (BWS/Neuhauser)","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"purpose","dir":"Articles","previous_headings":"","what":"Purpose","title":"LikertMakeR vignette","text":"package useful teaching Social Sciences, scholars wish “replicate” “reverse engineer” rating-scale data analysis visualisation summary statistics reported.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"motivation","dir":"Articles","previous_headings":"","what":"Motivation","title":"LikertMakeR vignette","text":"prompted write core functions LikertMakeR reviewing many journal article submissions authors presented questionnaire results means standard deviations (often means), apparent understanding scale distributions, impact scale properties. Hopefully, tool help researchers, teachers & students, reviewers, better think rating-scale distributions, effects variance, scale boundaries, number items scale. Researchers can also use LikertMakeR create dummy data prepare analyses ahead formal survey.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"rating-scale-properties","dir":"Articles","previous_headings":"","what":"Rating scale properties","title":"LikertMakeR vignette","text":"Likert scale mean, sum, several ordinal rating scales. Typically, bipolar (usually “agree-disagree”) responses propositions determined moderately--highly correlated capture facet theoretical construct. Rating scales, Likert scales, continuous unbounded. example, 5-point Likert scale constructed , say, five items (questions) summed range 5 (rated ‘1’) 25 (rated ‘5’) integers , mean range ‘1’ ‘5’ intervals 1/5=0.20. 7-point Likert scale constructed eight items summed range 8 (rated ‘1’) 56 (rated ‘7’) integers , mean range ‘1’ ‘7’ intervals 1/8=0.125. Technically, bounded continuous, parametric statistics, mean, standard deviation, correlation, applied summated rating scales. practice, however, parametric statistics commonly used social sciences : common usage easily understood, results conclusions drawn technically-correct non-parametric statistics (almost) always parametric statistics data.  example, D’Alessandro et al. (2020) argue summated scale, made multiple items, “approaches” interval scale measure, implying parametric statistics quite acceptable. Rating-scale boundaries define minima maxima scale values. mean close one boundary data points gather closely boundary.  mean middle scale, data always skewed, shown following plots. -centre means always give skewed distribution bounded rating scales","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"likertmaker-functions","dir":"Articles","previous_headings":"","what":"LikertMakeR functions","title":"LikertMakeR vignette","text":"lfast() generate vector values predefined mean standard deviation. lcor() takes dataframe rating-scale values rearranges values column columns correlated match predefined correlation matrix. makeCorrAlpha constructs random correlation matrix given dimensions predefined Cronbach’s Alpha. makeCorrLoadings constructs random correlation matrix given factor loadings matrix, factor-correlations matrix.  makeScales() wrapper function lfast() lcor() generate items summated scales predefined first second moments predefined correlation matrix. function replaces makeItems() now includes multi-item measures. makeItemsScale() generates random dataframe scale items based predefined summated scale desired Cronbach’s Alpha. makePaired() generates dataframe two correlated columns based summary data paired-sample t-test. makeRepeated() generates dataframe ‘k’ correlated columns based summary data repeated-samples ANOVA. makeScalesRegression() generates dataframe based results output multiple-regression - R2, standardised betas, IV correlations (available). correlateScales() creates dataframe correlated summated scales one might find completed survey questionnaire possibly used Structural Equation model. Helper Functions alpha() calculates Cronbach’s Alpha given correlation matrix given dataframe. eigenvalues() calculates eigenvalues correlation matrix, reports positive-definite status matrix , optionally, displays scree plot visualise eigenvalues.","code":""},{"path":[]},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"from-cran","dir":"Articles","previous_headings":"Using LikertMakeR > Download and Install LikertMakeR","what":"from CRAN","title":"LikertMakeR vignette","text":"","code":"> ``` > > install.packages(\"LikertMakeR\") > library(LikertMakeR) > > ```"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"development-version-from-github-","dir":"Articles","previous_headings":"Using LikertMakeR > Download and Install LikertMakeR","what":"development version from GitHub.","title":"LikertMakeR vignette","text":"","code":"> ``` >  > library(devtools) > install_github(\"WinzarH/LikertMakeR\") > library(LikertMakeR) > > ```"},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"lfast","dir":"Articles","previous_headings":"Using LikertMakeR > Generate synthetic rating-scale data","what":"lfast()","title":"LikertMakeR vignette","text":"lfast() applies simple evolutionary algorithm draws repeated random samples scaled Beta distribution. produces vector values mean standard deviation typically correct two decimal places. synthesise rating scale lfast(), user must input following parameters: n: sample size mean: desired mean sd: desired standard deviation lowerbound: desired lower bound upperbound: desired upper bound items: number items making scale - default = 1 earlier version LikertMakeR function, lexact(), slow accurate latest version lfast(). , lexact() now deprecated.","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"a-four-item-five-point-likert-scale","dir":"Articles","previous_headings":"","what":"LikertMakeR vignette","title":"LikertMakeR vignette","text":"Example: 4-item, 1-5 Likert scale","code":"nItems <- 4 mean <- 2.5 sd <- 0.75  x1 <- lfast(   n = 512,   mean = mean,   sd = sd,   lowerbound = 1,   upperbound = 5,   items = nItems ) #> best solution in 256 iterations"},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"lfast-1","dir":"Articles","previous_headings":"","what":"LikertMakeR vignette","title":"LikertMakeR vignette","text":"Example: likelihood--purchase scale","code":"x2 <- lfast(256, 3, 2.5, 0, 10) #> best solution in 7723 iterations"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"correlating-rating-scales","dir":"Articles","previous_headings":"Using LikertMakeR","what":"Correlating rating scales","title":"LikertMakeR vignette","text":"function, lcor(), rearranges values columns data-set correlated specified level. change values - swaps positions within column univariate statistics change, correlations vectors .","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"lcor","dir":"Articles","previous_headings":"Using LikertMakeR > Correlating rating scales","what":"lcor()","title":"LikertMakeR vignette","text":"lcor() systematically selects pairs values column swaps places, checks see swap improves correlation matrix. revised dataframe produces correlation matrix closer target correlation matrix, swap retained. Otherwise, values returned original places. process iterated across column. create desired correlated data, user must define following parameters: data: starter data set rating-scales. Number columns must match dimensions target correlation matrix. target: target correlation matrix.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"lcor-example","dir":"Articles","previous_headings":"Using LikertMakeR > Correlating rating scales","what":"lcor() example","title":"LikertMakeR vignette","text":"Let’s generate data: three 5-point Likert scales, five items. first six observations dataframe : first second moments (3 decimal places) : can see data first second moments close expected. expect, randomly-generated synthetic data low correlations: Now, let’s define target correlation matrix: now dataframe desired first second moments, target correlation matrix. Values column new dataframe change original; values rearranged. first ten observations dataframe : new dataframe correlated close desired correlation matrix; presented 3 decimal places:","code":"## generate uncorrelated synthetic data n <- 128 lowerbound <- 1 upperbound <- 5 items <- 5  mydat3 <- data.frame(   x1 = lfast(n, 2.5, 0.75, lowerbound, upperbound, items),   x2 = lfast(n, 3.0, 1.50, lowerbound, upperbound, items),   x3 = lfast(n, 3.5, 1.00, lowerbound, upperbound, items) ) #> best solution in 812 iterations #> best solution in 7553 iterations #> best solution in 385 iterations #>    x1  x2  x3 #> 1 1.4 1.0 5.0 #> 2 2.8 5.0 4.2 #> 3 3.4 1.8 2.0 #> 4 2.0 4.8 4.4 #> 5 3.6 1.0 3.4 #> 6 2.2 2.8 4.0 #>         x1    x2    x3 #> mean 2.500 3.002 3.498 #> sd   0.752 1.501 1.001 #>       x1    x2   x3 #> x1  1.00 -0.02 0.03 #> x2 -0.02  1.00 0.00 #> x3  0.03  0.00 1.00 ## describe a target correlation matrix tgt3 <- matrix(   c(     1.00, 0.85, 0.75,     0.85, 1.00, 0.65,     0.75, 0.65, 1.00   ),   nrow = 3 ) ## apply lcor() function new3 <- lcor(data = mydat3, target = tgt3) #>     X1  X2  X3 #> 1  2.8 3.8 2.6 #> 2  3.6 5.0 4.8 #> 3  3.4 4.2 4.6 #> 4  3.8 5.0 4.4 #> 5  1.8 1.2 2.4 #> 6  3.8 5.0 4.8 #> 7  2.0 2.8 3.2 #> 8  2.0 3.4 3.2 #> 9  2.4 2.8 4.4 #> 10 1.8 1.0 3.8 #>      X1   X2   X3 #> X1 1.00 0.85 0.75 #> X2 0.85 1.00 0.65 #> X3 0.75 0.65 1.00"},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"makecorralpha","dir":"Articles","previous_headings":"Using LikertMakeR > Generate a correlation matrix from Cronbach’s Alpha","what":"makeCorrAlpha()","title":"LikertMakeR vignette","text":"makeCorrAlpha(), constructs random correlation matrix given dimensions predefined Cronbach’s Alpha. create desired correlation matrix, user must define following parameters: items: “k” - number rows columns desired correlation matrix. alpha: target value Cronbach’s Alpha variance: notional variance coefficient affect spread values correlation matrix. Default = ‘0.5’. value ‘0’ produces matrix -diagonal correlations equal. Setting ‘variance = 1.0’ gives wider range values. Setting ‘variance = 2.0’, , may feasible increases likelihood non-positive-definite matrix.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"makecorralpha-is-volatile","dir":"Articles","previous_headings":"Using LikertMakeR > Generate a correlation matrix from Cronbach’s Alpha","what":"makeCorrAlpha() is volatile","title":"LikertMakeR vignette","text":"Random values generated makeCorrAlpha() highly volatile. makeCorrAlpha() may generate feasible (positive-definite) correlation matrix, especially variance high relative desired Alpha, desired correlation dimensions makeCorrAlpha() inform user resulting correlation matrix positive definite, . returned correlation matrix positive-definite, feasible solution may still possible, often . user encouraged try , possibly several times, find one.","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"four-variables-alpha-0-85-variance-default","dir":"Articles","previous_headings":"","what":"LikertMakeR vignette","title":"LikertMakeR vignette","text":"makeCorrAlpha() produced following correlation matrix (three decimal places):","code":"## define parameters items <- 4 alpha <- 0.85 # variance <- 0.5 ## by default  ## apply makeCorrAlpha() function set.seed(42)  cor_matrix_4 <- makeCorrAlpha(items, alpha) #> correlation values consistent with desired alpha in 59 iterations #> The correlation matrix is positive definite #>       [,1]  [,2]  [,3]  [,4] #> [1,] 1.000 0.425 0.433 0.507 #> [2,] 0.425 1.000 0.693 0.694 #> [3,] 0.433 0.693 1.000 0.766 #> [4,] 0.507 0.694 0.766 1.000"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"test-output-with-helper-functions","dir":"Articles","previous_headings":"","what":"LikertMakeR vignette","title":"LikertMakeR vignette","text":"","code":"## using helper function alpha()  alpha(cor_matrix_4) #> [1] 0.8500063 ## using helper function eigenvalues()  eigenvalues(cor_matrix_4, 1) #> cor_matrix_4  is positive-definite #> [1] 2.7842025 0.6581071 0.3291732 0.2285172"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"twelve-variables-alpha-0-90-variance-1","dir":"Articles","previous_headings":"Using LikertMakeR > Generate a correlation matrix from Cronbach’s Alpha > makeCorrAlpha() is volatile","what":"twelve variables, alpha = 0.90, variance = 1","title":"LikertMakeR vignette","text":"","code":"## define parameters items <- 12 alpha <- 0.90 variance <- 1.0  ## apply makeCorrAlpha() function set.seed(42)  cor_matrix_12 <- makeCorrAlpha(items = items, alpha = alpha, variance = variance) #> correlation values consistent with desired alpha in 4312 iterations #> Correlation matrix is not yet positive definite #>          #> Working on it #>  #> improved at swap - 12 #> improved at swap - 67 #> improved at swap - 79 #> improved at swap - 80 #> improved at swap - 115 #> improved at swap - 121 #> improved at swap - 128 #> improved at swap - 130 #> improved at swap - 134 #> improved at swap - 137 #> improved at swap - 146 #> improved at swap - 151 #> improved at swap - 160 #> improved at swap - 162 #> improved at swap - 166 #> improved at swap - 174 #> improved at swap - 183 #> improved at swap - 188 #> improved at swap - 191 #> improved at swap - 208 #> improved at swap - 263 #> improved at swap - 304 #> improved at swap - 399 #> improved at swap - 400 #> improved at swap - 402 #> improved at swap - 445 #> improved at swap - 485 #> improved at swap - 542 #> stopped at swap - 542 #> The correlation matrix is positive definite"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"section","dir":"Articles","previous_headings":"","what":"LikertMakeR vignette","title":"LikertMakeR vignette","text":"makeCorrAlpha() produced following correlation matrix (two decimal places):","code":"#>        [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10] [,11] [,12] #>  [1,]  1.00 -0.51 -0.67 -0.32 -0.30 -0.29 -0.27 -0.14 -0.07 -0.04 -0.03  0.00 #>  [2,] -0.51  1.00  0.06  0.31  0.43  0.26  0.28  0.20  0.26  0.06  0.25  0.34 #>  [3,] -0.67  0.06  1.00  0.61  0.36  0.62  0.57  0.47  0.45  0.46  0.47  0.33 #>  [4,] -0.32  0.31  0.61  1.00  0.48  0.50  0.60  0.36  0.39  0.53  0.64  0.59 #>  [5,] -0.30  0.43  0.36  0.48  1.00  0.42  0.56  0.62  0.62  0.62  0.56  0.63 #>  [6,] -0.29  0.26  0.62  0.50  0.42  1.00  0.81  0.66  0.70  0.70  0.70  0.70 #>  [7,] -0.27  0.28  0.57  0.60  0.56  0.81  1.00  0.57  0.71  0.72  0.72  0.73 #>  [8,] -0.14  0.20  0.47  0.36  0.62  0.66  0.57  1.00  0.71  0.79  0.79  0.78 #>  [9,] -0.07  0.26  0.45  0.39  0.62  0.70  0.71  0.71  1.00  0.80  0.83  0.84 #> [10,] -0.04  0.06  0.46  0.53  0.62  0.70  0.72  0.79  0.80  1.00  0.88  0.89 #> [11,] -0.03  0.25  0.47  0.64  0.56  0.70  0.72  0.79  0.83  0.88  1.00  0.97 #> [12,]  0.00  0.34  0.33  0.59  0.63  0.70  0.73  0.78  0.84  0.89  0.97  1.00"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"test-output","dir":"Articles","previous_headings":"","what":"LikertMakeR vignette","title":"LikertMakeR vignette","text":"","code":"## calculate Cronbach's Alpha alpha(cor_matrix_12) #> [1] 0.9000045  ## calculate eigenvalues of the correlation matrix eigenvalues(cor_matrix_12, 1) |> round(3) #> cor_matrix_12  is positive-definite #>  [1] 6.964 1.743 1.087 0.658 0.567 0.377 0.254 0.159 0.127 0.051 0.014 0.001"},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"makecorrloadings","dir":"Articles","previous_headings":"Using LikertMakeR > Generate a correlation matrix from factor loadings","what":"makeCorrLoadings","title":"LikertMakeR vignette","text":"makeCorrLoadings() generates correlation matrix factor loadings factor correlations might seen Exploratory Factor Analysis (EFA) Structural Equation Model (SEM).","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"makecorrloadings-usage","dir":"Articles","previous_headings":"Using LikertMakeR > Generate a correlation matrix from factor loadings > makeCorrLoadings","what":"makeCorrLoadings() usage","title":"LikertMakeR vignette","text":"","code":"makeCorrLoadings(loadings, factorCor = NULL, uniquenesses = NULL, nearPD = FALSE)"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"makecorrloadings-arguments","dir":"Articles","previous_headings":"","what":"LikertMakeR vignette","title":"LikertMakeR vignette","text":"loadings: ‘k’ (items) ‘f’ (factors) matrix standardised factor loadings. Item names Factor names can taken row_names (items) column_names (factors), present. factorCor: ‘f’ x ‘f’ factor correlation matrix. present, assume factors uncorrelated (orthogonal), rare practice, function applies identity matrix factor_cor. uniquenesses: length ‘k’ vector uniquenesses. NULL, default, compute calculated communalities. nearPD: (logical) TRUE, function calls nearPD function Matrix package transform resulting correlation matrix onto nearest Positive Definite matrix. Obviously, applies resulting correlation matrix positive definite. (never needed.)","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"note","dir":"Articles","previous_headings":"","what":"LikertMakeR vignette","title":"LikertMakeR vignette","text":"“Censored” loadings (example, loadings less small value (often ‘0.30’), removed ease--communication) tend severely reduce accuracy makeCorrLoadings() function. detailed demonstration, see vignette file, makeCorrLoadings_Validate.","code":""},{"path":[]},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"define-parameters","dir":"Articles","previous_headings":"","what":"LikertMakeR vignette","title":"LikertMakeR vignette","text":"","code":"## Example loadings  factorLoadings <- matrix(   c(     0.05, 0.20, 0.70,     0.10, 0.05, 0.80,     0.05, 0.15, 0.85,     0.20, 0.85, 0.15,     0.05, 0.85, 0.10,     0.10, 0.90, 0.05,     0.90, 0.15, 0.05,     0.80, 0.10, 0.10   ),   nrow = 8, ncol = 3, byrow = TRUE )  ## row and column names  rownames(factorLoadings) <- c(\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\", \"Q6\", \"Q7\", \"Q8\") colnames(factorLoadings) <- c(\"Factor1\", \"Factor2\", \"Factor3\")  ## Factor correlation matrix**  factorCor <- matrix(   c(     1.0,  0.5, 0.4,     0.5,  1.0, 0.3,     0.4,  0.3, 1.0   ),   nrow = 3, byrow = TRUE )"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"apply-the-function","dir":"Articles","previous_headings":"","what":"LikertMakeR vignette","title":"LikertMakeR vignette","text":"","code":"## apply makeCorrLoadings() function itemCorrelations <- makeCorrLoadings(factorLoadings, factorCor)  ## derived correlation matrix to two decimal places round(itemCorrelations, 2) #>      Q1   Q2   Q3   Q4   Q5   Q6   Q7   Q8 #> Q1 1.00 0.62 0.67 0.48 0.42 0.42 0.43 0.41 #> Q2 0.62 1.00 0.72 0.43 0.36 0.36 0.44 0.42 #> Q3 0.67 0.72 1.00 0.50 0.43 0.43 0.46 0.45 #> Q4 0.48 0.43 0.50 1.00 0.79 0.83 0.65 0.58 #> Q5 0.42 0.36 0.43 0.79 1.00 0.80 0.54 0.48 #> Q6 0.42 0.36 0.43 0.83 0.80 1.00 0.59 0.52 #> Q7 0.43 0.44 0.46 0.65 0.54 0.59 1.00 0.78 #> Q8 0.41 0.42 0.45 0.58 0.48 0.52 0.78 1.00"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"test-makecorrloadings-output","dir":"Articles","previous_headings":"","what":"LikertMakeR vignette","title":"LikertMakeR vignette","text":"","code":"## correlated factors mean that eigenvalues should suggest two or three factors eigenvalues(cormatrix = itemCorrelations, scree = TRUE) #> itemCorrelations  is positive-definite #> [1] 4.7679427 1.2254239 0.7641967 0.3799863 0.2668158 0.2237851 0.2073574 #> [8] 0.1644922"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"assuming-orthogonal-factors","dir":"Articles","previous_headings":"","what":"LikertMakeR vignette","title":"LikertMakeR vignette","text":"","code":"## orthogonal factors are assumed when factor correlation matrix is not included orthogonalItemCors <- makeCorrLoadings(factorLoadings)  ## derived correlation matrix to two decimal places round(orthogonalItemCors, 2) #>      Q1   Q2   Q3   Q4   Q5   Q6   Q7   Q8 #> Q1 1.00 0.58 0.63 0.29 0.24 0.22 0.11 0.13 #> Q2 0.58 1.00 0.69 0.18 0.13 0.10 0.14 0.17 #> Q3 0.63 0.69 1.00 0.26 0.22 0.18 0.11 0.14 #> Q4 0.29 0.18 0.26 1.00 0.75 0.79 0.32 0.26 #> Q5 0.24 0.13 0.22 0.75 1.00 0.78 0.18 0.14 #> Q6 0.22 0.10 0.18 0.79 0.78 1.00 0.23 0.18 #> Q7 0.11 0.14 0.11 0.32 0.18 0.23 1.00 0.74 #> Q8 0.13 0.17 0.14 0.26 0.14 0.18 0.74 1.00"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"test-orthogonal-output","dir":"Articles","previous_headings":"","what":"LikertMakeR vignette","title":"LikertMakeR vignette","text":"","code":"## eigenvalues should suggest exactly  three factors eigenvalues(cormatrix = orthogonalItemCors, scree = TRUE) #> orthogonalItemCors  is positive-definite #> [1] 3.2769426 1.8091128 1.4966064 0.4244753 0.2966222 0.2605233 0.2402622 #> [8] 0.1954553"},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"makescales","dir":"Articles","previous_headings":"Using LikertMakeR > Generate a dataframe of rating scales from a correlation matrix and predefined moments","what":"makeScales()","title":"LikertMakeR vignette","text":"makeScales() generates dataframe random discrete values data replicate set scale items summated rating scales, correlated close predefined correlation matrix. Generally, means, standard deviations, correlations correct two decimal places. makeScales() wrapper function lfast(), takes repeated samples selecting vector best fits desired moments, lcor(), rearranges values column dataframe closely match desired correlation matrix. create desired dataframe, user must define following parameters: n: number observations dfMeans: vector length ‘k’ desired means variable dfSds: vector length ‘k’ desired standard deviations variable lowerbound: vector length ‘k’ values lower bound variable. default = ‘1’ upperbound: vector length ‘k’ values upper bound variable. Default = ‘5’ items: vector length ‘k’ number items variable. Default = ‘1’. cormatrix: target correlation matrix ‘k’ rows ‘k’ columns.","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"four-correlated-items","dir":"Articles","previous_headings":"Using LikertMakeR > Generate a dataframe of rating scales from a correlation matrix and predefined moments > makeScales() examples","what":"four correlated items","title":"LikertMakeR vignette","text":"","code":"## define parameters n <- 128 dfMeans <- c(2.5, 3.0, 3.0, 3.5) dfSds <- c(1.0, 1.0, 1.5, 0.75) lowerbound <- rep(1, 4) upperbound <- rep(5, 4)  corMat <- matrix(   c(     1.00, 0.25, 0.35, 0.45,     0.25, 1.00, 0.70, 0.75,     0.35, 0.70, 1.00, 0.85,     0.45, 0.75, 0.85, 1.00   ),   nrow = 4, ncol = 4 )  var_names <- c(\"var1\", \"var2\", \"var3\", \"var4\") colnames(corMat) <- var_names rownames(corMat) <- var_names  ## apply makeScales() function df <- makeScales(   n = n,   means = dfMeans,   sds = dfSds,   lowerbound = lowerbound,   upperbound = upperbound,   cormatrix = corMat ) #> Variable  1 #> reached maximum of 16384 iterations #> Variable  2 #> reached maximum of 16384 iterations #> Variable  3 #> best solution in 2371 iterations #> Variable  4 #> reached maximum of 16384 iterations #>  #> Arranging data to match correlations #>  #> Successfully generated correlated variables  ## test the function str(df) #> 'data.frame':    128 obs. of  4 variables: #>  $ var1: num  2 2 4 3 2 3 3 3 3 1 ... #>  $ var2: num  3 3 5 4 2 3 2 2 3 3 ... #>  $ var3: num  2 5 5 2 1 5 1 1 2 3 ... #>  $ var4: num  3 4 5 4 2 4 3 3 3 4 ...  ### means should be correct to two decimal places dfmoments <- data.frame(   mean = apply(df, 2, mean) |> round(3),   sd = apply(df, 2, sd) |> round(3) ) |> t()  dfmoments #>       var1  var2  var3  var4 #> mean 2.500 3.000 3.000 3.500 #> sd   1.004 1.004 1.501 0.753  ### correlations should be correct to two decimal places cor(df) |> round(3) #>       var1  var2  var3  var4 #> var1 1.000 0.250 0.350 0.448 #> var2 0.250 1.000 0.695 0.750 #> var3 0.350 0.695 1.000 0.836 #> var4 0.448 0.750 0.836 1.000"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"four-likert-scales","dir":"Articles","previous_headings":"Using LikertMakeR > Generate a dataframe of rating scales from a correlation matrix and predefined moments > makeScales() examples","what":"four Likert scales","title":"LikertMakeR vignette","text":"Brand Trust (BT) - confidence consumer brand’s reliability honesty. Brand Satisfaction (BS) - Overall affective evaluation brand experience. Brand Love (BL) - Deep emotional attachment toward brand. Brand Loyalty (BLY) - Intention repurchase recommend brand.","code":"## define parameters n <- 256 dfMeans <- c(3.9, 4.1, 3.6, 4.0) dfSds <-   c(0.6, 0.5, 0.8, 0.7) lowerbound <- rep(1, 4) upperbound <- rep(5, 4) items <- c(4, 3, 4, 3)  corMat <- matrix(   c(      1.00, 0.75, 0.60, 0.70,      0.75, 1.00, 0.65, 0.72,      0.60, 0.65, 1.00, 0.68,      0.70, 0.72, 0.68, 1.00   ),   nrow = 4, ncol = 4 )  scale_names <- c(\"BT\", \"BS\", \"BL\", \"BLY\") rownames(corMat) <- scale_names colnames(corMat) <- scale_names  ## apply makeScales() function df <- makeScales(   n = n,   means = dfMeans,   sds = dfSds,   lowerbound = lowerbound,   upperbound = upperbound,   items = items,   cormatrix = corMat ) #> Variable  1 #> best solution in 266 iterations #> Variable  2 #> best solution in 237 iterations #> Variable  3 #> best solution in 322 iterations #> Variable  4 #> best solution in 696 iterations #>  #> Arranging data to match correlations #>  #> Successfully generated correlated variables  ## test the function head(df) #>     BT       BS   BL      BLY #> 1 4.00 4.333333 3.50 4.333333 #> 2 3.75 3.666667 2.75 2.666667 #> 3 4.75 4.333333 5.00 4.666667 #> 4 4.25 4.333333 4.75 4.333333 #> 5 4.50 4.666667 4.50 5.000000 #> 6 4.75 5.000000 4.50 4.333333 tail(df) #>       BT       BS   BL      BLY #> 251 3.50 4.000000 4.00 4.000000 #> 252 4.00 4.333333 3.50 4.000000 #> 253 3.25 3.333333 3.25 3.666667 #> 254 4.00 3.333333 2.00 3.666667 #> 255 4.00 4.333333 4.50 4.666667 #> 256 4.00 4.666667 4.50 4.000000  ### means should be correct to two decimal places dfmoments <- data.frame(   mean = apply(df, 2, mean) |> round(3),   sd = apply(df, 2, sd) |> round(3) ) |> t()  dfmoments #>         BT    BS    BL   BLY #> mean 3.899 4.102 3.601 4.001 #> sd   0.602 0.500 0.800 0.700  ### correlations should be correct to two decimal places cor(df) |> round(3) #>       BT    BS   BL   BLY #> BT  1.00 0.750 0.60 0.700 #> BS  0.75 1.000 0.65 0.719 #> BL  0.60 0.650 1.00 0.680 #> BLY 0.70 0.719 0.68 1.000"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"generate-a-dataframe-from-cronbachs-alpha-and-predefined-moments","dir":"Articles","previous_headings":"Using LikertMakeR","what":"Generate a dataframe from Cronbach’s Alpha and predefined moments","title":"LikertMakeR vignette","text":"two-step process: apply makeCorrAlpha() generate correlation matrix desired alpha, apply makeItems() generate rating-scale items correlation matrix desired moments Required parameters : k: number items/ columns alpha: target Cronbach’s Alpha. n: number observations lowerbound: vector length ‘k’ values lower bound variable upperbound: vector length ‘k’ values upper bound variable means: vector length ‘k’ desired means variable sds: vector length ‘k’ desired standard deviations variable","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"step-1-generate-a-correlation-matrix","dir":"Articles","previous_headings":"Using LikertMakeR > Generate a dataframe from Cronbach’s Alpha and predefined moments","what":"Step 1: Generate a correlation matrix","title":"LikertMakeR vignette","text":"","code":"## define parameters k <- 6 myAlpha <- 0.85  ## generate correlation matrix set.seed(42) myCorr <- makeCorrAlpha(items = k, alpha = myAlpha) #> correlation values consistent with desired alpha in 15193 iterations #> The correlation matrix is positive definite  ## display correlation matrix myCorr |> round(3) #>        [,1]   [,2]  [,3]  [,4]  [,5]  [,6] #> [1,]  1.000 -0.153 0.116 0.430 0.438 0.473 #> [2,] -0.153  1.000 0.480 0.498 0.528 0.585 #> [3,]  0.116  0.480 1.000 0.602 0.625 0.641 #> [4,]  0.430  0.498 0.602 1.000 0.662 0.677 #> [5,]  0.438  0.528 0.625 0.662 1.000 0.684 #> [6,]  0.473  0.585 0.641 0.677 0.684 1.000  ### checking Cronbach's Alpha alpha(cormatrix = myCorr) #> [1] 0.8500101"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"step-2-generate-dataframe","dir":"Articles","previous_headings":"Using LikertMakeR > Generate a dataframe from Cronbach’s Alpha and predefined moments","what":"Step 2: Generate dataframe","title":"LikertMakeR vignette","text":"","code":"## define parameters n <- 256 myMeans <- c(2.75, 3.00, 3.00, 3.25, 3.50, 3.5) mySds <- c(1.00, 0.75, 1.00, 1.00, 1.00, 1.5) lowerbound <- rep(1, k) upperbound <- rep(5, k)  ## Generate Items myItems <- makeItems(   n = n, means = myMeans, sds = mySds,   lowerbound = lowerbound, upperbound = upperbound,   cormatrix = myCorr ) #> Variable  1 #> best solution in 972 iterations #> Variable  2 #> best solution in 17 iterations #> Variable  3 #> best solution in 973 iterations #> Variable  4 #> best solution in 4866 iterations #> Variable  5 #> best solution in 336 iterations #> Variable  6 #> best solution in 16769 iterations #>  #> Arranging data to match correlations #>  #> Successfully generated correlated variables  ## resulting dataframe head(myItems) #>               #> 1 2 2 3 2 3 2 #> 2 4 3 2 3 4 5 #> 3 3 3 3 4 3 3 #> 4 4 2 2 3 4 2 #> 5 3 3 2 3 4 5 #> 6 1 4 2 3 4 2 tail(myItems) #>                 #> 251 2 4 4 3 3 5 #> 252 3 2 3 2 3 2 #> 253 3 3 2 1 2 2 #> 254 2 4 4 4 4 4 #> 255 4 3 3 4 5 5 #> 256 2 4 5 5 4 5  ## means and standard deviations myMoments <- data.frame(   means = apply(myItems, 2, mean) |> round(3),   sds = apply(myItems, 2, sd) |> round(3) ) |> t() myMoments #>        [,1]  [,2]  [,3]  [,4]  [,5]  [,6] #> means 2.750 3.000 3.000 3.250 3.500 3.500 #> sds   0.998 0.751 1.002 0.998 0.998 1.498  ## Cronbach's Alpha of dataframe alpha(NULL, myItems) #> [1] 0.8498695"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"summary-plots-of-new-dataframe","dir":"Articles","previous_headings":"Using LikertMakeR > Generate a dataframe from Cronbach’s Alpha and predefined moments > Step 2: Generate dataframe","what":"Summary plots of new dataframe","title":"LikertMakeR vignette","text":"Summary dataframe makeItems() function","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"makeitemsscale","dir":"Articles","previous_headings":"Using LikertMakeR > Generate a dataframe of rating-scale items from a summated rating scale","what":"makeItemsScale()","title":"LikertMakeR vignette","text":"makeItemsScale() generates dataframe rating-scale items summated rating scale desired Cronbach’s Alpha. create desired dataframe, user must define following parameters: scale: vector dataframe summated rating scale. range (‘lowerbound’ * ‘items’) (‘upperbound’ * ‘items’) lowerbound: lower bound scale item (example: ‘1’ ‘1’ ‘5’ rating) upperbound: upper bound scale item (example: ‘5’ ‘1’ ‘5’ rating) items: k, number columns generate alpha: desired Cronbach’s Alpha. Default = ‘0.8’ variance: quantile selecting combination items give summated scores. Must lie ‘0’ (minimum variance) ‘1’ (maximum variance). Default = ‘0.5’.","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"generate-a-summated-scale","dir":"Articles","previous_headings":"","what":"LikertMakeR vignette","title":"LikertMakeR vignette","text":"Summated scale distribution","code":"## define parameters n <- 256 mean <- 3.00 sd <- 0.85 lowerbound <- 1 upperbound <- 5 items <- 4  ## apply lfast() function meanScale <- lfast(   n = n, mean = mean, sd = sd,   lowerbound = lowerbound, upperbound = upperbound,   items = items ) #> best solution in 900 iterations  ## sum over all items summatedScale <- meanScale * items"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"create-items-with-makeitemsscale","dir":"Articles","previous_headings":"Using LikertMakeR > Generate a dataframe of rating-scale items from a summated rating scale > makeItemsScale()","what":"create items with makeItemsScale()","title":"LikertMakeR vignette","text":"","code":"## apply makeItemsScale() function  newItems_1 <- makeItemsScale(   scale = summatedScale,   lowerbound = lowerbound,   upperbound = upperbound,   items = items ) #> generate 256 rows #> rearrange 4 values within each of 256 rows #> Complete! #> desired Cronbach's alpha = 0.8 (achieved alpha = 0.8004)  ### First 10 observations and summated scale head(cbind(newItems_1, summatedScale), 10) #>    V1 V2 V3 V4 summatedScale #> 1   4  1  1  3             9 #> 2   2  2  2  2             8 #> 3   5  1  2  4            12 #> 4   5  4  4  4            17 #> 5   5  2  3  3            13 #> 6   5  5  5  4            19 #> 7   4  1  2  4            11 #> 8   5  4  4  5            18 #> 9   5  3  4  5            17 #> 10  4  1  4  3            12  ### correlation matrix cor(newItems_1) |> round(2) #>      V1   V2   V3   V4 #> V1 1.00 0.56 0.61 0.51 #> V2 0.56 1.00 0.60 0.33 #> V3 0.61 0.60 1.00 0.39 #> V4 0.51 0.33 0.39 1.00  ### default Cronbach's alpha = 0.80 alpha(data = newItems_1) |> round(4) #> [1] 0.8004  ### calculate eigenvalues and print scree plot eigenvalues(cor(newItems_1), 1) |> round(3) #> cor(newItems_1)  is positive-definite #> [1] 2.517 0.717 0.403 0.364"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"makeitemsscale-with-same-summated-values-and-higher-alpha","dir":"Articles","previous_headings":"Using LikertMakeR > Generate a dataframe of rating-scale items from a summated rating scale > makeItemsScale()","what":"makeItemsScale() with same summated values and higher alpha","title":"LikertMakeR vignette","text":"","code":"## apply makeItemsScale() function newItems_2 <- makeItemsScale(   scale = summatedScale,   lowerbound = lowerbound,   upperbound = upperbound,   items = items,   alpha = 0.9 ) #> generate 256 rows #> rearrange 4 values within each of 256 rows #> Complete! #> desired Cronbach's alpha = 0.9 (achieved alpha = 0.8778)  ### First 10 observations and summated scale head(cbind(newItems_2, summatedScale), 10) #>    V1 V2 V3 V4 summatedScale #> 1   4  1  2  2             9 #> 2   3  1  2  2             8 #> 3   3  3  3  3            12 #> 4   5  3  5  4            17 #> 5   4  2  4  3            13 #> 6   5  4  5  5            19 #> 7   4  1  4  2            11 #> 8   5  4  5  4            18 #> 9   5  4  4  4            17 #> 10  4  1  4  3            12  ### correlation matrix cor(newItems_2) |> round(2) #>      V1   V2   V3   V4 #> V1 1.00 0.58 0.68 0.64 #> V2 0.58 1.00 0.58 0.66 #> V3 0.68 0.58 1.00 0.73 #> V4 0.64 0.66 0.73 1.00  ### requested Cronbach's alpha = 0.90 alpha(data = newItems_2) |> round(4) #> [1] 0.8778  ### calculate eigenvalues and print scree plot eigenvalues(cor(newItems_2), 1) |> round(3) #> cor(newItems_2)  is positive-definite #> [1] 2.929 0.457 0.366 0.248"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"same-summated-values-with-lower-alpha-may-require-higher-variance","dir":"Articles","previous_headings":"Using LikertMakeR > Generate a dataframe of rating-scale items from a summated rating scale > makeItemsScale()","what":"same summated values with lower alpha may require higher variance","title":"LikertMakeR vignette","text":"","code":"## apply makeItemsScale() function newItems_3 <- makeItemsScale(   scale = summatedScale,   lowerbound = lowerbound,   upperbound = upperbound,   items = items,   alpha = 0.6,   variance = 0.7 ) #> generate 256 rows #> rearrange 4 values within each of 256 rows #> Complete! #> desired Cronbach's alpha = 0.6 (achieved alpha = 0.5989)  ### First 10 observations and summated scale head(cbind(newItems_3, summatedScale), 10) #>    V1 V2 V3 V4 summatedScale #> 1   1  1  3  4             9 #> 2   1  4  2  1             8 #> 3   2  4  4  2            12 #> 4   3  5  4  5            17 #> 5   2  5  2  4            13 #> 6   4  5  5  5            19 #> 7   1  4  3  3            11 #> 8   5  5  5  3            18 #> 9   4  5  5  3            17 #> 10  2  3  2  5            12  ### correlation matrix cor(newItems_3) |> round(2) #>      V1   V2   V3   V4 #> V1 1.00 0.45 0.45 0.09 #> V2 0.45 1.00 0.25 0.17 #> V3 0.45 0.25 1.00 0.22 #> V4 0.09 0.17 0.22 1.00  ### requested Cronbach's alpha = 0.70 alpha(data = newItems_3) |> round(4) #> [1] 0.5989  ### calculate eigenvalues and print scree plot eigenvalues(cor(newItems_3), 1) |> round(3) #> cor(newItems_3)  is positive-definite #> [1] 1.862 0.946 0.742 0.450"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"create-a-dataframe-for-a-t-test","dir":"Articles","previous_headings":"Using LikertMakeR","what":"Create a dataframe for a t-test","title":"LikertMakeR vignette","text":"Generating data independent-samples t-test trivial LikertMakeR. dataframe paired-sample t-test tricky observations related . , must generate dataframe correlated observations.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"independent-samples-t-test","dir":"Articles","previous_headings":"Using LikertMakeR > Create a dataframe for a t-test","what":"Independent-samples t-test","title":"LikertMakeR vignette","text":"Note tests don’t even require sample-size.","code":"## define parameters lower <- 1 upper <- 5 items <- 6  ## generate two independent samples x1 <- lfast(   n = 20, mean = 2.5, sd = 0.75,   lowerbound = lower, upperbound = upper, items = items ) #> reached maximum of 1024 iterations x2 <- lfast(   n = 30, mean = 3.0, sd = 0.85,   lowerbound = lower, upperbound = upper, items = items ) #> reached maximum of 1024 iterations  ## run independent-samples t-test t.test(x1, x2) #>  #>  Welch Two Sample t-test #>  #> data:  x1 and x2 #> t = -2.1599, df = 44.101, p-value = 0.03626 #> alternative hypothesis: true difference in means is not equal to 0 #> 95 percent confidence interval: #>  -0.95576930 -0.03311959 #> sample estimates: #> mean of x mean of y  #>  2.500000  2.994444"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"makepaired-paired-sample-t-test","dir":"Articles","previous_headings":"Using LikertMakeR > Create a dataframe for a t-test","what":"makePaired() paired-sample t-test","title":"LikertMakeR vignette","text":"makePaired() generates correlated values data replicate rating scales taken, example, experimental design. function effectively wrapper function lfast() lcor() addition t-statistic -column correlation inferred. Paired t-tests apply observations associated . example: people rating object treatment, people rating two different objects, ratings husband & wife, etc. makePaired() similar parameters lfast() function addition value desired t-statistic. n sample size means [1:2] vector target means two /measures sds [1:2] vector target standard deviations t_value desired paired t-statistic lowerbound lower bound (e.g. ‘1’ 1-5 rating scale) upperbound upper bound (e.g. ‘5’ 1-5 rating scale) items number items rating scale. precision can relax level accuracy required, lfast().","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"makepaired-examples","dir":"Articles","previous_headings":"Using LikertMakeR > Create a dataframe for a t-test","what":"makePaired() examples","title":"LikertMakeR vignette","text":"","code":"## define parameters n <- 20 means <- c(2.5, 3.0) sds <- c(0.75, 0.85) lower <- 1 upper <- 5 items <- 6 t <- -2.5  ## run the function pairedDat <- makePaired(   n = n, means = means, sds = sds,   t_value = t,   lowerbound = lower, upperbound = upper, items = items ) #> Initial data vectors #> reached maximum of 1024 iterations #> reached maximum of 1024 iterations #> Arranging values to conform with desired t-value #> Complete!"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"check-properties-of-new-data","dir":"Articles","previous_headings":"","what":"LikertMakeR vignette","title":"LikertMakeR vignette","text":"","code":"## test function output str(pairedDat) #> 'data.frame':    20 obs. of  2 variables: #>  $ X1: num  2 3.5 3.67 1.17 2.33 ... #>  $ X2: num  2.5 3.67 2.83 1.67 4 ...  cor(pairedDat) |> round(2) #>      X1   X2 #> X1 1.00 0.38 #> X2 0.38 1.00  pairedMoments <- data.frame(   mean = apply(pairedDat, MARGIN = 2, FUN = mean) |> round(3),   sd = apply(pairedDat, MARGIN = 2, FUN = sd) |> round(3) ) |> t()  pairedMoments #>         X1    X2 #> mean 2.500 2.992 #> sd   0.759 0.851"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"run-a-paired-sample-t-test-with-the-new-data","dir":"Articles","previous_headings":"","what":"LikertMakeR vignette","title":"LikertMakeR vignette","text":"","code":"## run a paired-sample t-test  paired_t <- t.test(x = pairedDat$X1, y = pairedDat$X2, paired = TRUE)  # paired_t <- t.test(pairedDat$X1, pairedDat$X2, paired = TRUE)   paired_t #>  #>  Paired t-test #>  #> data:  pairedDat$X1 and pairedDat$X2 #> t = -2.4455, df = 19, p-value = 0.02438 #> alternative hypothesis: true mean difference is not equal to 0 #> 95 percent confidence interval: #>  -0.91246509 -0.07086825 #> sample estimates: #> mean difference  #>      -0.4916667"},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"makerepeated","dir":"Articles","previous_headings":"Using LikertMakeR > Create a dataframe for Repeated-Measures ANOVA","what":"makeRepeated()","title":"LikertMakeR vignette","text":"makeRepeated() Reconstructs synthetic dataset inter-timepoint correlation matrix repeated-measures ANOVA result, based reported means, standard deviations, F-statistic. function estimates average correlation repeated measures matching reported F-statistic, one three assumed correlation structures: \"cs\" (Compound Symmetry): Compound Symmetry assumes repeated measures equally correlated . , correlation time 1 time 2 time 1 time 3, . structure commonly used repeated-measures ANOVA default. ’s mathematically simple reflects idea timepoints equally related. However, may realistic data correlations decrease time intervals increase (e.g., memory decay learning effects). \"ar1\" (First-Order Autoregressive): first-order autoregressive, assumes measurements closer together time highly correlated apart. example, correlation time 1 time 2 stronger time 1 time 3. pattern often realistic longitudinal time-series studies change gradual. correlation drops exponentially time step. \"toeplitz\" (Linearly Decreasing): Toeplitz structure flexible option allows correlation measurements decrease linearly time gap increases. Unlike AR(1), decline exponential, Toeplitz structure assumes straight-line drop correlation.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"makerepeated-usage","dir":"Articles","previous_headings":"Using LikertMakeR > Create a dataframe for Repeated-Measures ANOVA > makeRepeated()","what":"makeRepeated() usage","title":"LikertMakeR vignette","text":"","code":"makeRepeated(   n,    k,    means,    sds,   f_stat,   df_between = k - 1,   df_within = (n - 1) * (k - 1),   structure = c(\"cs\", \"ar1\", \"toeplitz\"),   names = paste0(\"time_\", 1:k),   items = 1,   lowerbound = 1, upperbound = 5,   return_corr_only = FALSE,   diagnostics = FALSE,   ... )"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"makerepeated-arguments","dir":"Articles","previous_headings":"Using LikertMakeR > Create a dataframe for Repeated-Measures ANOVA > makeRepeated()","what":"makeRepeated() arguments","title":"LikertMakeR vignette","text":"n Integer. Sample size used original study. k Integer. Number repeated measures (timepoints). means Numeric vector length k. Mean values reported timepoint. sds Numeric vector length k. Standard deviations reported timepoint. f_stat Numeric. reported repeated-measures ANOVA F-statistic within-subjects factor. df_between, Degrees freedom conditions (default: k - 1). df_within, Degrees freedom within-subjects (default: (n - 1) * (k - 1)). structure Character. Correlation structure assume: \"cs\", \"ar1\", \"toeplitz\" (default). names Character vector length k. Variable names timepoint (default: \"time_1\" \"time_k\"). items Integer. Number items used generate scale score (passed link{lfast}). lowerbound, Integer. Lower bounds Likert-type response scales (default: 1). upperbound, Integer. upper bounds Likert-type response scales (default: 5). return_corr_only Logical. TRUE, return estimated correlation matrix. diagnostics Logical. TRUE, include diagnostic summaries feasible F-statistic range effect sizes.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"makerepeated-examples","dir":"Articles","previous_headings":"Using LikertMakeR > Create a dataframe for Repeated-Measures ANOVA > makeRepeated()","what":"makeRepeated() examples","title":"LikertMakeR vignette","text":"","code":"out1 <- makeRepeated(   n = 128,   k = 3,   means = c(3.1, 3.5, 3.9),   sds = c(1.0, 1.1, 1.0),   items = 4,   f_stat = 4.87,   structure = \"cs\",   diagnostics = FALSE ) #> Warning in makeRepeated(n = 128, k = 3, means = c(3.1, 3.5, 3.9), sds = c(1, : #> Optimization may not have converged. Check results carefully. #> best solution in 1114 iterations #> best solution in 661 iterations #> best solution in 1021 iterations  head(out1$data) #>   time_1 time_2 time_3 #> 1   1.75   3.75   5.00 #> 2   3.00   3.00   4.50 #> 3   4.25   2.25   4.25 #> 4   4.00   3.50   3.25 #> 5   2.25   4.50   4.00 #> 6   1.25   4.25   5.00 out1$correlation_matrix #>            time_1     time_2     time_3 #> time_1  1.0000000 -0.4899454 -0.4899454 #> time_2 -0.4899454  1.0000000 -0.4899454 #> time_3 -0.4899454 -0.4899454  1.0000000   out2 <- makeRepeated(   n = 32, k = 4,   means = c(2.75, 3.5, 4.0, 4.4),   sds = c(0.8, 1.0, 1.2, 1.0),   f_stat = 16,   structure = \"ar1\",   items = 5,   lowerbound = 1, upperbound = 7,   return_corr_only = FALSE,   diagnostics = TRUE ) #> best solution in 110 iterations #> best solution in 673 iterations #> best solution in 336 iterations #> reached maximum of 1024 iterations  print(out2) #> $data #>    time_1 time_2 time_3 time_4 #> 1     2.0    2.6    2.0    4.4 #> 2     3.0    2.4    4.6    5.0 #> 3     3.0    4.0    4.0    4.0 #> 4     2.4    4.6    4.0    5.0 #> 5     1.4    3.4    2.4    4.0 #> 6     2.6    4.6    4.8    2.6 #> 7     3.0    4.0    3.8    5.6 #> 8     3.6    3.2    5.2    4.2 #> 9     2.4    1.8    1.4    4.6 #> 10    2.0    1.6    2.2    2.8 #> 11    2.4    4.2    3.4    6.2 #> 12    1.8    3.2    4.8    5.8 #> 13    2.2    3.2    3.0    4.0 #> 14    3.0    3.0    5.2    5.0 #> 15    1.6    3.6    3.2    2.0 #> 16    4.4    5.8    4.8    5.6 #> 17    1.4    2.2    3.8    5.2 #> 18    2.2    3.2    5.4    4.8 #> 19    1.8    4.0    6.0    5.2 #> 20    3.4    3.0    4.4    5.0 #> 21    4.0    4.6    5.0    4.8 #> 22    2.6    3.4    5.4    5.0 #> 23    2.8    2.0    4.6    5.0 #> 24    3.6    5.6    4.0    5.0 #> 25    3.2    2.4    3.0    3.6 #> 26    3.0    3.8    3.8    3.0 #> 27    2.0    4.0    4.8    4.2 #> 28    3.4    3.8    2.4    3.0 #> 29    4.4    3.8    3.0    4.0 #> 30    3.4    2.8    2.8    3.2 #> 31    3.0    3.8    4.8    5.0 #> 32    3.0    4.4    6.0    4.2 #>  #> $correlation_matrix #>            time_1    time_2    time_3     time_4 #> time_1 1.00000000 0.3910032 0.1528835 0.05977794 #> time_2 0.39100319 1.0000000 0.3910032 0.15288350 #> time_3 0.15288350 0.3910032 1.0000000 0.39100319 #> time_4 0.05977794 0.1528835 0.3910032 1.00000000 #>  #> $structure #> [1] \"ar1\" #>  #> $feasible_f_range #>       min       max  #>  9.353034 39.481390  #>  #> $recommended_f #> $recommended_f$conservative #> [1] 10.21 #>  #> $recommended_f$moderate #> [1] 11.91 #>  #> $recommended_f$strong #> [1] 30.29 #>  #>  #> $achieved_f #> [1] 15.99983 #>  #> $effect_size_raw #> [1] 0.3792188 #>  #> $effect_size_standardised #> [1] 0.3717831   out3 <- makeRepeated(   n = 32, k = 4,   means = c(2.0, 2.5, 3.0, 2.8),   sds = c(0.8, 0.9, 1.0, 0.9),   items = 4,   f_stat = 24,   structure = \"toeplitz\",   diagnostics = TRUE ) #> Warning in makeRepeated(n = 32, k = 4, means = c(2, 2.5, 3, 2.8), sds = c(0.8, #> : Optimization may not have converged. Check results carefully. #> reached maximum of 1024 iterations #> best solution in 721 iterations #> reached maximum of 1024 iterations #> reached maximum of 1024 iterations  str(out3) #> List of 8 #>  $ data                    :'data.frame':    32 obs. of  4 variables: #>   ..$ time_1: num [1:32] 2.5 1.75 2.5 1.75 1.5 1 2.5 1.25 3.25 1.25 ... #>   ..$ time_2: num [1:32] 2.75 2.25 3 2 1.5 1.25 2.5 2 4.25 1.5 ... #>   ..$ time_3: num [1:32] 2.25 3.5 3.25 2 3.25 1.75 2.75 2 4.75 1.75 ... #>   ..$ time_4: num [1:32] 1.75 3.5 3.75 2 2.25 2 1.75 3.25 4.5 2.25 ... #>  $ correlation_matrix      : num [1:4, 1:4] 1 0.66 0.33 0 0.66 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:4] \"time_1\" \"time_2\" \"time_3\" \"time_4\" #>   .. ..$ : chr [1:4] \"time_1\" \"time_2\" \"time_3\" \"time_4\" #>  $ structure               : chr \"toeplitz\" #>  $ feasible_f_range        : Named num [1:2] 5.57 8.64 #>   ..- attr(*, \"names\")= chr [1:2] \"min\" \"max\" #>  $ recommended_f           :List of 3 #>   ..$ conservative: num 5.59 #>   ..$ moderate    : num 5.62 #>   ..$ strong      : num 7.64 #>  $ achieved_f              : num 9.95 #>  $ effect_size_raw         : num 0.142 #>  $ effect_size_standardised: num 0.174"},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"makescalesregression","dir":"Articles","previous_headings":"Using LikertMakeR > Generate rating-scale data from multiple regression results","what":"makeScalesRegression()","title":"LikertMakeR vignette","text":"Generates synthetic rating-scale data replicates reported regression results: standardised betas, R^2, correlation matrix independent variables (available).","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"makescalesregression-usage","dir":"Articles","previous_headings":"Using LikertMakeR > Generate rating-scale data from multiple regression results > makeScalesRegression()","what":"makeScalesRegression() usage","title":"LikertMakeR vignette","text":"","code":"makeScalesRegression <- (    n,     beta_std,     r_squared,     iv_cormatrix = NULL,     iv_cor_mean = 0.3,      iv_cor_variance = 0.01,     iv_cor_range = c(-0.7, 0.7),     iv_means,     iv_sds,      dv_mean,      dv_sd,     lowerbound_iv,      upperbound_iv,      lowerbound_dv,     upperbound_dv,      items_iv = 1,      items_dv = 1,      var_names = NULL,      tolerance = 0.005  )"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"makescalesregression-arguments","dir":"Articles","previous_headings":"Using LikertMakeR > Generate rating-scale data from multiple regression results > makeScalesRegression()","what":"makeScalesRegression() arguments","title":"LikertMakeR vignette","text":"n sample size. beta_std vector length k (number independent variables) standardised betas. r_squared model R^2 iv_cormatrix independent variables correlation matrix. Default= NULL iv_cor_mean iv_cormatrix, average IV correlations. Default = 0.3 iv_cor_variance iv_cormatrix, variation iv_cormatrix. Default = 0.01 iv_cor_range iv_cormatrix, range iv_cormatrix. Default = c(-0.7, 0.7) iv_means vector length k IV mean values iv_sds vector length k IV standard deviations dv_mean mean Dependent Variable (DV) dv_sd standard deviation DV lowerbound_iv vector length k lowerbounds IV’s upperbound_iv vector length k upperbounds IV’s lowerbound_dv lowerbound DV upperbound_dv upperbound DV items_iv vector length k number items IV’s. Default = 1. items_dv number items DV. Default = 1. var_names vector variable names (Independent Variables first Dependent Variable). Default = NULL tolerance close target R-squared. Default = 0.005","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"example-1-with-provided-iv-correlation-matrix","dir":"Articles","previous_headings":"","what":"LikertMakeR vignette","title":"LikertMakeR vignette","text":"","code":"set.seed(123) iv_corr <- matrix(c(1.0, 0.3, 0.3, 1.0), nrow = 2)  result1 <- makeScalesRegression(   n = 64,   beta_std = c(0.4, 0.3),   r_squared = 0.35,   iv_cormatrix = iv_corr,   iv_means = c(3.0, 3.5),   iv_sds = c(1.0, 0.9),   dv_mean = 3.8,   dv_sd = 1.1,   lowerbound_iv = 1,   upperbound_iv = 5,   lowerbound_dv = 1,   upperbound_dv = 5,   items_iv = 4,   items_dv = 4,   var_names = c(\"Attitude\", \"Intention\", \"Behaviour\") )  print(result1) head(result1$data)"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"example-2-with-optimisation-no-iv-correlation-matrix","dir":"Articles","previous_headings":"","what":"LikertMakeR vignette","title":"LikertMakeR vignette","text":"","code":"set.seed(456) result2 <- makeScalesRegression(   n = 64,   beta_std = c(0.3, 0.25, 0.2),   r_squared = 0.40,   iv_cormatrix = NULL, # Will be optimised   iv_cor_mean = 0.3,   iv_cor_variance = 0.02,   iv_means = c(3.0, 3.2, 2.8),   iv_sds = c(1.0, 0.9, 1.1),   dv_mean = 3.5,   dv_sd = 1.0,   lowerbound_iv = 1,   upperbound_iv = 5,   lowerbound_dv = 1,   upperbound_dv = 5,   items_iv = 4,   items_dv = 5 )  # View optimised correlation matrix print(result2$target_stats$iv_cormatrix) print(result2$optimisation_info)"},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"correlatescales","dir":"Articles","previous_headings":"Using LikertMakeR > Create a multidimensional dataframe of correlated scale items","what":"correlateScales()","title":"LikertMakeR vignette","text":"Correlated rating-scale items generally summed averaged create measure “unobservable”, “latent”, construct. correlateScales() takes several dataframes rating-scale items rearranges rows scales correlated according predefined correlation matrix. Univariate statistics dataframe rating-scale items change, correlations rating-scale items dataframes . run correlateScales(), parameters : dataframes: list ‘k’ dataframes rearranged combined scalecors: target correlation matrix - symmetric k*k positive-semi-definite matrix, ‘k’ number dataframes functions LikertMakeR, correlateScales() focuses item scale moments (mean standard deviation) rather covariance structure. wish simulate data teaching experimenting Structural Equation modelling, recommend sim.item() sim.congeneric() functions psych package","code":""},{"path":[]},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"create-dataframes-of-likert-scale-items","dir":"Articles","previous_headings":"","what":"LikertMakeR vignette","title":"LikertMakeR vignette","text":"","code":"n <- 128 lower <- 1 upper <- 5  ### attitude #1  #### generate a correlation matrix cor_1 <- makeCorrAlpha(items = 4, alpha = 0.80) #> correlation values consistent with desired alpha in 14116 iterations #> The correlation matrix is positive definite  #### specify moments as vectors means_1 <- c(2.5, 2.5, 3.0, 3.5) sds_1 <- c(0.75, 0.85, 0.85, 0.75)  #### apply makeItems() function Att_1 <- makeItems(   n = n, means = means_1, sds = sds_1,   lowerbound = rep(lower, 4), upperbound = rep(upper, 4),   cormatrix = cor_1 ) #> Variable  1 #> reached maximum of 16384 iterations #> Variable  2 #> best solution in 1070 iterations #> Variable  3 #> best solution in 68 iterations #> Variable  4 #> reached maximum of 16384 iterations #>  #> Arranging data to match correlations #>  #> Successfully generated correlated variables  ### attitude #2  #### generate a correlation matrix cor_2 <- makeCorrAlpha(items = 5, alpha = 0.85) #> correlation values consistent with desired alpha in 22469 iterations #> The correlation matrix is positive definite  #### specify moments as vectors means_2 <- c(2.5, 2.5, 3.0, 3.0, 3.5) sds_2 <- c(0.75, 0.85, 0.75, 0.85, 0.75)  #### apply makeItems() function Att_2 <- makeItems(   n, means_2, sds_2,   rep(lower, 5), rep(upper, 5),   cor_2 ) #> Variable  1 #> reached maximum of 16384 iterations #> Variable  2 #> best solution in 106 iterations #> Variable  3 #> reached maximum of 16384 iterations #> Variable  4 #> best solution in 290 iterations #> Variable  5 #> reached maximum of 16384 iterations #>  #> Arranging data to match correlations #>  #> Successfully generated correlated variables  ### attitude #3  #### generate a correlation matrix cor_3 <- makeCorrAlpha(items = 6, alpha = 0.90) #> correlation values consistent with desired alpha in 603 iterations #> The correlation matrix is positive definite  #### specify moments as vectors means_3 <- c(2.5, 2.5, 3.0, 3.0, 3.5, 3.5) sds_3 <- c(0.75, 0.85, 0.85, 1.0, 0.75, 0.85)  #### apply makeItems() function Att_3 <- makeItems(   n, means_3, sds_3,   rep(lower, 6), rep(upper, 6),   cor_3 ) #> Variable  1 #> reached maximum of 16384 iterations #> Variable  2 #> best solution in 343 iterations #> Variable  3 #> best solution in 42 iterations #> Variable  4 #> reached maximum of 16384 iterations #> Variable  5 #> reached maximum of 16384 iterations #> Variable  6 #> best solution in 1230 iterations #>  #> Arranging data to match correlations #>  #> Successfully generated correlated variables  ### behavioural intention intent <- lfast(n, mean = 4.0, sd = 3, lowerbound = 0, upperbound = 10) |>   data.frame() #> best solution in 3059 iterations names(intent) <- \"int\""},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"check-properties-of-item-dataframes","dir":"Articles","previous_headings":"","what":"LikertMakeR vignette","title":"LikertMakeR vignette","text":"","code":"## Attitude #1 A1_moments <- data.frame(   means = apply(Att_1, 2, mean) |> round(2),   sds = apply(Att_1, 2, sd) |> round(2) ) |> t()  ### Attitude #1 moments A1_moments #>       [,1] [,2] [,3] [,4] #> means 2.50 2.50 3.00 3.50 #> sds   0.75 0.85 0.85 0.75  ### Attitude #1 correlations cor(Att_1) |> round(2) #>      [,1] [,2] [,3] [,4] #> [1,] 1.00 0.18 0.27 0.43 #> [2,] 0.18 1.00 0.63 0.71 #> [3,] 0.27 0.63 1.00 0.77 #> [4,] 0.43 0.71 0.77 1.00  ### Attitude #1 cronbach's alpha alpha(cor(Att_1)) |> round(3) #> [1] 0.8  ## Attitude #2 A2_moments <- data.frame(   means = apply(Att_2, 2, mean) |> round(2),   sds = apply(Att_2, 2, sd) |> round(2) ) |> t()  ### Attitude #2 moments A2_moments #>       [,1] [,2] [,3] [,4] [,5] #> means 2.50 2.50 3.00 3.00 3.50 #> sds   0.75 0.85 0.75 0.85 0.75  ### Attitude #2 correlations cor(Att_2) |> round(2) #>      [,1] [,2] [,3] [,4] [,5] #> [1,] 1.00 0.06 0.31 0.44 0.50 #> [2,] 0.06 1.00 0.57 0.63 0.65 #> [3,] 0.31 0.57 1.00 0.68 0.68 #> [4,] 0.44 0.63 0.68 1.00 0.79 #> [5,] 0.50 0.65 0.68 0.79 1.00  ### Attitude #2 cronbach's alpha alpha(cor(Att_2)) |> round(3) #> [1] 0.849  ## Attitude #3 A3_moments <- data.frame(   means = apply(Att_3, 2, mean) |> round(2),   sds = apply(Att_3, 2, sd) |> round(2) ) |> t()  ### Attitude #3 moments A3_moments #>       [,1] [,2] [,3] [,4] [,5] [,6] #> means 2.50 2.50 3.00    3 3.50 3.50 #> sds   0.75 0.85 0.85    1 0.75 0.85  ### Attitude #3 correlations cor(Att_3) |> round(2) #>      [,1] [,2] [,3] [,4] [,5] [,6] #> [1,] 1.00 0.33 0.36 0.42 0.47 0.48 #> [2,] 0.33 1.00 0.50 0.54 0.57 0.63 #> [3,] 0.36 0.50 1.00 0.65 0.72 0.78 #> [4,] 0.42 0.54 0.65 1.00 0.83 0.85 #> [5,] 0.47 0.57 0.72 0.83 1.00 0.85 #> [6,] 0.48 0.63 0.78 0.85 0.85 1.00  ### Attitude #2 cronbach's alpha alpha(cor(Att_3)) |> round(3) #> [1] 0.899   ## Behavioural Intention  intent_moments <- data.frame(   mean = apply(intent, 2, mean) |> round(3),   sd = apply(intent, 2, sd) |> round(3) ) |> t()  ### Intention moments intent_moments #>        int #> mean 4.000 #> sd   2.999"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"correlatescales-parameters","dir":"Articles","previous_headings":"","what":"LikertMakeR vignette","title":"LikertMakeR vignette","text":"","code":"### target scale correlation matrix scale_cors <- matrix(   c(     1.0, 0.7, 0.6, 0.5,     0.7, 1.0, 0.4, 0.3,     0.6, 0.4, 1.0, 0.2,     0.5, 0.3, 0.2, 1.0   ),   nrow = 4 )  ### bring dataframes into a list data_frames <- list(\"A1\" = Att_1, \"A2\" = Att_2, \"A3\" = Att_3, \"Int\" = intent)"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"apply-the-correlatescales-function","dir":"Articles","previous_headings":"Using LikertMakeR > Create a multidimensional dataframe of correlated scale items > correlateScales() examples","what":"apply the correlateScales() function","title":"LikertMakeR vignette","text":"","code":"### apply correlateScales() function my_correlated_scales <- correlateScales(   dataframes = data_frames,   scalecors = scale_cors ) #> scalecors  is positive-definite #> New dataframe successfully created"},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"check-the-properties-of-our-derived-dataframe","dir":"Articles","previous_headings":"","what":"LikertMakeR vignette","title":"LikertMakeR vignette","text":"","code":"## data structure str(my_correlated_scales) #> 'data.frame':    128 obs. of  16 variables: #>  $ A1_1 : num  3 2 3 2 4 2 2 2 3 3 ... #>  $ A1_2 : num  2 2 1 1 3 1 1 3 2 2 ... #>  $ A1_3 : num  3 2 2 2 3 1 3 2 3 2 ... #>  $ A1_4 : num  3 3 3 2 4 2 3 3 3 3 ... #>  $ A2_1 : num  3 1 2 2 2 1 2 2 3 2 ... #>  $ A2_2 : num  1 2 2 2 3 2 3 2 3 3 ... #>  $ A2_3 : num  2 2 2 3 4 2 3 3 4 3 ... #>  $ A2_4 : num  2 2 2 3 3 2 3 2 4 3 ... #>  $ A2_5 : num  3 3 3 3 4 2 3 4 5 3 ... #>  $ A3_1 : num  2 2 2 1 3 3 2 3 2 2 ... #>  $ A3_2 : num  2 2 3 2 2 1 2 2 2 2 ... #>  $ A3_3 : num  3 3 2 2 3 1 3 2 2 2 ... #>  $ A3_4 : num  3 2 3 1 3 2 3 4 2 2 ... #>  $ A3_5 : num  4 3 3 2 3 3 3 3 3 3 ... #>  $ A3_6 : num  4 3 3 2 3 2 3 3 3 3 ... #>  $ Int_1: num  9 7 0 2 6 2 6 1 10 5 ... ## eigenvalues of dataframe correlations Cor_Correlated_Scales <- cor(my_correlated_scales) eigenvalues(cormatrix = Cor_Correlated_Scales, scree = TRUE) |> round(2) #> Cor_Correlated_Scales  is positive-definite #>  [1] 7.06 2.32 1.21 1.03 0.81 0.72 0.51 0.50 0.39 0.36 0.32 0.22 0.18 0.16 0.13 #> [16] 0.10 #### Eigenvalues of predictor variable items only Cor_Attitude_items <- cor(my_correlated_scales[, -16]) eigenvalues(cormatrix = Cor_Attitude_items, scree = TRUE) |> round(2) #> Cor_Attitude_items  is positive-definite #>  [1] 6.90 2.29 1.19 0.86 0.75 0.63 0.50 0.40 0.36 0.32 0.22 0.18 0.16 0.14 0.10"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"helper-functions","dir":"Articles","previous_headings":"Using LikertMakeR","what":"Helper functions","title":"LikertMakeR vignette","text":"likertMakeR() includes two additional functions may help examining parameters output. alpha() calculates Cronbach’s Alpha given correlation matrix given dataframe eigenvalues() calculates eigenvalues correlation matrix, report whether correlation matrix positive definite, produces optional scree plot.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"alpha","dir":"Articles","previous_headings":"Using LikertMakeR > Helper functions","what":"alpha()","title":"LikertMakeR vignette","text":"alpha() accepts, input, either correlation matrix dataframe. submitted, correlation matrix used default, message effect.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"alpha-examples","dir":"Articles","previous_headings":"Using LikertMakeR > Helper functions","what":"alpha() examples","title":"LikertMakeR vignette","text":"","code":"## define parameters df <- data.frame(   V1 = c(4, 2, 4, 3, 2, 2, 2, 1),   V2 = c(3, 1, 3, 4, 4, 3, 2, 3),   V3 = c(4, 1, 3, 5, 4, 1, 4, 2),   V4 = c(4, 3, 4, 5, 3, 3, 3, 3) )  corMat <- matrix(   c(     1.00, 0.35, 0.45, 0.75,     0.35, 1.00, 0.65, 0.55,     0.45, 0.65, 1.00, 0.65,     0.75, 0.55, 0.65, 1.00   ),   nrow = 4, ncol = 4 )  ## apply function examples alpha(cormatrix = corMat) #> [1] 0.8395062 alpha(data = df) #> [1] 0.8026658 alpha(NULL, df) #> [1] 0.8026658 alpha(corMat, df) #> Alert:  #> Both cormatrix and data present. #>                  #> Using cormatrix by default. #> [1] 0.8395062"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"eigenvalues","dir":"Articles","previous_headings":"Using LikertMakeR > Helper functions","what":"eigenvalues()","title":"LikertMakeR vignette","text":"eigenvalues() calculates eigenvalues correlation matrix, reports whether matrix positive-definite, optionally produces scree plot.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"eigenvalues-examples","dir":"Articles","previous_headings":"Using LikertMakeR > Helper functions","what":"eigenvalues() examples","title":"LikertMakeR vignette","text":"","code":"## define parameters correlationMatrix <- matrix(   c(     1.00, 0.25, 0.35, 0.45,     0.25, 1.00, 0.70, 0.75,     0.35, 0.70, 1.00, 0.85,     0.45, 0.75, 0.85, 1.00   ),   nrow = 4, ncol = 4 )  ## apply function evals <- eigenvalues(cormatrix = correlationMatrix) #> correlationMatrix  is positive-definite  print(evals) #> [1] 2.7484991 0.8122627 0.3048151 0.1344231"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"eigenvalues-function-with-optional-scree-plot","dir":"Articles","previous_headings":"","what":"LikertMakeR vignette","title":"LikertMakeR vignette","text":"","code":"evals <- eigenvalues(correlationMatrix, 1) #> correlationMatrix  is positive-definite print(evals) #> [1] 2.7484991 0.8122627 0.3048151 0.1344231"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"alternative-methods-packages","dir":"Articles","previous_headings":"","what":"Alternative methods & packages","title":"LikertMakeR vignette","text":"LikertMakeR intended synthesising & correlating rating-scale data means, standard deviations, correlations close possible predefined parameters. don’t need data close exact, options may faster flexible. Different approaches include: sampling truncated normal distribution sampling predetermined probability distribution marginal model specification","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"sampling-from-a-truncated-normal-distribution","dir":"Articles","previous_headings":"Alternative methods & packages","what":"sampling from a truncated normal distribution","title":"LikertMakeR vignette","text":"Data sampled normal distribution, truncated suit rating-scale boundaries, rounded set discrete values see rating scales. See Heinz (2021) excellent short example using following packages: truncnorm faux See also rLikert() function excellent latent2likert package, Lalovic (2024), approach using optimal discretization skew-normal distribution. latent2likert() converts continuous latent variables ordinal categories generate Likert scale item responses.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"sampling-with-a-predetermined-probability-distribution","dir":"Articles","previous_headings":"Alternative methods & packages","what":"sampling with a predetermined probability distribution","title":"LikertMakeR vignette","text":"following code generate vector values approximately given probabilities. Good simulating single item.","code":"n <- 128 sample(1:5, n,   replace = TRUE,   prob = c(0.1, 0.2, 0.4, 0.2, 0.1) )"},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"marginal-model-specification","dir":"Articles","previous_headings":"Alternative methods & packages","what":"marginal model specification","title":"LikertMakeR vignette","text":"Marginal model specification extends idea predefined probability distribution multivariate correlated dataframes. SimCorrMix: Simulation Correlated Data Multiple Variable Types Including Continuous Count Mixture Distributions CRAN. SimMultiCorrData: Simulation Correlated Data Multiple Variable Types CRAN. lsasim: Functions Facilitate Simulation Large Scale Assessment Data CRAN. See Matta et al. (2018) GenOrd:Simulation Discrete Random Variables Given Correlation Matrix Marginal Distributions CRAN. SimCorMultRes: Simulates Correlated Multinomial Responses CRAN. See Touloumis (2016) covsim: VITA, IG PLSIM Simulation Given Covariance Marginals CRAN. See Grønneberg et al. (2022)","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"factor-models-classical-test-theory-ctt","dir":"Articles","previous_headings":"Alternative methods & packages","what":"Factor Models: Classical Test Theory (CTT)","title":"LikertMakeR vignette","text":"psych package several excellent functions simulating rating-scale data based factor loadings.  focus factor item correlations rather item moments.  Highly recommended. psych::sim.item Generate simulated data structures circumplex, spherical, simple structure psych::sim.congeneric Simulate congeneric data set without minor factors See Revelle (prep) Also: simsem many functions simulating testing data application Structural Equation modelling. See examples https://simsem.org/","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"general-data-simulation","dir":"Articles","previous_headings":"Alternative methods & packages","what":"General data simulation","title":"LikertMakeR vignette","text":"simpr provides general, simple, tidyverse-friendly framework generating simulated data, fitting models simulations, tidying model results.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/LikertMakeR_vignette.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"LikertMakeR vignette","text":"D’Alessandro, S., H. Winzar, B. Lowe, B.J. Babin, W. Zikmund (2020). Marketing Research 5ed, Cengage Australia. https://cengage.com.au/sem121/marketing-research-5th-edition-dalessandro-babin-zikmund Grønneberg, S., Foldnes, N., & Marcoulides, K. M. (2022). covsim: R Package Simulating Non-Normal Data Structural Equation Models Using Copulas. Journal Statistical Software, 102(1), 1–45. doi:10.18637/jss.v102.i03 Heinz, . (2021), Simulating Correlated Likert-Scale Data R: 3 Simple Steps (blog post) https://glaswasser.github.io/simulating-correlated-likert-scale-data/ Lalovic M (2024). latent2likert: Converting Latent Variables Likert Scale Responses. R package version 1.2.2, https://latent2likert.lalovic.io/. Matta, T.H., Rutkowski, L., Rutkowski, D. & Liaw, Y.L. (2018), lsasim: R package simulating large-scale assessment data. Large-scale Assessments Education 6, 15. doi:10.1186/s40536-018-0068-8 Pornprasertmanit, S., Miller, P., & Schoemann, . (2021). simsem: R package simulated structural equation modeling https://simsem.org/ Revelle, W. (prep) introduction psychometric theory applications R. Springer. (working draft available https://personality-project.org/r/book/ ) Touloumis, . (2016), Simulating Correlated Binary Multinomial Responses Marginal Model Specification: SimCorMultRes Package, R Journal 8:2, 79-91. doi:10.32614/RJ-2016-034 Winzar, H. (2022). LikertMakeR: Synthesise correlate Likert scale related rating-scale data predefined first second moments. CRAN: doi:10.32614/CRAN.package.LikertMakeR","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/makeCorrLoadings_validate.html","id":"abstract","dir":"Articles","previous_headings":"","what":"Abstract","title":"makeCorrLoadings() validation","text":"makeCorrLoadings() function accurately reconstructs item correlation matrix item-factor loadings factor correlations, similar produced EFA SEM. function robust even without explicit uniqueness factor correlation inputs, although loadings greater 0.05 needed best results.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/makeCorrLoadings_validate.html","id":"the-makecorrloadings-function","dir":"Articles","previous_headings":"","what":"The makeCorrLoadings() function","title":"makeCorrLoadings() validation","text":"makeCorrLoadings() function generates correlation matrix factor loadings factor correlations might published results Exploratory Factor Analysis (EFA) Structural Equation Model (SEM). resulting correlation matrix can applied makeItems() function generate synthetic data set rating-scale items closely resemble original data created factor loadings summary table. paper tests well makeCorrLoadings() function achieves goal.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/makeCorrLoadings_validate.html","id":"study-design","dir":"Articles","previous_headings":"","what":"Study design","title":"makeCorrLoadings() validation","text":"valid makeCorrLoadings() function able produce correlation matrix identical original correlation matrix. , subsequent treatment makeItems() produce dataframe appears come population original sample. need original, True, dataframe test function. Preferably, several different original dataframes ensure results generalisable.","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/articles/makeCorrLoadings_validate.html","id":"original-data","dir":"Articles","previous_headings":"Study #1: Party Panel 2015","what":"Original data","title":"makeCorrLoadings() validation","text":"use pp15 dataset rosetta package (Peters Verboon 2023). subset Party Panel 2015 dataset. Party Panel annual semi-panel study among Dutch nightlife patrons, every year, determinants another nightlife-related risk behaviour mapped. 2015, determinants measured behaviours related using highly dosed ecstasy pills. Nine items relevant study. 7-point likert-style question scored range -3 +3. questions item labels presented follows:","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/makeCorrLoadings_validate.html","id":"extract-and-clean-the-original-data-file","dir":"Articles","previous_headings":"Study #1: Party Panel 2015 > Original data","what":"Extract and clean the original data file","title":"makeCorrLoadings() validation","text":"","code":"## variable names item_list <- c(   \"highDose_AttBeliefs_long\",   \"highDose_AttBeliefs_intensity\",   \"highDose_AttBeliefs_intoxicated\",   \"highDose_AttBeliefs_energy\",   \"highDose_AttBeliefs_euphoria\",   \"highDose_AttBeliefs_insight\",   \"highDose_AttBeliefs_connection\",   \"highDose_AttBeliefs_contact\",   \"highDose_AttBeliefs_sex\" )  ## read the data/ select desired variables/ remove obs with missing values dat <- read.csv2(file = \"data/pp15.csv\") |>   select(all_of(item_list)) |>   na.omit()  ## give variables shorter names names(dat) <- itemLabels  sampleSize <- nrow(dat)"},{"path":"https://winzarh.github.io/LikertMakeR/articles/makeCorrLoadings_validate.html","id":"target-correlation-matrix","dir":"Articles","previous_headings":"Study #1: Party Panel 2015","what":"Target correlation matrix","title":"makeCorrLoadings() validation","text":"correlations among nine items reproducable makeCorrLoadings() function.","code":"## correlation matrix pp15_cor <- cor(dat)"},{"path":"https://winzarh.github.io/LikertMakeR/articles/makeCorrLoadings_validate.html","id":"test-cases","dir":"Articles","previous_headings":"Study #1: Party Panel 2015 > Target correlation matrix","what":"Test cases","title":"makeCorrLoadings() validation","text":"shall produce following options factor correlation reporting: Full information: factor loadings factor correlations five decimal places, plus uniquenesses. Full information - uniquenesses: factor loadings factor correlations 5 decimal places without uniquenesses. Rounded loadings: factor loadings factor correlations two decimal places, plus uniquenesses. Rounded loadings - uniquenesses: factor loadings factor correlations two decimal places without uniquenesses. Censored loadings: factor loadings two decimal places, loadings less arbitrary value removed clarity presentation, uniquenesses. Censored loadings - uniqueness: factor loadings two decimal places, loadings less arbitrary value removed clarity, without uniquenesses. Censored loadings, uniqueness, factor correlations: factor loadings two decimal places, loadings less arbitrary value removed clarity, uniquenesses factor correlations. Functionally, equivalent claiming orthogonal factors even factor loadings non-orthogonal rotation.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/makeCorrLoadings_validate.html","id":"evaluation","dir":"Articles","previous_headings":"Study #1: Party Panel 2015 > Target correlation matrix","what":"Evaluation","title":"makeCorrLoadings() validation","text":"compare True correlation matrix Synthetic matrix, employ cortest.jennrich() function psych package (Revelle 2024). Chi-square test whether pair matrices equal (Jennrich 1970). report raw χ2\\chi^2 statistic corresponding p-value test.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/makeCorrLoadings_validate.html","id":"exploratory-factor-analysis","dir":"Articles","previous_headings":"Study #1: Party Panel 2015","what":"Exploratory Factor Analysis","title":"makeCorrLoadings() validation","text":"pretesting suggest two factors appropriate sample. ’re confident factors correlated, use promax rotation.","code":"## factor analysis from `rosetta` package rfaDose <- rosetta::factorAnalysis(   data = dat,   nfactors = 2,   rotate = \"promax\" ) #> Warning: `aes_string()` was deprecated in ggplot2 3.0.0. #> ℹ Please use tidy evaluation idioms with `aes()`. #> ℹ See also `vignette(\"ggplot2-in-packages\")` for more information. #> ℹ The deprecated feature was likely used in the rosetta package. #>   Please report the issue at <https://gitlab.com/r-packages/rosetta/-/issues>. #> This warning is displayed once every 8 hours. #> Call `lifecycle::last_lifecycle_warnings()` to see where this warning was #> generated. #> Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0. #> ℹ Please use `linewidth` instead. #> ℹ The deprecated feature was likely used in the rosetta package. #>   Please report the issue at <https://gitlab.com/r-packages/rosetta/-/issues>. #> This warning is displayed once every 8 hours. #> Call `lifecycle::last_lifecycle_warnings()` to see where this warning was #> generated.  factorLoadings <- rfaDose$output$loadings factorCorrs <- rfaDose$output$correlations"},{"path":[]},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/articles/makeCorrLoadings_validate.html","id":"test-case-1-full-information","dir":"Articles","previous_headings":"Study #1: Party Panel 2015","what":"Test Case #1: Full information","title":"makeCorrLoadings() validation","text":"","code":"## round input values to 5 decimal places # factor loadings fl1 <- factorLoadings[, 1:2] |>   round(5) |>   as.matrix() # item uniquenesses un1 <- factorLoadings[, 3] |> round(5) # factor correlations fc1 <- round(factorCorrs, 5) |> as.matrix() # run makeCorrLoadings() function itemCors_1 <- makeCorrLoadings(   loadings = fl1,   factorCor = fc1,   uniquenesses = un1 ) ## Compare the two matrices chiSq_1 <- cortest.jennrich(   R1 = pp15_cor, R2 = itemCors_1,   n1 = sampleSize, n2 = sampleSize )"},{"path":"https://winzarh.github.io/LikertMakeR/articles/makeCorrLoadings_validate.html","id":"test-case-2-full-information---no-uniquenesses","dir":"Articles","previous_headings":"Study #1: Party Panel 2015","what":"Test case #2: Full information - No uniquenesses","title":"makeCorrLoadings() validation","text":"factor loadings factor correlations 5 decimal places without uniquenesses","code":"## round input values to 2 decimal places # factor loadings fl2 <- factorLoadings[, 1:2] |>   round(5) |>   as.matrix() # factor correlations fc2 <- factorCorrs |>   round(5) |>   as.matrix() itemCors_2 <- makeCorrLoadings(   loadings = fl2,   factorCor = fc2,   uniquenesses = NULL ) ## Compare the two matrices chiSq_2 <- cortest.jennrich(   R1 = pp15_cor, R2 = itemCors_2,   n1 = sampleSize, n2 = sampleSize )"},{"path":"https://winzarh.github.io/LikertMakeR/articles/makeCorrLoadings_validate.html","id":"test-case-3-rounded-loadings","dir":"Articles","previous_headings":"Study #1: Party Panel 2015","what":"Test case #3: Rounded loadings","title":"makeCorrLoadings() validation","text":"factor loadings factor correlations two decimal places.","code":"## round input values to 2 decimal places # factor loadings fl3 <- factorLoadings[, 1:2] |>   round(2) |>   as.matrix() # item uniquenesses un3 <- factorLoadings[, 3] |>   round(2) ## factor correlations fc3 <- factorCorrs |>   round(2) |>   as.matrix() ## Compare the two matrices itemCors_3 <- makeCorrLoadings(   loadings = fl3,   factorCor = fc3,   uniquenesses = un3 ) ## Compare the two matrices chiSq_3 <- cortest.jennrich(   R1 = pp15_cor, R2 = itemCors_3,   n1 = sampleSize, n2 = sampleSize )"},{"path":"https://winzarh.github.io/LikertMakeR/articles/makeCorrLoadings_validate.html","id":"test-case-4-rounded-loadings---no-uniquenesses","dir":"Articles","previous_headings":"Study #1: Party Panel 2015","what":"Test case #4: Rounded loadings - No uniquenesses","title":"makeCorrLoadings() validation","text":"Factor loadings factor correlations two decimal places, uniquenesses","code":"## round input values to 2 decimal places # factor loadings fl4 <- factorLoadings[, 1:2] |>   round(2) |>   as.matrix() ## factor correlations fc4 <- factorCorrs |>   round(2) |>   as.matrix() # apply the function itemCors_4 <- makeCorrLoadings(   loadings = fl4,   factorCor = fc4,   uniquenesses = NULL ) ## Compare the two matrices chiSq_4 <- cortest.jennrich(   R1 = pp15_cor, R2 = itemCors_4,   n1 = sampleSize, n2 = sampleSize )"},{"path":"https://winzarh.github.io/LikertMakeR/articles/makeCorrLoadings_validate.html","id":"censored-loadings","dir":"Articles","previous_headings":"Study #1: Party Panel 2015","what":"Censored loadings","title":"makeCorrLoadings() validation","text":"Often, item-factor loadings presented lower values removed ease reading. ’m calling “Censored” loadings. usually acceptable, purpose show reader larger loadings . missing information may affect results reverse-engineering ’re employing makeCorrLoadings() function. study, set level hidden loadings values less ‘0.1’, ‘0.2’ ‘0.3’.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/makeCorrLoadings_validate.html","id":"test-case-5-censored-loadings","dir":"Articles","previous_headings":"Study #1: Party Panel 2015","what":"Test case #5: Censored loadings","title":"makeCorrLoadings() validation","text":"Factor loadings less ‘0.1’, ‘0.2’, ‘0.3’ removed clarity, presented two decimal places.","code":"## round input values to 2 decimal places # factor loadings fl5a <- factorLoadings[, 1:2] |>   round(2) # convert factor loadings < '0.1' to '0' fl5a[abs(fl5a) < 0.1] <- 0 fl5a <- as.matrix(fl5a) # item uniquenesses un5 <- factorLoadings[, 3] |>   round(2) # factor correlations fc5 <- factorCorrs |>   round(2) |>   as.matrix() # apply the function itemCors_5a <- makeCorrLoadings(   loadings = fl5a,   factorCor = fc5,   uniquenesses = un5 ) ## Compare the two matrices chiSq_5a <- cortest.jennrich(   R1 = pp15_cor, R2 = itemCors_5a,   n1 = sampleSize, n2 = sampleSize )  # factor loadings fl5b <- factorLoadings[, 1:2] |>   round(2) # convert factor loadings < '0.2' to '0' fl5b[abs(fl5b) < 0.2] <- 0 fl5b <- as.matrix(fl5b) # apply the function itemCors_5b <- makeCorrLoadings(   loadings = fl5b,   factorCor = fc5,   uniquenesses = un5 ) ## Compare the two matrices chiSq_5b <- cortest.jennrich(   R1 = pp15_cor, R2 = itemCors_5b,   n1 = sampleSize, n2 = sampleSize )  # factor loadings fl5c <- factorLoadings[, 1:2] |>   round(2) # convert factor loadings < '0.2' to '0' fl5c[abs(fl5c) < 0.3] <- 0 fl5c <- as.matrix(fl5c) # apply the function itemCors_5c <- makeCorrLoadings(   loadings = fl5c,   factorCor = fc5,   uniquenesses = un5 ) ## Compare the two matrices chiSq_5c <- cortest.jennrich(   R1 = pp15_cor, R2 = itemCors_5c,   n1 = sampleSize, n2 = sampleSize ) # kable(itemCors_5, digits = 2)"},{"path":"https://winzarh.github.io/LikertMakeR/articles/makeCorrLoadings_validate.html","id":"test-case-6-censored-loadings---no-uniquenesses","dir":"Articles","previous_headings":"Study #1: Party Panel 2015","what":"Test case #6: Censored loadings - no uniquenesses","title":"makeCorrLoadings() validation","text":"declared uniquenesses, inferred estimated communalities.","code":"itemCors_6a <- makeCorrLoadings(   loadings = fl5a,   factorCor = fc5,   uniquenesses = NULL ) ## Compare the two matrices chiSq_6a <- cortest.jennrich(   R1 = pp15_cor, R2 = itemCors_6a,   n1 = sampleSize, n2 = sampleSize ) # apply the function itemCors_6b <- makeCorrLoadings(   loadings = fl5b,   factorCor = fc5,   uniquenesses = NULL ) ## Compare the two matrices chiSq_6b <- cortest.jennrich(   R1 = pp15_cor, R2 = itemCors_6b,   n1 = sampleSize, n2 = sampleSize ) # apply the function itemCors_6c <- makeCorrLoadings(   loadings = fl5c,   factorCor = fc5,   uniquenesses = NULL ) ## Compare the two matrices chiSq_6c <- cortest.jennrich(   R1 = pp15_cor, R2 = itemCors_6c,   n1 = sampleSize, n2 = sampleSize )"},{"path":"https://winzarh.github.io/LikertMakeR/articles/makeCorrLoadings_validate.html","id":"test-case-7-censored-loadings-no-uniqueness-no-factor-correlations","dir":"Articles","previous_headings":"Study #1: Party Panel 2015","what":"Test case #7 Censored loadings, no uniqueness, no factor correlations","title":"makeCorrLoadings() validation","text":"uniquenesses. , Uniquenesses estimated 1-communalities, communalities = sum(factor-loadings^2). factor correlations. , assume orthogonal factors.","code":"itemCors_7a <- makeCorrLoadings(   loadings = fl5a,   factorCor = NULL,   uniquenesses = NULL ) ## Compare the two matrices chiSq_7a <- cortest.jennrich(   R1 = pp15_cor, R2 = itemCors_7a,   n1 = sampleSize, n2 = sampleSize ) # apply the function itemCors_7b <- makeCorrLoadings(   loadings = fl5b,   factorCor = NULL,   uniquenesses = NULL ) ## Compare the two matrices chiSq_7b <- cortest.jennrich(   R1 = pp15_cor, R2 = itemCors_7b,   n1 = sampleSize, n2 = sampleSize ) # apply the function itemCors_7c <- makeCorrLoadings(   loadings = fl5c,   factorCor = NULL,   uniquenesses = NULL ) ## Compare the two matrices chiSq_7c <- cortest.jennrich(   R1 = pp15_cor, R2 = itemCors_7c,   n1 = sampleSize, n2 = sampleSize )"},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/articles/makeCorrLoadings_validate.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"makeCorrLoadings() validation","text":"makeCorrLoadings function works quite well information factor loadings, much less well “summary” (censored) factor loadings given.","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/articles/makeCorrLoadings_validate.html","id":"original-data-bfi-25-personality-items-representing-5-factors","dir":"Articles","previous_headings":"Study #2: Big Five (bfi personality items)","what":"Original data: bfi 25 Personality items representing 5 factors","title":"makeCorrLoadings() validation","text":"25 personality self report items taken International Personality Item Pool (ipip.ori.org) included part Synthetic Aperture Personality Assessment (SAPA) web based personality assessment project. data available psychTools package (William Revelle 2024). 2800 subjects included demonstration set scale construction, factor analysis, Item Response Theory analysis. Three additional demographic variables (sex, education, age) also included. purposes study, confine women (sex==2) postgraduate qualifications (education==5), giving us sample size 229 subjects. dataset contains following 28 variables. (q numbers SAPA item numbers). A1 indifferent feelings others. (q_146) A2 Inquire others’ well-. (q_1162) A3 Know comfort others. (q_1206) A4 Love children. (q_1364) A5 Make people feel ease. (q_1419) C1 exacting work. (q_124) C2 Continue everything perfect. (q_530) C3 things according plan. (q_619) C4 things half-way manner. (q_626) C5 Waste time. (q_1949) E1 Don’t talk lot. (q_712) E2 Find difficult approach others. (q_901) E3 Know captivate people. (q_1205) E4 Make friends easily. (q_1410) E5 Take charge. (q_1768) N1 Get angry easily. (q_952) N2 Get irritated easily. (q_974) N3 frequent mood swings. (q_1099 N4 Often feel blue. (q_1479) N5 Panic easily. (q_1505) O1 full ideas. (q_128) O2 Avoid difficult reading material.(q_316) O3 Carry conversation higher level. (q_492) O4 Spend time reflecting things. (q_1738) O5 probe deeply subject. (q_1964) gender (Male=1, Female=2) education (1=HS, 2=finished_HS, 3=some_college, 4=college_graduate 5=graduate_degree) age age years","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/makeCorrLoadings_validate.html","id":"second-target-correlation-matrix","dir":"Articles","previous_headings":"Study #2: Big Five (bfi personality items)","what":"Second target correlation matrix","title":"makeCorrLoadings() validation","text":"correlations among 25 items reproducable makeCorrLoadings() function.","code":"## download data data(bfi) ## filter for highly-educated women bfi_short <- bfi |>   filter(education == 5 & gender == 2) |>   na.omit() ## keep just the 25 items bfi_short <- bfi_short[, 1:25] sampleSize <- nrow(bfi_short) ## derive correlation matrix bfi_cor <- cor(bfi_short)"},{"path":"https://winzarh.github.io/LikertMakeR/articles/makeCorrLoadings_validate.html","id":"test-cases-and-evaluation","dir":"Articles","previous_headings":"Study #2: Big Five (bfi personality items) > Second target correlation matrix","what":"Test cases and Evaluation","title":"makeCorrLoadings() validation","text":"first study, shall produce following options factor correlation reporting: Full information Full information - uniquenesses Rounded loadings Rounded loadings - uniquenesses Censored loadings Censored loadings - uniqueness Censored loadings - uniqueness factor cors , first study, compare True correlation matrix Synthetic matrix, employing Jennrich test.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/makeCorrLoadings_validate.html","id":"exploratory-factor-analysis-1","dir":"Articles","previous_headings":"Study #2: Big Five (bfi personality items)","what":"Exploratory Factor Analysis","title":"makeCorrLoadings() validation","text":"Five correlated factors appropriate sample, use promax rotation.","code":"## factor analysis from `rosetta` package is a less messy version of the `psych::fa()` function  fa_bfi <- rosetta::factorAnalysis(   data = bfi_short,   nfactors = 5,   rotate = \"promax\" )  bfiLoadings <- fa_bfi$output$loadings bfiCorrs <- fa_bfi$output$correlations"},{"path":[]},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/articles/makeCorrLoadings_validate.html","id":"test-case-1-full-information-1","dir":"Articles","previous_headings":"Study #2: Big Five (bfi personality items)","what":"Test Case #1: Full information","title":"makeCorrLoadings() validation","text":"","code":"## round input values to 5 decimal places # factor loadings fl1 <- bfiLoadings[, 1:5] |>   round(5) |>   as.matrix() # item uniquenesses un1 <- bfiLoadings[, 6] |> round(5) # factor correlations fc1 <- round(bfiCorrs, 5) |> as.matrix() # run makeCorrLoadings() function itemCors_1 <- makeCorrLoadings(   loadings = fl1,   factorCor = fc1,   uniquenesses = un1 ) ## Compare the two matrices chiSq_1 <- cortest.jennrich(   R1 = bfi_cor, R2 = itemCors_1,   n1 = sampleSize, n2 = sampleSize )"},{"path":"https://winzarh.github.io/LikertMakeR/articles/makeCorrLoadings_validate.html","id":"other-test-cases-as-for-the-first-study","dir":"Articles","previous_headings":"Study #2: Big Five (bfi personality items)","what":"Other test cases as for the first study","title":"makeCorrLoadings() validation","text":"remaining test cases first study last test case. Changes made number decimal places considered, presence uniquenesses, presence factor correlation matrix, level item-factor loading included.","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/articles/makeCorrLoadings_validate.html","id":"overall-results","dir":"Articles","previous_headings":"","what":"Overall Results","title":"makeCorrLoadings() validation","text":"studies show consistent results.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/articles/makeCorrLoadings_validate.html","id":"conclusions","dir":"Articles","previous_headings":"Overall Results","what":"Conclusions","title":"makeCorrLoadings() validation","text":"makeCorrLoadings() function designed produce item correlation matrix based item-factor loadings factor correlations one might see results Exploratory Factor Analysis (EFA) Structural Equation Modelling (SEM). Results study suggest makeCorrLoadings() function surprisingly good job reproducing target correlation matrix item-factor loadings present. correlation matrix created makeCorrLoadings() seems robust even absence specified uniquenesses, even without factor correlations. valid reproduction correlation matrix complete item-factor loadings.","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Hume Winzar. Maintainer, author.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Winzar H (2025). LikertMakeR: Synthesise Correlate Likert Scale Rating-Scale Data Based Summary Statistics. R package version 1.3.0, https://github.com/WinzarH/LikertMakeR.","code":"@Manual{,   title = {LikertMakeR: Synthesise and Correlate Likert Scale and Rating-Scale Data Based on Summary Statistics},   author = {Hume Winzar},   year = {2025},   note = {R package version 1.3.0},   url = {https://github.com/WinzarH/LikertMakeR}, }"},{"path":"https://winzarh.github.io/LikertMakeR/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to LikertMakeR","title":"Contributing to LikertMakeR","text":"outlines propose change LikertMakeR. detailed discussion contributing tidyverse packages, please see development contributing guide code review principles.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/CONTRIBUTING.html","id":"fixing-typos","dir":"","previous_headings":"","what":"Fixing typos","title":"Contributing to LikertMakeR","text":"can fix typos, spelling mistakes, grammatical errors documentation directly using GitHub web interface, long changes made source file. generally means ’ll need edit roxygen2 comments .R, .Rd file. can find .R file generates .Rd reading comment first line.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/CONTRIBUTING.html","id":"bigger-changes","dir":"","previous_headings":"","what":"Bigger changes","title":"Contributing to LikertMakeR","text":"want make bigger change, ’s good idea first file issue make sure someone team agrees ’s needed. ’ve found bug, please file issue illustrates bug minimal reprex (also help write unit test, needed). See guide create great issue advice.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/CONTRIBUTING.html","id":"pull-request-process","dir":"","previous_headings":"Bigger changes","what":"Pull request process","title":"Contributing to LikertMakeR","text":"Fork package clone onto computer. haven’t done , recommend using usethis::create_from_github(\"WinzarH/LikertMakeR\", fork = TRUE). Install development dependencies devtools::install_dev_deps(), make sure package passes R CMD check running devtools::check(). R CMD check doesn’t pass cleanly, ’s good idea ask help continuing. Create Git branch pull request (PR). recommend using usethis::pr_init(\"brief-description--change\"). Make changes, commit git, create PR running usethis::pr_push(), following prompts browser. title PR briefly describe change. body PR contain Fixes #issue-number. user-facing changes, add bullet top NEWS.md (.e. just first header). Follow style described https://style.tidyverse.org/news.html.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/CONTRIBUTING.html","id":"code-style","dir":"","previous_headings":"Bigger changes","what":"Code style","title":"Contributing to LikertMakeR","text":"New code follow tidyverse style guide. can use styler package apply styles, please don’t restyle code nothing PR. use roxygen2, Markdown syntax, documentation. use testthat unit tests. Contributions test cases included easier accept.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Contributing to LikertMakeR","text":"Please note LikertMakeR project released Contributor Code Conduct. contributing project agree abide terms.","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"likertmaker-","dir":"","previous_headings":"","what":"LikertMakeR","title":"LikertMakeR","text":"(V 1.3.0 October 2025) Synthesise correlate Likert scales, similar rating-scale data, predefined first & second moments (mean standard deviation), Cronbach’s Alpha, Factor Loadings, summary statistics.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"purpose","dir":"","previous_headings":"","what":"Purpose","title":"LikertMakeR","text":"package intended : “Reproducing” “Reverse-engineering” rating-scale data analysis visualisation summary statistics reported, Teaching. Create data known properties without need find gather original data. Helping researchers students better understand relationships among scale properties, sample size, number items, etc. … checking feasibility scale moments given scale correlation properties.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"functions","dir":"","previous_headings":"","what":"Functions","title":"LikertMakeR","text":"Functions version LikertMakeR : lfast() applies simple Evolutionary Algorithm, based repeated random samples scaled Beta distribution, approximate predefined first second moments. lcor() rearranges values columns dataframe correlated match predefined correlation matrix. makeCorrAlpha constructs random item correlation matrix given dimensions predefined Cronbach’s Alpha. makeScales() wrapper function lfast() lcor() generate synthetic rating-scale data predefined first second moments predefined correlation matrix. makeCorrLoadings constructs item correlation matrix based factor loadings factor correlations might reported Exploratory Factor Analysis (EFA) Structural Equation Modelling (SEM). makeItemsScale() Generate dataframe rating scale items summative scale desired Cronbach’s Alpha. makePaired() Generate dataset paired-sample t-test summary statistics. makeRepeated() Generate dataset summary statistics repeated-measures ANOVA, options correlation structure diagnostics. makeScalesRegression() Generate synthetic rating-scale data replicate reported regression results. correlateScales() generates multidimensional dataframe combining several dataframes rating-scale items summated scales correlated according predefined correlation matrix.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"helper-functions","dir":"","previous_headings":"Functions","what":"Helper functions","title":"LikertMakeR","text":"alpha() calculates Cronbach’s Alpha given correlation matrix given dataframe eigenvalues() calculates eigenvalues correlation matrix, reports positive-definite status matrix , optionally, displays scree plot visualise eigenvalues","code":""},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"rating-scale-properties","dir":"","previous_headings":"","what":"Rating scale properties","title":"LikertMakeR","text":"Likert scale mean, sum, several ordinal rating scales. bipolar (usually “agree-disagree”) responses propositions determined moderately--highly correlated among , capturing various facets theoretical construct. Summated rating scales continuous unbounded. example, 5-point Likert scale constructed , say, five items (questions) summed range 5 (rated ‘1’) 25 (rated ‘5’) integers , mean range ‘1’ ‘5’ intervals 1/5=0.20. 7-point Likert scale constructed eight items summed range 8 (rated ‘1’) 56 (rated ‘7’) integers , mean range ‘1’ ‘7’ intervals 1/8=0.125. Technically, Likert scales, similar rating scales upper lower bounds measured discrete intervals, parametric statistics (mean, standard deviation, correlation) applied summated rating scales. practice, however, parametric statistics commonly used social sciences : common usage easily understood, practice, measures bounded constraints measurement tool, meaning also upper lower boundaries discrete units measurement, means : results conclusions drawn technically-correct non-parametric statistics (almost) always parametric statistics data. D’Alessandro et al. (2020) argue summated scale, made multiple items, “approaches” interval scale measure. Likert-scale items, responses single 1--5 agree-disagree question, analysed professional responsible researchers. much random error single item. Rensis Likert (1932) designed scale logic random overstatement one item likely compensated random understatement another item, , multiple items combined, get reasonably consistent, internally reliable, measure target construct.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"alternative-approaches-to-synthesising-scales","dir":"","previous_headings":"Rating scale properties","what":"Alternative approaches to synthesising scales","title":"LikertMakeR","text":"Typically, researcher synthesise simple rating-scale data sampling predetermined probability distribution. example, following code generate vector values single Likert-scale item, approximately given probabilities. approach good testing Likert items help working complete Likert scales, want specify means standard deviations might reported published research. function lfast() allows user specify exact univariate statistics might ordinarily reported. lcor() take multiple scales created lfast() rearrange values vectors correlated. makeCorrAlpha() generates correlation matrix predefined Cronbach’s Alpha(), enabling user apply makeScales() generate scale items summated scales produce exact Cronbach’s Alpha. makeCorrLoadings() generates correlation matrix factor loadings data, enabling user apply makeScales() generate multidimensional data. makeScales() generate synthetic rating-scale items summated scales predefined first second moments predefined correlation matrix. makeItemsScale() generate dataframe rating scale items summative scale desired Cronbach’s Alpha. correlateScales() generates multidimensional dataframe combining several dataframes rating-scale items summated scales correlated according predefined correlation matrix.","code":"n <- 128       sample(1:5, n, replace = TRUE,         prob = c(0.1, 0.2, 0.4, 0.2, 0.1)       )"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"install-likertmaker","dir":"","previous_headings":"","what":"Install LikertMakeR","title":"LikertMakeR","text":"download install package, run following code R console. CRAN: latest development version available author’s GitHub repository.","code":"install.packages('LikertMakeR') library(devtools)  install_github(\"WinzarH/LikertMakeR\")"},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"lfast","dir":"","previous_headings":"Generate synthetic rating scales","what":"lfast()","title":"LikertMakeR","text":"lfast() generates vector synthetic values predefined first second moments. accurate two decimal places.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"lfast-usage","dir":"","previous_headings":"Generate synthetic rating scales > lfast()","what":"lfast() usage","title":"LikertMakeR","text":"","code":"lfast(n, mean, sd, lowerbound, upperbound, items = 1, precision = 0)"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"lfast-arguments","dir":"","previous_headings":"Generate synthetic rating scales > lfast() > lfast() usage","what":"lfast arguments","title":"LikertMakeR","text":"n: sample size mean: desired mean sd: desired standard deviation lowerbound: desired lower bound (e.g. ‘1’ 1-5 rating scale) upperbound: desired upper bound (e.g. ‘5’ 1-5 rating scale) items: number items making scale. Default = ‘1’ precision: can relax level accuracy moments. Default = ‘0’ typically gives accuracy two decimal places.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"lfast-example-a-five-item-seven-point-likert-scale","dir":"","previous_headings":"Generate synthetic rating scales > lfast()","what":"lfast() Example: a five-item, seven-point Likert scale","title":"LikertMakeR","text":"","code":"x <- lfast(    n = 128,     mean = 4.5,     sd = 1.0,     lowerbound = 1,     upperbound = 7,     items = 5    )"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"lfast-example-a-four-item-seven-point-likert-scale-with-negative-to-positive-scores","dir":"","previous_headings":"Generate synthetic rating scales > lfast()","what":"lfast() Example: a four-item, seven-point Likert scale with negative-to-positive scores","title":"LikertMakeR","text":"","code":"x <- lfast(    n = 128,     mean = 1.0,     sd = 1.0,     lowerbound = -3,     upperbound = 3,     items = 4    )"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"lfast-example-a-four-item-five-point-likert-scale-with-moderate-precision","dir":"","previous_headings":"Generate synthetic rating scales > lfast()","what":"lfast() Example: a four-item, five-point Likert scale with moderate precision","title":"LikertMakeR","text":"","code":"x <- lfast(    n = 256,     mean = 3.25,     sd = 1.0,     lowerbound = 1,     upperbound = 5,     items = 5,    precision = 4    )"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"lfast-example-an-11-point-likelihood-of-purchase-scale","dir":"","previous_headings":"Generate synthetic rating scales > lfast()","what":"lfast() Example: an 11-point likelihood-of-purchase scale","title":"LikertMakeR","text":"","code":"x <- lfast(256, 2.5, 2.5, 0, 10)"},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"lcor","dir":"","previous_headings":"Correlating vectors of synthetic rating scales","what":"lcor()","title":"LikertMakeR","text":"function, lcor(), rearranges values columns data set correlated specified level.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"note","dir":"","previous_headings":"Correlating vectors of synthetic rating scales > lcor()","what":"NOTE","title":"LikertMakeR","text":"lcor() change values data frame - swaps positions column univariate statistics change, correlations columns .","code":""},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"lcor-usage","dir":"","previous_headings":"Correlating vectors of synthetic rating scales > lcor()","what":"lcor() usage","title":"LikertMakeR","text":"","code":"lcor(data, target, passes = 10)"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"lcor-arguments","dir":"","previous_headings":"Correlating vectors of synthetic rating scales > lcor() > lcor() usage","what":"lcor() arguments","title":"LikertMakeR","text":"data: starter data set ‘k’ rating-scales presented ‘k’ columns target: target correlation matrix: ‘k’*‘k’ correlation matrix passes: number value swap passes apply creating correlated data. Increasing number MAY improve accuracy number columns large. Decreasing number faster, MAY less accurate.","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"generate-synthetic-data","dir":"","previous_headings":"Correlating vectors of synthetic rating scales > lcor() Example #1","what":"generate synthetic data","title":"LikertMakeR","text":"","code":"n <- 64  x1 <- lfast(n, 3.5, 1.00, 1, 5, 5)   x2 <- lfast(n, 2.0, 0.85, 1, 5, 5)   x3 <- lfast(n, 3.0, 1.70, 1, 5, 5)   x4 <- lfast(n, 2.5, 1.50, 1, 5, 5)       mydat4 <- data.frame(x1, x2, x3, x4)     head(mydat4)  cor(mydat4) |> round(3) ## random independent data with low correlations"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"define-a-target-correlation-matrix","dir":"","previous_headings":"Correlating vectors of synthetic rating scales > lcor() Example #1","what":"Define a target correlation matrix","title":"LikertMakeR","text":"","code":"tgt4 <- matrix(  c(    1.00, 0.55, 0.60, 0.75,    0.55, 1.00, 0.25, 0.65,    0.60, 0.25, 1.00, 0.80,    0.75, 0.65, 0.80, 1.00  ),  nrow = 4  )"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"lcor-application","dir":"","previous_headings":"Correlating vectors of synthetic rating scales > lcor() Example #1","what":"lcor() application","title":"LikertMakeR","text":"","code":"new4 <- lcor(data = mydat4, target = tgt4)    cor(new4) |> round(3)  ## same data rearranged to be close to target"},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"three-starting-columns-and-a-different-target-correlation-matrix","dir":"","previous_headings":"Correlating vectors of synthetic rating scales > lcor() example #2","what":"three starting columns and a different target correlation matrix","title":"LikertMakeR","text":"","code":"mydat3 <- data.frame(x1, x2, x3)    tgt3 <- matrix(    c(       1.00, -0.50, -0.85,      -0.50,  1.00,  0.60,      -0.85,  0.60,  1.00    ),    nrow = 3  )"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"apply-lcor","dir":"","previous_headings":"Correlating vectors of synthetic rating scales > lcor() example #2","what":"Apply lcor()","title":"LikertMakeR","text":"","code":"new3 <- lcor(mydat3, tgt3)     cor(new3) |> round(3)"},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"makecorralpha","dir":"","previous_headings":"Generate a correlation matrix from Cronbach’s Alpha","what":"makeCorrAlpha()","title":"LikertMakeR","text":"makeCorrAlpha(), constructs random correlation matrix given dimensions predefined Cronbach’s Alpha.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"makecorralpha-usage","dir":"","previous_headings":"Generate a correlation matrix from Cronbach’s Alpha > makeCorrAlpha()","what":"makeCorrAlpha() usage","title":"LikertMakeR","text":"","code":"makeCorrAlpha(items, alpha, variance = 0.5, precision = 0)"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"makecorralpha-arguments","dir":"","previous_headings":"Generate a correlation matrix from Cronbach’s Alpha > makeCorrAlpha() > makeCorrAlpha() usage","what":"makeCorrAlpha() arguments","title":"LikertMakeR","text":"items: ‘k’, dimensions (number rows & columns) desired correlation matrix alpha: target Cronbach’s Alpha (usually positive, must greater ‘-1’ less ‘+1’) variance: standard deviation values sampled normally-distributed log transformation. Default = ‘0.5’. value ‘0’ makes values correlation matrix , equal mean correlation needed produce desired Alpha. value ‘2’, , risks producing matrix positive-definite, feasible. precision: value ‘0’ ‘3’ add random variation around target Cronbach’s Alpha. Default = ‘0’. value ‘0’ produces desired Alpha, generally exact two decimal places. Higher values produce increasingly random values around desired Alpha.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"note-1","dir":"","previous_headings":"Generate a correlation matrix from Cronbach’s Alpha > makeCorrAlpha()","what":"NOTE","title":"LikertMakeR","text":"Random values generated makeCorrAlpha() volatile. cases, makeCorrAlpha() may generate feasible (positive-definite) correlation matrix, especially variance high relative desired Alpha, desired correlation dimensions (number items) makeCorrAlpha() inform user resulting correlation matrix positive definite, . returned correlation matrix positive-definite, solutions volatile, feasible solution still may possible, often . user encouraged try , possibly several times, find one.","code":""},{"path":[]},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"define-parameters","dir":"","previous_headings":"Generate a correlation matrix from Cronbach’s Alpha > four variables, Alpha = 0.85","what":"define parameters","title":"LikertMakeR","text":"apply makeCorrAlpha() function test output Helper functions","code":"items <- 4 alpha <- 0.85 cor_matrix_4 <- makeCorrAlpha(items, alpha, variance) alpha(cor_matrix_4) eigenvalues(cor_matrix_4, 1)"},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"define-parameters-1","dir":"","previous_headings":"Generate a correlation matrix from Cronbach’s Alpha > four variables, Alpha = 0.85 > eight variables, Alpha = 0.95, larger variance","what":"define parameters","title":"LikertMakeR","text":"apply makeCorrAlpha() function test output","code":"items <- 8 alpha <- 0.95 variance <- 1.0 cor_matrix_8 <- makeCorrAlpha(items, alpha, variance) alpha(cor_matrix_8) eigenvalues(cor_matrix_8, 1)"},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"define-parameters-2","dir":"","previous_headings":"Generate a correlation matrix from Cronbach’s Alpha > four variables, Alpha = 0.85 > repeated with random variation around Alpha","what":"define parameters","title":"LikertMakeR","text":"apply makeCorrAlpha() function test output","code":"precision <- 2 cor_matrix_8a <- makeCorrAlpha(items, alpha, variance, precision) alpha(cor_matrix_8a) eigenvalues(cor_matrix_8a, 1)"},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"makecorrloadings","dir":"","previous_headings":"Generate a correlation matrix from factor loadings","what":"makeCorrLoadings","title":"LikertMakeR","text":"makeCorrLoadings() generates correlation matrix factor loadings factor correlations might seen Exploratory Factor Analysis (EFA) Structural Equation Model (SEM).","code":""},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"makecorrloadings-usage","dir":"","previous_headings":"Generate a correlation matrix from factor loadings > makeCorrLoadings","what":"makeCorrLoadings() usage","title":"LikertMakeR","text":"","code":"makeCorrLoadings(loadings, factorCor = NULL, uniquenesses = NULL, nearPD = FALSE)"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"makecorrloadings-arguments","dir":"","previous_headings":"Generate a correlation matrix from factor loadings > makeCorrLoadings > makeCorrLoadings() usage","what":"makeCorrLoadings() arguments","title":"LikertMakeR","text":"loadings: ‘k’ (items) ‘f’ (factors) matrix standardised factor loadings. Item names Factor names can taken row_names (items) column_names (factors), present. factorCor: ‘f’ x ‘f’ factor correlation matrix. present, assume factors uncorrelated (orthogonal), rare practice, function applies identity matrix factorCor. uniquenesses: length ‘k’ vector uniquenesses. NULL, default, compute calculated communalities. nearPD: (logical) TRUE, function calls nearPD() function Matrix package transform resulting correlation matrix onto nearest Positive Definite matrix. Obviously, applies resulting correlation matrix positive definite. (never needed.)","code":""},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"note-2","dir":"","previous_headings":"Generate a correlation matrix from factor loadings > makeCorrLoadings > makeCorrLoadings() usage","what":"Note","title":"LikertMakeR","text":"“Censored” loadings, loadings less small value (often ‘0.30’) removed ease--communication, tend severely reduce accuracy makeCorrLoadings() function. detailed demonstration, see file, makeCorrLoadings_Validate.pdf package website GitHub.","code":""},{"path":[]},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"define-parameters-3","dir":"","previous_headings":"Generate a correlation matrix from factor loadings > makeCorrLoadings() examples > Typical application from published EFA results","what":"define parameters","title":"LikertMakeR","text":"Example loadings row column names Factor correlation matrix","code":"factorLoadings <- matrix(   c(       0.05, 0.20, 0.70,       0.10, 0.05, 0.80,       0.05, 0.15, 0.85,       0.20, 0.85, 0.15,       0.05, 0.85, 0.10,       0.10, 0.90, 0.05,       0.90, 0.15, 0.05,       0.80, 0.10, 0.10    ),    nrow = 8, ncol = 3, byrow = TRUE ) rownames(factorLoadings) <- c(\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\", \"Q6\", \"Q7\", \"Q8\") colnames(factorLoadings) <- c(\"Factor1\", \"Factor2\", \"Factor3\") factorCor <- matrix( c(   1.0,  0.5, 0.4,   0.5,  1.0, 0.3,   0.4,  0.3, 1.0  ), nrow = 3, byrow = TRUE )"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"apply-the-function","dir":"","previous_headings":"Generate a correlation matrix from factor loadings > makeCorrLoadings() examples > Typical application from published EFA results","what":"Apply the function","title":"LikertMakeR","text":"","code":"itemCorrelations <- makeCorrLoadings(factorLoadings, factorCor)  round(itemCorrelations, 3)"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"assuming-orthogonal-factors","dir":"","previous_headings":"Generate a correlation matrix from factor loadings > makeCorrLoadings() examples","what":"Assuming orthogonal factors","title":"LikertMakeR","text":"","code":"itemCors <- makeCorrLoadings(factorLoadings)  round(itemCors, 3)"},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"makescales","dir":"","previous_headings":"Generate a dataframe of rating scales from a correlation matrix and predefined moments","what":"makeScales()","title":"LikertMakeR","text":"makeScales() generates dataframe two rating-scale items, summated rating scales, correlated close predefined correlation matrix. makeScales() wrapper function : lfast(), generates vector random discrete values scaled Beta distribution best fits desired moments, lcor(), rearranges values column dataframe closely match desired correlation matrix.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"makescales-usage","dir":"","previous_headings":"Generate a dataframe of rating scales from a correlation matrix and predefined moments > makeScales()","what":"makeScales() usage","title":"LikertMakeR","text":"","code":"makeItems(n, means, sds, lowerbound, upperbound, items, cormatrix)"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"makeitems-arguments","dir":"","previous_headings":"Generate a dataframe of rating scales from a correlation matrix and predefined moments > makeScales()","what":"makeItems() arguments","title":"LikertMakeR","text":"n: number observations generate. means: target means: vector length ‘k’ mean values scale. sds: target standard deviations: vector length ‘k’ standard deviation values scale. lowerbound: vector length ‘k’ (rows & columns correlation matrix) values lower bound scale (e.g. ‘1’ 1-5 rating scale). Default = ‘1’. upperbound: vector length ‘k’ values upper bound scale (e.g. ‘5’ 1-5 rating scale). Default = ‘5’. items: vector length ‘k’ number items scale. Default = ‘1’. cormatrix: target correlation matrix: ‘k’ x ‘k’ square symmetric matrix values ranging ‘-1 ’’+1’, ‘1’ diagonal.","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"define-parameters-4","dir":"","previous_headings":"Generate a dataframe of rating scales from a correlation matrix and predefined moments > makeScales() examples","what":"define parameters","title":"LikertMakeR","text":"","code":"n <- 128 dfMeans <- c(2.5, 3.0, 3.0, 3.5) dfSds <- c(1.0, 1.0, 1.5, 0.75) lowerbound <- rep(1, 4) upperbound <- rep(5, 4) items <- c(5, 5, 4, 4)  corMat <- matrix( c(  1.00, 0.25, 0.35, 0.40,  0.25, 1.00, 0.70, 0.75,  0.35, 0.70, 1.00, 0.80,  0.40, 0.75, 0.80, 1.00  ),  nrow = 4, ncol = 4 )"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"apply-function","dir":"","previous_headings":"Generate a dataframe of rating scales from a correlation matrix and predefined moments > makeScales() examples","what":"apply function","title":"LikertMakeR","text":"","code":"df <- makeScales(    n = n,    means = dfMeans,    sds = dfSds,    lowerbound = lowerbound,    upperbound = upperbound,    items = items,    cormatrix = corMat  )"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"test-function","dir":"","previous_headings":"Generate a dataframe of rating scales from a correlation matrix and predefined moments > makeScales() examples","what":"test function","title":"LikertMakeR","text":"","code":"str(df)  dfmoments <- data.frame(   mean = apply(df, 2, mean) |> round(3),   sd = apply(df, 2, sd) |> round(3) ) |> t()  dfmoments  cor(df) |> round(3)"},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"makeitemsscale","dir":"","previous_headings":"Generate a dataframe of rating-scale items from a summated rating scale","what":"makeItemsScale()","title":"LikertMakeR","text":"makeItemsScale() generates dataframe rating-scale items summated rating scale desired Cronbach’s Alpha.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"makeitemsscale-usage","dir":"","previous_headings":"Generate a dataframe of rating-scale items from a summated rating scale > makeItemsScale()","what":"makeItemsScale() usage","title":"LikertMakeR","text":"","code":"makeItemsScale(scale, lowerbound, upperbound, items,  alpha = 0.8, variance = 0.5)"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"makeitemsscale-arguments","dir":"","previous_headings":"Generate a dataframe of rating-scale items from a summated rating scale > makeItemsScale()","what":"makeItemsScale() arguments","title":"LikertMakeR","text":"scale: vector dataframe summated rating scale. range (‘lowerbound’ * ‘items’) (‘upperbound’ * ‘items’) lowerbound: lower bound scale item (example: ‘1’ ‘1’ ‘5’ rating) upperbound: upper bound scale item (example: ‘5’ ‘1’ ‘5’ rating) items: k, number columns generate alpha: desired Cronbach’s Alpha. Default = ‘0.8’ variance: quantile selecting combination items give summated scores. Must lie ‘0’ (minimum variance) ‘1’ (maximum variance). Default = ‘0.5’.","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"generate-a-summated-scale","dir":"","previous_headings":"Generate a dataframe of rating-scale items from a summated rating scale > makeItemsScale() > makeItemsScale() Example:","what":"generate a summated scale","title":"LikertMakeR","text":"","code":"n <- 64 mean <- 3.5 sd <- 1.00 lowerbound <- 1 upperbound <- 5 items <- 4  meanScale <- lfast(   n = n, mean = mean, sd = sd,   lowerbound = lowerbound, upperbound = upperbound,   items = items  )  summatedScale <- meanScale * items"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"create-items-with-makeitemsscale","dir":"","previous_headings":"Generate a dataframe of rating-scale items from a summated rating scale > makeItemsScale()","what":"create items with makeItemsScale()","title":"LikertMakeR","text":"","code":"newItems_1 <- makeItemsScale(   scale = summatedScale,   lowerbound = lowerbound,    upperbound = upperbound,   items = items )  cor(newItems_1) |> round(2) alpha(data = newItems_1) eigenvalues(cor(newItems_1), 1)"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"makeitemsscale-with-same-summated-values-and-higher-alpha","dir":"","previous_headings":"Generate a dataframe of rating-scale items from a summated rating scale > makeItemsScale()","what":"makeItemsScale() with same summated values and higher alpha","title":"LikertMakeR","text":"","code":"newItems_2 <- makeItemsScale(   scale = summatedScale,   lowerbound = lowerbound,    upperbound = upperbound,   items = items,   alpha = 0.9 )  cor(newItems_2) |> round(2) alpha(data = newItems_2) eigenvalues(cor(newItems_2), 1)"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"same-summated-values-with-lower-alpha-that-may-require-higher-variance","dir":"","previous_headings":"Generate a dataframe of rating-scale items from a summated rating scale > makeItemsScale()","what":"same summated values with lower alpha that may require higher variance","title":"LikertMakeR","text":"","code":"newItems_3 <- makeItemsScale(   scale = summatedScale,   lowerbound = lowerbound,    upperbound = upperbound,   items = items,   alpha = 0.6,   variance = 0.7 )     cor(newItems_3) |> round(2) alpha(data = newItems_3) eigenvalues(cor(newItems_3), 1)"},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"makepaired","dir":"","previous_headings":"Create a dataframe for paired-sample t-test","what":"makePaired()","title":"LikertMakeR","text":"makePaired() generates dataset paired-sample t-test summary statistics. makePaired() generates correlated values data replicate rating scales taken paired-samples t-test - example, experimental design. function effectively wrapper function lfast() lcor() addition t-statistic -column correlation inferred. Paired t-tests apply observations associated . example: people treatment; people rating two different objects; ratings husband & wife; etc.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"makepaired-usage","dir":"","previous_headings":"Create a dataframe for paired-sample t-test > makePaired()","what":"makePaired() usage","title":"LikertMakeR","text":"","code":"makePaired(n, means, sds, t_value, lowerbound, upperbound, items = 1, precision = 0)"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"makepaired-arguments","dir":"","previous_headings":"Create a dataframe for paired-sample t-test > makePaired()","what":"makePaired() arguments","title":"LikertMakeR","text":"n sample size means [1:2] vector target means two /measures sds [1:2] vector target standard deviations t_value desired paired t-statistic lowerbound lower bound (e.g. ‘1’ 1-5 rating scale) upperbound upper bound (e.g. ‘5’ 1-5 rating scale) items number items rating scale. Default = 1 precision can relax level accuracy required. Default = 0, generally gives results correct within two decimal places. value ‘1’ generally creates vector moments correct within ‘0.025’; ‘2’ generally within ‘0.05’.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"makepaired-examples","dir":"","previous_headings":"Create a dataframe for paired-sample t-test > makePaired()","what":"makePaired() examples","title":"LikertMakeR","text":"","code":"n <- 20 means <- c(2.5, 3.0) sds <- c(1.0, 1.5) lowerbound <- 1 upperbound <- 5 items <- 6 t <- -2.5  pairedDat <- makePaired(n = n, means = means, sds = sds, t_value = t, lowerbound = lowerbound, upperbound = upperbound, items = items)  str(pairedDat) cor(pairedDat) |> round(2) pairedMoments <- data.frame(   mean = apply(newDat, MARGIN = 2, FUN = mean) |> round(3),   sd = apply(newDat, MARGIN = 2, FUN = sd) |> round(3) ) |> t() pairedMoments  t.test(pairedDat$X1, pairedDat$X2, paired = TRUE)"},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"makerepeated","dir":"","previous_headings":"Create a dataframe for Repeated-Measures ANOVA","what":"makeRepeated()","title":"LikertMakeR","text":"makeRepeated() constructs synthetic dataset inter-timepoint correlation matrix repeated-measures ANOVA result, based reported means, standard deviations, F-statistic. function estimates average correlation repeated measures matching reported F-statistic, one three assumed correlation structures: \"cs\" (Compound Symmetry): Compound Symmetry assumes repeated measures equally correlated . , correlation time 1 time 2 time 1 time 3, . structure commonly used repeated-measures ANOVA default. ’s mathematically simple reflects idea timepoints equally related. However, may realistic data correlations decrease time intervals increase (e.g., memory decay learning effects). \"ar1\" (First-Order Autoregressive): first-order autoregressive, assumes measurements closer together time highly correlated apart. example, correlation time 1 time 2 stronger time 1 time 3. pattern often realistic longitudinal time-series studies change gradual. correlation drops exponentially time step. Use structure believe relationship repeated measures weakens steadily time. \"toeplitz\" (Linearly Decreasing): Toeplitz structure flexible option allows correlation measurements decrease linearly time gap increases. Unlike AR(1), decline exponential, Toeplitz structure assumes straight-line drop correlation. may useful studies changes across time gradual irregular, strictly exponential. ’s good middle ground neither compound symmetry AR(1) seems quite right.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"makerepeated-usage","dir":"","previous_headings":"Create a dataframe for Repeated-Measures ANOVA > makeRepeated()","what":"makeRepeated() usage","title":"LikertMakeR","text":"","code":"makeRepeated(   n,    k,    means,    sds,   f_stat,   df_between = k - 1,   df_within = (n - 1) * (k - 1),   structure = c(\"cs\", \"ar1\", \"toeplitz\"),   names = paste0(\"time_\", 1:k),   items = 1,   lowerbound = 1, upperbound = 5,   return_corr_only = FALSE,   diagnostics = FALSE,   ... )"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"makerepeated-arguments","dir":"","previous_headings":"Create a dataframe for Repeated-Measures ANOVA > makeRepeated()","what":"makeRepeated() arguments","title":"LikertMakeR","text":"n Integer. Sample size used original study. k Integer. Number repeated measures (timepoints). means Numeric vector length k. Mean values reported timepoint. sds Numeric vector length k. Standard deviations reported timepoint. f_stat Numeric. reported repeated-measures ANOVA F-statistic within-subjects factor. df_between, Degrees freedom conditions (default: k - 1). df_within, Degrees freedom within-subjects (default: (n - 1) * (k - 1)). structure Character. Correlation structure assume: \"cs\", \"ar1\", \"toeplitz\" (default). names Character vector length k. Variable names timepoint (default: \"time_1\" \"time_k\"). items Integer. Number items used generate scale score (passed lfast()). lowerbound, Integer. Lower bounds Likert-type response scales (default: 1). upperbound, Integer. upper bounds Likert-type response scales (default: 5). return_corr_only Logical. TRUE, return estimated correlation matrix. diagnostics Logical. TRUE, include diagnostic summaries feasible F-statistic range effect sizes.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"makerepeated-examples","dir":"","previous_headings":"Create a dataframe for Repeated-Measures ANOVA > makeRepeated()","what":"makeRepeated() examples","title":"LikertMakeR","text":"","code":"out1 <- makeRepeated(    n = 128,     k = 3,    means = c(3.1, 3.5, 3.9),    sds = c(1.0, 1.1, 1.0),    items = 4,    f_stat = 4.87,    structure = \"cs\",    diagnostics = FALSE  )    head(out1$data)  out1$correlation_matrix    out2 <- makeRepeated(    n = 32, k = 4,    means = c(2.75, 3.5, 4.0, 4.4),    sds = c(0.8, 1.0, 1.2, 1.0),    f_stat = 16,    structure = \"ar1\",    items = 5,    lowerbound = 1, upperbound = 7,    return_corr_only = FALSE,    diagnostics = TRUE  )   print(out2)    out3 <- makeRepeated(    n = 32, k = 4,    means = c(2.0, 2.5, 3.0, 2.8),    sds = c(0.8, 0.9, 1.0, 0.9),    items = 4,    f_stat = 24,    structure = \"toeplitz\",    diagnostics = TRUE  )   str(out3)"},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"makescalesregression","dir":"","previous_headings":"Generate rating-scale data that replicate reported regression results","what":"makeScalesRegression()","title":"LikertMakeR","text":"Generates synthetic rating-scale data replicates reported regression results: standardised betas, R2, correlation matrix independent variables (available).","code":""},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"makescalesregression-usage","dir":"","previous_headings":"Generate rating-scale data that replicate reported regression results > makeScalesRegression()","what":"makeScalesRegression() usage","title":"LikertMakeR","text":"","code":"makeScalesRegression <- (    n,  # sample size    beta_std,  # a vector of standardised betas    r_squared, # R_squared    iv_cormatrix = NULL,  # independent variables correlation matrix    iv_cor_mean = 0.3,  # if no iv_cormatrix average IV correlations     iv_cor_variance = 0.01, # if no iv_cormatrix, variation in iv_cormatrix    iv_cor_range = c(-0.7, 0.7), # if no iv_cormatrix, range in iv_cormatrix    iv_means, # a vector of IV mean values    iv_sds,  # a vector of IV sd's    dv_mean,  # mean of DV    dv_sd,  # sd of DV    lowerbound_iv,  # a vector of lowerbounds for IV's    upperbound_iv,  # a vector of upperbounds for IV's    lowerbound_dv,  # lowerbound for DV    upperbound_dv,  # upperbound for DV    items_iv = 1,  # a vector of number of items in the IV's    items_dv = 1,  # number of items in DV    var_names = NULL,  # a vector of variable names    tolerance = 0.005  # close to target R-squared )"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"makescalesregression-examples","dir":"","previous_headings":"Generate rating-scale data that replicate reported regression results > makeScalesRegression()","what":"makeScalesRegression() examples","title":"LikertMakeR","text":"","code":"# Example 1: With provided IV correlation matrix set.seed(123) iv_corr <- matrix(c(1.0, 0.3, 0.3, 1.0), nrow = 2)  result1 <- makeScalesRegression(   n = 64,   beta_std = c(0.4, 0.3),   r_squared = 0.35,   iv_cormatrix = iv_corr,   iv_means = c(3.0, 3.5),   iv_sds = c(1.0, 0.9),   dv_mean = 3.8,   dv_sd = 1.1,   lowerbound_iv = 1,   upperbound_iv = 5,   lowerbound_dv = 1,   upperbound_dv = 5,   items_iv = 4,   items_dv = 4,   var_names = c(\"Attitude\", \"Intention\", \"Behaviour\") )  print(result1) head(result1$data)  # Example 2: With optimisation (no IV correlation matrix) set.seed(456) result2 <- makeScalesRegression(   n = 64,   beta_std = c(0.3, 0.25, 0.2),   r_squared = 0.40,   iv_cormatrix = NULL, # Will be optimised   iv_cor_mean = 0.3,   iv_cor_variance = 0.02,   iv_means = c(3.0, 3.2, 2.8),   iv_sds = c(1.0, 0.9, 1.1),   dv_mean = 3.5,   dv_sd = 1.0,   lowerbound_iv = 1,   upperbound_iv = 5,   lowerbound_dv = 1,   upperbound_dv = 5,   items_iv = 4,   items_dv = 5 )  # View optimised correlation matrix print(result2$target_stats$iv_cormatrix) print(result2$optimisation_info)"},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"correlatescales","dir":"","previous_headings":"Create a multidimensional dataframe of scale items as we might see from a questionnaire","what":"correlateScales()","title":"LikertMakeR","text":"correlateScales() takes several dataframes rating-scale items rearranges rows scales correlated according predefined correlation matrix. Univariate statistics dataframe rating-scale items change, inter-item correlations within dataframe change, correlations rating-scale items dataframes change.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"correlatescales-usage","dir":"","previous_headings":"Create a multidimensional dataframe of scale items as we might see from a questionnaire > correlateScales()","what":"correlateScales() usage","title":"LikertMakeR","text":"","code":"correlateScales(dataframes, scalecors)"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"correlatescales-arguments","dir":"","previous_headings":"Create a multidimensional dataframe of scale items as we might see from a questionnaire > correlateScales()","what":"correlateScales() arguments","title":"LikertMakeR","text":"dataframes: list ‘k’ dataframes rearranged combined scalecors: target correlation matrix - symmetric k*k positive-semi-definite matrix, ‘k’ number dataframes","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"three-attitude-scales-each-of-three-items","dir":"","previous_headings":"Create a multidimensional dataframe of scale items as we might see from a questionnaire > correlateScales() > correlateScales() example","what":"three attitude scales, each of three items","title":"LikertMakeR","text":"","code":"n <- 64 lower <- 1 upper <- 5"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"attitude-1","dir":"","previous_headings":"","what":"LikertMakeR","title":"LikertMakeR","text":"","code":"cor_1 <- makeCorrAlpha(items = 3, alpha = 0.85) means_1 <- c(2.5, 2.5, 3.0) sds_1 <- c(0.9, 1.0, 1.0) Att_1 <- makeItems(   n, means_1, sds_1,   rep(lower, 4), rep(upper, 4),   cor_1 )"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"attitude-2","dir":"","previous_headings":"","what":"LikertMakeR","title":"LikertMakeR","text":"","code":"cor_2 <- makeCorrAlpha(items = 3, alpha = 0.80) means_2 <- c(2.5, 3.0, 3.5) sds_2 <- c(1.0, 1.5, 1.0) Att_2 <- makeItems(   n, means_2, sds_2,   rep(lower, 5), rep(upper, 5),   cor_2 )"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"attitude-3","dir":"","previous_headings":"","what":"LikertMakeR","title":"LikertMakeR","text":"","code":"cor_3 <- makeCorrAlpha(items = 3, alpha = 0.75) means_3 <- c(2.5, 3.0, 3.5) sds_3 <- c(1.0, 1.5, 1.0)  Att_3 <- makeItems(   n, means_3, sds_3,   rep(lower, 6), rep(upper, 6),   cor_3 )"},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"target-scale-correlation-matrix","dir":"","previous_headings":"","what":"LikertMakeR","title":"LikertMakeR","text":"","code":"scale_cors <- matrix(   c(     1.0, 0.6, 0.5,     0.6, 1.0, 0.4,      0.5, 0.4, 1.0   ),   nrow = 3 )"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"initial-data-frames","dir":"","previous_headings":"","what":"LikertMakeR","title":"LikertMakeR","text":"","code":"data_frames <- list(\"A1\" = Att_1, \"A2\" = Att_2, \"A3\" = Att_3)"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"apply-the-correlatescales-function","dir":"","previous_headings":"Create a multidimensional dataframe of scale items as we might see from a questionnaire > correlateScales() > correlateScales() example","what":"apply the correlateScales() function","title":"LikertMakeR","text":"","code":"my_correlated_scales <- correlateScales(   dataframes = data_frames,   scalecors = scale_cors )"},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"data-structure","dir":"","previous_headings":"","what":"LikertMakeR","title":"LikertMakeR","text":"","code":"str(my_correlated_scales)"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"inter-item-correlations","dir":"","previous_headings":"","what":"LikertMakeR","title":"LikertMakeR","text":"","code":"cor(my_correlated_scales) |> round(2)"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"eigenvalues-of-dataframe-correlations","dir":"","previous_headings":"","what":"LikertMakeR","title":"LikertMakeR","text":"","code":"eigenvalues(cormatrix = cor(my_correlated_scales), scree = TRUE) |>  round(2)"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"helper-functions-1","dir":"","previous_headings":"","what":"Helper functions","title":"LikertMakeR","text":"likertMakeR includes two additional functions may help examining parameters output. alpha() calculates Cronbach’s Alpha given correlation matrix given dataframe eigenvalues() calculates eigenvalues correlation matrix, reports whether correlation matrix positive definite optional scree plot","code":""},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"alpha","dir":"","previous_headings":"Helper functions","what":"alpha()","title":"LikertMakeR","text":"alpha() accepts, input, either correlation matrix data frame. submitted, correlation matrix used default, message effect.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"alpha-usage","dir":"","previous_headings":"Helper functions > alpha()","what":"alpha() usage","title":"LikertMakeR","text":"","code":"alpha(cormatrix = NULL, data = NULL)"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"alpha-arguments","dir":"","previous_headings":"Helper functions > alpha()","what":"alpha() arguments","title":"LikertMakeR","text":"cormatrix: correlation matrix examination: square symmetrical matrix values ranging ‘-1’ ‘+1’ ‘1’ diagonal data: data frame data matrix","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"sample-data-frame","dir":"","previous_headings":"Helper functions > alpha() > alpha() examples","what":"Sample data frame","title":"LikertMakeR","text":"","code":"df <- data.frame(  V1  =  c(4, 2, 4, 3, 2, 2, 2, 1),  V2  =  c(4, 1, 3, 4, 4, 3, 2, 3),  V3  =  c(4, 1, 3, 5, 4, 1, 4, 2),  V4  =  c(4, 3, 4, 5, 3, 3, 3, 3) )"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"example-correlation-matrix","dir":"","previous_headings":"Helper functions > alpha() > alpha() examples","what":"example correlation matrix","title":"LikertMakeR","text":"","code":"corMat <- matrix(  c(   1.00, 0.35, 0.45, 0.70,   0.35, 1.00, 0.60, 0.55,   0.45, 0.60, 1.00, 0.65,   0.70, 0.55, 0.65, 1.00  ),  nrow = 4, ncol = 4 )"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"apply-function-examples","dir":"","previous_headings":"Helper functions > alpha()","what":"apply function examples","title":"LikertMakeR","text":"","code":"alpha(cormatrix = corMat)  alpha(data = df)  alpha(NULL, df)  alpha(corMat, df)"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"eigenvalues","dir":"","previous_headings":"Helper functions","what":"eigenvalues()","title":"LikertMakeR","text":"eigenvalues() calculates eigenvalues correlation matrix, reports whether matrix positive-definite, optionally produces scree plot.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"eigenvalues-usage","dir":"","previous_headings":"Helper functions > eigenvalues()","what":"eigenvalues() usage","title":"LikertMakeR","text":"","code":"eigenvalues(cormatrix, scree = FALSE)"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"eigenvalues-arguments","dir":"","previous_headings":"Helper functions > eigenvalues()","what":"eigenvalues() arguments","title":"LikertMakeR","text":"cormatrix: correlation matrix. scree: (logical) default = FALSE. TRUE (1), eigenvalues() produces scree plot illustrate eigenvalues.","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"define-parameters-5","dir":"","previous_headings":"Helper functions > eigenvalues() examples","what":"define parameters","title":"LikertMakeR","text":"","code":"correlationMatrix <- matrix(  c(   1.00, 0.25, 0.35, 0.40,   0.25, 1.00, 0.70, 0.75,   0.35, 0.70, 1.00, 0.80,   0.40, 0.75, 0.80, 1.00  ),  nrow = 4, ncol = 4 )"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"apply-function-1","dir":"","previous_headings":"Helper functions > eigenvalues() examples","what":"apply function","title":"LikertMakeR","text":"","code":"evals <- eigenvalues(cormatrix = correlationMatrix)  print(evals)  evals <- eigenvalues(correlationMatrix, 1)  print(evals)"},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"apa","dir":"","previous_headings":"Helper functions > To cite LikertMakeR","what":"APA:","title":"LikertMakeR","text":"","code":"Winzar, H. (2022). LikertMakeR: Synthesise and correlate Likert-scale   and related rating-scale data with predefined first & second moments,   Version 1.2.0 (2025),  The Comprehensive R Archive Network (CRAN), <https://CRAN.R-project.org/package=LikertMakeR>"},{"path":"https://winzarh.github.io/LikertMakeR/index.html","id":"bib","dir":"","previous_headings":"Helper functions > To cite LikertMakeR","what":"BIB:","title":"LikertMakeR","text":"","code":"@software{winzar2022, title = {LikertMakeR: Synthesise and correlate Likert-scale  and related rating-scale data with predefined first & second moments}, author = {Hume Winzar}, abstract = {LikertMakeR synthesises Likert scale and related rating-scale data with predefined means and standard deviations, and optionally correlates these vectors to fit a predefined correlation matrix or Cronbach's Alpha.}, journal = {The Comprehensive R Archive Network (CRAN)}, month = {12}, year = {2022}, version = {1.2.0 (2025)} url = {https://CRAN.R-project.org/package=LikertMakeR}, }"},{"path":"https://winzarh.github.io/LikertMakeR/reference/alpha.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Cronbach's Alpha from a correlation matrix or dataframe — alpha","title":"Calculate Cronbach's Alpha from a correlation matrix or dataframe — alpha","text":"alpha() calculates Cronbach's Alpha given correlation matrix given dataframe.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/alpha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Cronbach's Alpha from a correlation matrix or dataframe — alpha","text":"","code":"alpha(cormatrix = NULL, data = NULL)"},{"path":"https://winzarh.github.io/LikertMakeR/reference/alpha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Cronbach's Alpha from a correlation matrix or dataframe — alpha","text":"cormatrix (real) square symmetrical matrix values ranging -1 +1 '1' diagonal data (real) dataframe matrix","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/alpha.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Cronbach's Alpha from a correlation matrix or dataframe — alpha","text":"single value","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/alpha.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Cronbach's Alpha from a correlation matrix or dataframe — alpha","text":"","code":"## Sample data frame df <- data.frame(   V1  =  c(4, 2, 4, 3, 2, 2, 2, 1),   V2  =  c(4, 1, 3, 4, 4, 3, 2, 3),   V3  =  c(4, 1, 3, 5, 4, 1, 4, 2),   V4  =  c(4, 3, 4, 5, 3, 3, 3, 3) )  ## example correlation matrix corMat <- matrix(   c(     1.00, 0.35, 0.45, 0.70,     0.35, 1.00, 0.60, 0.55,     0.45, 0.60, 1.00, 0.65,     0.70, 0.55, 0.65, 1.00   ),   nrow = 4, ncol = 4 )  ## apply function examples  alpha(cormatrix = corMat) #> [1] 0.8301887  alpha(, df) #> [1] 0.830008  alpha(corMat, df) #> Alert:  #> Both cormatrix and data present. #>                  #> Using cormatrix by default. #> [1] 0.8301887"},{"path":"https://winzarh.github.io/LikertMakeR/reference/correlateScales.html","id":null,"dir":"Reference","previous_headings":"","what":"Dataframe of correlated scales from different dataframes of scale items — correlateScales","title":"Dataframe of correlated scales from different dataframes of scale items — correlateScales","text":"correlateScales() creates dataframe scale items representing correlated constructs, one might find completed questionnaire.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/correlateScales.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dataframe of correlated scales from different dataframes of scale items — correlateScales","text":"","code":"correlateScales(dataframes, scalecors)"},{"path":"https://winzarh.github.io/LikertMakeR/reference/correlateScales.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dataframe of correlated scales from different dataframes of scale items — correlateScales","text":"dataframes list 'k' dataframes rearranged combined scalecors target correlation matrix - symmetric \\(k \\times k\\) positive-semi-definite matrix, 'k' number dataframes","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/correlateScales.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Dataframe of correlated scales from different dataframes of scale items — correlateScales","text":"Returns dataframe whose columns taken starter dataframes whose summated values correlated according user-specified correlation matrix","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/correlateScales.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Dataframe of correlated scales from different dataframes of scale items — correlateScales","text":"Correlated rating-scale items generally summed averaged create measure \"unobservable\", \"latent\", construct. correlateScales() takes several dataframes rating-scale items rearranges rows scales correlated according predefined correlation matrix. Univariate statistics dataframe rating-scale items change, correlations rating-scale items dataframes .","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/correlateScales.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dataframe of correlated scales from different dataframes of scale items — correlateScales","text":"","code":"## three attitudes and a behavioural intention n <- 32 lower <- 1 upper <- 5  ### attitude #1 cor_1 <- makeCorrAlpha(items = 4, alpha = 0.90) #> correlation values consistent with desired alpha in 9727 iterations #> The correlation matrix is positive definite #>  means_1 <- c(2.5, 2.5, 3.0, 3.5) sds_1 <- c(0.9, 1.0, 0.9, 1.0)  Att_1 <- makeItems(   n = n, means = means_1, sds = sds_1,   lowerbound = rep(lower, 4), upperbound = rep(upper, 4),   cormatrix = cor_1 ) #> Variable  1 #> reached maximum of 1024 iterations #> Variable  2 #> reached maximum of 1024 iterations #> Variable  3 #> reached maximum of 1024 iterations #> Variable  4 #> reached maximum of 1024 iterations #>  #> Arranging data to match correlations #>  #> Successfully generated correlated variables #>     ### attitude #2 cor_2 <- makeCorrAlpha(items = 5, alpha = 0.85) #> correlation values consistent with desired alpha in 7528 iterations #> The correlation matrix is positive definite #>  means_2 <- c(2.5, 2.5, 3.0, 3.0, 3.5) sds_2 <- c(1.0, 1.0, 0.9, 1.0, 1.5)  Att_2 <- makeItems(   n = n, means = means_2, sds = sds_2,   lowerbound = rep(lower, 5), upperbound = rep(upper, 5),   cormatrix = cor_2 ) #> Variable  1 #> reached maximum of 1024 iterations #> Variable  2 #> reached maximum of 1024 iterations #> Variable  3 #> reached maximum of 1024 iterations #> Variable  4 #> reached maximum of 1024 iterations #> Variable  5 #> reached maximum of 1024 iterations #>  #> Arranging data to match correlations #>  #> Successfully generated correlated variables #>     ### attitude #3 cor_3 <- makeCorrAlpha(items = 6, alpha = 0.75) #> correlation values consistent with desired alpha in 13699 iterations #> The correlation matrix is positive definite #>  means_3 <- c(2.5, 2.5, 3.0, 3.0, 3.5, 3.5) sds_3 <- c(1.0, 1.5, 1.0, 1.5, 1.0, 1.5)  Att_3 <- makeItems(   n = n, means = means_3, sds = sds_3,   lowerbound = rep(lower, 6), upperbound = rep(upper, 6),   cormatrix = cor_3 ) #> Variable  1 #> reached maximum of 1024 iterations #> Variable  2 #> reached maximum of 1024 iterations #> Variable  3 #> reached maximum of 1024 iterations #> Variable  4 #> reached maximum of 1024 iterations #> Variable  5 #> reached maximum of 1024 iterations #> Variable  6 #> reached maximum of 1024 iterations #>  #> Arranging data to match correlations #>  #> Successfully generated correlated variables #>     ### behavioural intention intent <- lfast(n, mean = 3.0, sd = 3, lowerbound = 0, upperbound = 10) |>   data.frame() #> reached maximum of 1024 iterations names(intent) <- \"int\"   ### target scale correlation matrix scale_cors <- matrix(   c(     1.0, 0.6, 0.5, 0.3,     0.6, 1.0, 0.4, 0.2,     0.5, 0.4, 1.0, 0.1,     0.3, 0.2, 0.1, 1.0   ),   nrow = 4 )  data_frames <- list(\"A1\" = Att_1, \"A2\" = Att_2, \"A3\" = Att_3, \"Int\" = intent)   ### apply the function my_correlated_scales <- correlateScales(   dataframes = data_frames,   scalecors = scale_cors ) #> scalecors  is positive-definite #>  #> New dataframe successfully created head(my_correlated_scales) #>   A1_1 A1_2 A1_3 A1_4 A2_1 A2_2 A2_3 A2_4 A2_5 A3_1 A3_2 A3_3 A3_4 A3_5 A3_6 #> 1    3    3    3    4    4    3    4    4    5    2    2    2    5    2    2 #> 2    1    2    2    1    2    1    1    2    2    2    1    2    2    3    1 #> 3    2    4    4    4    4    2    3    3    5    5    3    4    5    4    4 #> 4    4    3    4    5    3    3    3    4    5    3    1    4    4    4    5 #> 5    1    1    1    2    1    2    2    2    1    2    1    2    1    2    1 #> 6    4    5    4    5    4    4    4    4    5    3    4    5    5    4    5 #>   Int_1 #> 1     1 #> 2     5 #> 3     9 #> 4     4 #> 5     1 #> 6     0"},{"path":"https://winzarh.github.io/LikertMakeR/reference/eigenvalues.html","id":null,"dir":"Reference","previous_headings":"","what":"calculate eigenvalues of a correlation matrix with optional scree plot — eigenvalues","title":"calculate eigenvalues of a correlation matrix with optional scree plot — eigenvalues","text":"eigenvalues() calculates eigenvalues correlation matrix optionally produces scree plot.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/eigenvalues.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"calculate eigenvalues of a correlation matrix with optional scree plot — eigenvalues","text":"","code":"eigenvalues(cormatrix, scree = FALSE)"},{"path":"https://winzarh.github.io/LikertMakeR/reference/eigenvalues.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"calculate eigenvalues of a correlation matrix with optional scree plot — eigenvalues","text":"cormatrix (real, matrix) correlation matrix scree (logical) default = FALSE. TRUE (1), eigenvalues() produces scree plot illustrate eigenvalues","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/eigenvalues.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"calculate eigenvalues of a correlation matrix with optional scree plot — eigenvalues","text":"vector eigenvalues report positive-definite status cormatrix","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/eigenvalues.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"calculate eigenvalues of a correlation matrix with optional scree plot — eigenvalues","text":"","code":"## define parameters  correlationMatrix <- matrix(   c(     1.00, 0.25, 0.35, 0.40,     0.25, 1.00, 0.70, 0.75,     0.35, 0.70, 1.00, 0.80,     0.40, 0.75, 0.80, 1.00   ),   nrow = 4, ncol = 4 )  ## apply function  evals <- eigenvalues(cormatrix = correlationMatrix) #> correlationMatrix  is positive-definite #>  evals <- eigenvalues(correlationMatrix, 1)  #> correlationMatrix  is positive-definite #>"},{"path":"https://winzarh.github.io/LikertMakeR/reference/lcor.html","id":null,"dir":"Reference","previous_headings":"","what":"Rearrange elements in each column of a data-frame to fit a predefined correlation matrix — lcor","title":"Rearrange elements in each column of a data-frame to fit a predefined correlation matrix — lcor","text":"lcor() rearranges values column data-frame columns correlated match predefined correlation matrix.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/lcor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rearrange elements in each column of a data-frame to fit a predefined correlation matrix — lcor","text":"","code":"lcor(data, target, passes = 10)"},{"path":"https://winzarh.github.io/LikertMakeR/reference/lcor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rearrange elements in each column of a data-frame to fit a predefined correlation matrix — lcor","text":"data dataframe rearranged target target correlation matrix. Must dimensions number columns data-frame. passes Number optimization passes (default = 10). Increasing value MAY improve results n-columns (target correlation matrix dimensions) many. Decreasing value 'passes' faster may decrease accuracy.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/lcor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rearrange elements in each column of a data-frame to fit a predefined correlation matrix — lcor","text":"Returns dataframe whose column-wise correlations approximate user-specified correlation matrix","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/lcor.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Rearrange elements in each column of a data-frame to fit a predefined correlation matrix — lcor","text":"Values column change, univariate statistics remain .","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/lcor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rearrange elements in each column of a data-frame to fit a predefined correlation matrix — lcor","text":"","code":"## parameters n <- 32 lowerbound <- 1 upperbound <- 5 items <- 5  mydat3 <- data.frame(   x1 = lfast(n, 2.5, 0.75, lowerbound, upperbound, items),   x2 = lfast(n, 3.0, 1.50, lowerbound, upperbound, items),   x3 = lfast(n, 3.5, 1.00, lowerbound, upperbound, items) ) #> best solution in 40 iterations #> reached maximum of 1024 iterations #> reached maximum of 1024 iterations  cor(mydat3) |> round(3) #>       x1     x2     x3 #> x1 1.000  0.014  0.052 #> x2 0.014  1.000 -0.110 #> x3 0.052 -0.110  1.000  tgt3 <- matrix(   c(     1.00, 0.50, 0.75,     0.50, 1.00, 0.25,     0.75, 0.25, 1.00   ),   nrow = 3, ncol = 3 )  ## apply function new3 <- lcor(mydat3, tgt3)  ## test output cor(new3) |> round(3) #>       X1    X2    X3 #> X1 1.000 0.498 0.749 #> X2 0.498 1.000 0.251 #> X3 0.749 0.251 1.000"},{"path":"https://winzarh.github.io/LikertMakeR/reference/lexact.html","id":null,"dir":"Reference","previous_headings":"","what":"Deprecated. Use lfast() instead — lexact","title":"Deprecated. Use lfast() instead — lexact","text":"lexact DEPRECATED. Replaced LikertMakeR Version 0.4.0 new version lfast. lexact remains legacy earlier package users. now just wrapper lfast Previously, lexact used Differential Evolution (DE) algorithm find optimum solution desired mean standard deviation, found updated lfast function much faster just accurate. Also package much less bulky.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/lexact.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deprecated. Use lfast() instead — lexact","text":"","code":"lexact(n, mean, sd, lowerbound, upperbound, items = 1)"},{"path":"https://winzarh.github.io/LikertMakeR/reference/lexact.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Deprecated. Use lfast() instead — lexact","text":"n (positive, int) number observations generate mean (real) target mean sd (real) target standard deviation lowerbound (positive, int) lower bound upperbound (positive, int) upper bound items (positive, int) number items rating scale.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/lexact.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Deprecated. Use lfast() instead — lexact","text":"vector simulated data approximating user-specified conditions.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/lexact.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Deprecated. Use lfast() instead — lexact","text":"","code":"x <- lexact(   n = 256,   mean = 4.0,   sd = 1.0,   lowerbound = 1,   upperbound = 7,   items = 6 ) #> lexact() function is deprecated. #>            #> Using the more efficient lfast() function instead #> best solution in 2331 iterations  x <- lexact(256, 2, 1.8, 0, 10) #> lexact() function is deprecated. #>            #> Using the more efficient lfast() function instead #> best solution in 1687 iterations"},{"path":"https://winzarh.github.io/LikertMakeR/reference/lfast.html","id":null,"dir":"Reference","previous_headings":"","what":"Synthesise rating-scale data with predefined mean and standard deviation — lfast","title":"Synthesise rating-scale data with predefined mean and standard deviation — lfast","text":"lfast() applies simple Evolutionary Algorithm find vector best fits desired moments. lfast() generates random discrete values scaled Beta distribution data replicate ordinal rating scale - example, Likert scale made multiple items (questions) 0-10 likelihood--purchase scale. Data generated generally consistent real data, shown lfast() validation article.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/lfast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Synthesise rating-scale data with predefined mean and standard deviation — lfast","text":"","code":"lfast(n, mean, sd, lowerbound, upperbound, items = 1, precision = 0)"},{"path":"https://winzarh.github.io/LikertMakeR/reference/lfast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Synthesise rating-scale data with predefined mean and standard deviation — lfast","text":"n (positive, int) number observations generate mean (real) target mean, upper lower bounds sd (positive, real) target standard deviation lowerbound (int) lower bound (e.g. '1' 1-5 rating scale) upperbound (int) upper bound (e.g. '5' 1-5 rating scale) items (positive, int) number items rating scale. Default = 1 precision (positive, real) can relax level accuracy required. (e.g. '1' generally generates vector moments correct within '0.025', '2' generally within '0.05') Default = 0","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/lfast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Synthesise rating-scale data with predefined mean and standard deviation — lfast","text":"vector approximating user-specified conditions.","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/reference/lfast.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Synthesise rating-scale data with predefined mean and standard deviation — lfast","text":"","code":"## six-item 1-7 rating scale x <- lfast(   n = 256,   mean = 4.0,   sd = 1.25,   lowerbound = 1,   upperbound = 7,   items = 6 ) #> best solution in 1807 iterations  ## five-item -3 to +3 rating scale x <- lfast(   n = 64,   mean = 0.025,   sd = 1.25,   lowerbound = -3,   upperbound = 3,   items = 5 ) #> best solution in 1599 iterations  ## four-item 1-5 rating scale with medium variation x <- lfast(   n = 128,   mean = 3.0,   sd = 1.00,   lowerbound = 1,   upperbound = 5,   items = 4,   precision = 5 ) #> best solution in 1 iterations  ## eleven-point 'likelihood of purchase' scale x <- lfast(256, 3, 3.0, 0, 10) #> best solution in 1391 iterations"},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeCorrAlpha.html","id":null,"dir":"Reference","previous_headings":"","what":"Correlation matrix from Cronbach's Alpha — makeCorrAlpha","title":"Correlation matrix from Cronbach's Alpha — makeCorrAlpha","text":"makeCorrAlpha() generates random correlation matrix given dimensions predefined Cronbach's Alpha. correlation matrix can applied makeItems() function generate synthetic data predefined alpha.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeCorrAlpha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Correlation matrix from Cronbach's Alpha — makeCorrAlpha","text":"","code":"makeCorrAlpha(items, alpha, variance = 0.5, precision = 0)"},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeCorrAlpha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Correlation matrix from Cronbach's Alpha — makeCorrAlpha","text":"items (positive, int) matrix dimensions: number rows & columns generate alpha (real) target Cronbach's Alpha (usually positive, must -0.3 +1) variance (positive, real) Default = 0.5. User-provided standard deviation values sampled normally-distributed log transformation. precision (positive, real) Default = 0. User-defined value ranging '0' '3' add random variation around target Cronbach's Alpha. '0' gives exact alpha (two decimal places)","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeCorrAlpha.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Correlation matrix from Cronbach's Alpha — makeCorrAlpha","text":"correlation matrix","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeCorrAlpha.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Correlation matrix from Cronbach's Alpha — makeCorrAlpha","text":"Random values generated makeCorrAlpha() highly volatile. makeCorrAlpha() may generate feasible (positive-definite) correlation matrix, especially variance high relative desired Alpha, desired correlation dimensions makeCorrAlpha() inform user resulting correlation matrix positive definite, . returned correlation matrix positive-definite, feasible solution may still possible. user encouraged try , possibly several times, find one.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeCorrAlpha.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Correlation matrix from Cronbach's Alpha — makeCorrAlpha","text":"","code":"# define parameters items <- 4 alpha <- 0.85 variance <- 0.5  # apply function set.seed(42) cor_matrix <- makeCorrAlpha(   items = items,   alpha = alpha,   variance = variance ) #> correlation values consistent with desired alpha in 59 iterations #> The correlation matrix is positive definite #>   # test function output print(cor_matrix) #>           [,1]      [,2]      [,3]      [,4] #> [1,] 1.0000000 0.4251139 0.4331446 0.5069007 #> [2,] 0.4251139 1.0000000 0.6926037 0.6936888 #> [3,] 0.4331446 0.6926037 1.0000000 0.7658611 #> [4,] 0.5069007 0.6936888 0.7658611 1.0000000 alpha(cor_matrix) #> [1] 0.8500063 eigenvalues(cor_matrix, 1)  #> cor_matrix  is positive-definite #>  #> [1] 2.7842025 0.6581071 0.3291732 0.2285172  # higher alpha, more items cor_matrix2 <- makeCorrAlpha(items = 8, alpha = 0.95) #> correlation values consistent with desired alpha in 731 iterations #> The correlation matrix is positive definite #>   # test output cor_matrix2 |> round(2) #>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] #> [1,] 1.00 0.25 0.45 0.51 0.58 0.58 0.62 0.67 #> [2,] 0.25 1.00 0.68 0.69 0.69 0.69 0.70 0.71 #> [3,] 0.45 0.68 1.00 0.72 0.73 0.73 0.73 0.75 #> [4,] 0.51 0.69 0.72 1.00 0.76 0.76 0.78 0.79 #> [5,] 0.58 0.69 0.73 0.76 1.00 0.81 0.83 0.86 #> [6,] 0.58 0.69 0.73 0.76 0.81 1.00 0.87 0.89 #> [7,] 0.62 0.70 0.73 0.78 0.83 0.87 1.00 0.89 #> [8,] 0.67 0.71 0.75 0.79 0.86 0.89 0.89 1.00 alpha(cor_matrix2) |> round(3) #> [1] 0.95 eigenvalues(cor_matrix2, 1) |> round(3)  #> cor_matrix2  is positive-definite #>  #> [1] 5.988 0.788 0.319 0.262 0.224 0.200 0.126 0.092   # large random variation around alpha set.seed(42) cor_matrix3 <- makeCorrAlpha(items = 6, alpha = 0.85, precision = 2) #> correlation values consistent with desired alpha in 2484 iterations #> The correlation matrix is positive definite #>   # test output cor_matrix3 |> round(2) #>      [,1] [,2] [,3] [,4] [,5] [,6] #> [1,] 1.00 0.47 0.48 0.68 0.71 0.71 #> [2,] 0.47 1.00 0.72 0.74 0.74 0.76 #> [3,] 0.48 0.72 1.00 0.77 0.77 0.78 #> [4,] 0.68 0.74 0.77 1.00 0.78 0.85 #> [5,] 0.71 0.74 0.77 0.78 1.00 0.90 #> [6,] 0.71 0.76 0.78 0.85 0.90 1.00 alpha(cor_matrix3) |> round(3) #> [1] 0.94 eigenvalues(cor_matrix3, 1) |> round(3)  #> cor_matrix3  is positive-definite #>  #> [1] 4.648 0.608 0.279 0.221 0.163 0.081"},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeCorrLoadings.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Inter-Item Correlation Matrix from Factor Loadings — makeCorrLoadings","title":"Generate Inter-Item Correlation Matrix from Factor Loadings — makeCorrLoadings","text":"Constructs inter-item correlation matrix based user-supplied matrix standardised factor loadings (optionally) factor correlation matrix. makeCorrLoadings() function surprisingly good job reproducing target correlation matrix item-factor loadings present, shown makeCorrLoadings() validation article.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeCorrLoadings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Inter-Item Correlation Matrix from Factor Loadings — makeCorrLoadings","text":"","code":"makeCorrLoadings(   loadings,   factorCor = NULL,   uniquenesses = NULL,   nearPD = FALSE,   diagnostics = FALSE )"},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeCorrLoadings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Inter-Item Correlation Matrix from Factor Loadings — makeCorrLoadings","text":"loadings Numeric matrix. \\(k \\times f\\) matrix standardized factor loadings \\(items \\times factors\\). Row names column names used diagnostics present. factorCor Optional \\(f \\times f\\) matrix factor correlations (\\(\\Phi\\)). NULL, assumes orthogonal factors. uniquenesses Optional vector length k. NULL, calculated \\(1 - rowSums(loadings^2)\\). nearPD Logical. TRUE, attempts coerce non–positive-definite matrices using Matrix::nearPD(). diagnostics Logical. TRUE, returns diagnostics including McDonald's Omega item-level summaries.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeCorrLoadings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Inter-Item Correlation Matrix from Factor Loadings — makeCorrLoadings","text":"diagnostics = FALSE, returns correlation matrix (class: matrix). diagnostics = TRUE, returns list : - R: correlation matrix - Omega: per-factor Omega adjusted Omega - OmegaTotal: total Omega across factors - Diagnostics: dataframe communalities, uniquenesses, primary factor","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeCorrLoadings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Inter-Item Correlation Matrix from Factor Loadings — makeCorrLoadings","text":"","code":"# -------------------------------------------------------- # Example 1: Basic use without diagnostics # --------------------------------------------------------  factorLoadings <- matrix(   c(     0.05, 0.20, 0.70,     0.10, 0.05, 0.80,     0.05, 0.15, 0.85,     0.20, 0.85, 0.15,     0.05, 0.85, 0.10,     0.10, 0.90, 0.05,     0.90, 0.15, 0.05,     0.80, 0.10, 0.10   ),   nrow = 8, ncol = 3, byrow = TRUE )  rownames(factorLoadings) <- paste0(\"Q\", 1:8) colnames(factorLoadings) <- c(\"Factor1\", \"Factor2\", \"Factor3\")  factorCor <- matrix(   c(     1.0,  0.7, 0.6,     0.7,  1.0, 0.4,     0.6,  0.4, 1.0   ),   nrow = 3, byrow = TRUE )  itemCor <- makeCorrLoadings(factorLoadings, factorCor) round(itemCor, 3) #>       Q1    Q2    Q3    Q4    Q5    Q6    Q7    Q8 #> Q1 1.000 0.638 0.683 0.537 0.477 0.484 0.552 0.521 #> Q2 0.638 1.000 0.735 0.503 0.434 0.436 0.557 0.531 #> Q3 0.683 0.735 1.000 0.569 0.499 0.503 0.601 0.570 #> Q4 0.537 0.503 0.569 1.000 0.799 0.839 0.751 0.676 #> Q5 0.477 0.434 0.499 0.799 1.000 0.805 0.670 0.599 #> Q6 0.484 0.436 0.503 0.839 0.805 1.000 0.709 0.633 #> Q7 0.552 0.557 0.601 0.751 0.670 0.709 1.000 0.790 #> Q8 0.521 0.531 0.570 0.676 0.599 0.633 0.790 1.000  # -------------------------------------------------------- # Example 2: Diagnostics with factor correlations (Adjusted Omega) # --------------------------------------------------------  result_adj <- makeCorrLoadings(   loadings = factorLoadings,   factorCor = factorCor,   diagnostics = TRUE ) #> Diagnostics returned with Adjusted Omega (accounting for factor correlations).  # View outputs round(result_adj$R, 3) # correlation matrix #>       Q1    Q2    Q3    Q4    Q5    Q6    Q7    Q8 #> Q1 1.000 0.638 0.683 0.537 0.477 0.484 0.552 0.521 #> Q2 0.638 1.000 0.735 0.503 0.434 0.436 0.557 0.531 #> Q3 0.683 0.735 1.000 0.569 0.499 0.503 0.601 0.570 #> Q4 0.537 0.503 0.569 1.000 0.799 0.839 0.751 0.676 #> Q5 0.477 0.434 0.499 0.799 1.000 0.805 0.670 0.599 #> Q6 0.484 0.436 0.503 0.839 0.805 1.000 0.709 0.633 #> Q7 0.552 0.557 0.601 0.751 0.670 0.709 1.000 0.790 #> Q8 0.521 0.531 0.570 0.676 0.599 0.633 0.790 1.000 round(result_adj$Omega, 3) # adjusted Omega #> Factor1 Factor2 Factor3  #>   0.691   0.683   0.638  round(result_adj$OmegaTotal, 3) # total Omega #> [1] 0.768 print(result_adj$Diagnostics) # communality and uniqueness per item #>    Item Communality Uniqueness PrimaryFactor #> Q1   Q1      0.5325     0.4675       Factor3 #> Q2   Q2      0.6525     0.3475       Factor3 #> Q3   Q3      0.7475     0.2525       Factor3 #> Q4   Q4      0.7850     0.2150       Factor2 #> Q5   Q5      0.7350     0.2650       Factor2 #> Q6   Q6      0.8225     0.1775       Factor2 #> Q7   Q7      0.8350     0.1650       Factor1 #> Q8   Q8      0.6600     0.3400       Factor1  # -------------------------------------------------------- # Example 3: Diagnostics assuming orthogonal factors (Per-Factor Omega) # --------------------------------------------------------  result_orth <- makeCorrLoadings(   loadings = factorLoadings,   diagnostics = TRUE ) #> Diagnostics returned with Per-Factor Omega (assuming orthogonal factors).  round(result_orth$Omega, 3) # per-factor Omega #> Factor1 Factor2 Factor3  #>   0.405   0.513   0.460  round(result_orth$OmegaTotal, 3) # total Omega #> [1] 0.721 print(result_orth$Diagnostics) #>    Item Communality Uniqueness PrimaryFactor #> Q1   Q1      0.5325     0.4675       Factor3 #> Q2   Q2      0.6525     0.3475       Factor3 #> Q3   Q3      0.7475     0.2525       Factor3 #> Q4   Q4      0.7850     0.2150       Factor2 #> Q5   Q5      0.7350     0.2650       Factor2 #> Q6   Q6      0.8225     0.1775       Factor2 #> Q7   Q7      0.8350     0.1650       Factor1 #> Q8   Q8      0.6600     0.3400       Factor1"},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeItems.html","id":null,"dir":"Reference","previous_headings":"","what":"Synthesise rating-scale item data with given first and second moments and a predefined correlation matrix — makeItems","title":"Synthesise rating-scale item data with given first and second moments and a predefined correlation matrix — makeItems","text":"makeItems() generates dataframe random discrete values data replicate rating scale, correlated close predefined correlation matrix. makeItems() wrapper function : lfast(), generates dataframe best fits desired moments, lcor(), rearranges values column dataframe closely match desired correlation matrix.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeItems.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Synthesise rating-scale item data with given first and second moments and a predefined correlation matrix — makeItems","text":"","code":"makeItems(n, means, sds, lowerbound, upperbound, cormatrix)"},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeItems.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Synthesise rating-scale item data with given first and second moments and a predefined correlation matrix — makeItems","text":"n (positive, int) sample-size - number observations means (real) target means: vector length k mean values scale item sds (positive, real) target standard deviations: vector length k standard deviation values scale item lowerbound (positive, int) vector length k (rows & columns correlation matrix) values lower bound scale item (e.g. '1' 1-5 rating scale) upperbound (positive, int) vector length k (rows & columns correlation matrix) values upper bound scale item (e.g. '5' 1-5 rating scale) cormatrix (real, matrix) target correlation matrix: square symmetric positive-semi-definite matrix values ranging -1 +1, '1' diagonal.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeItems.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Synthesise rating-scale item data with given first and second moments and a predefined correlation matrix — makeItems","text":"dataframe rating-scale values","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeItems.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Synthesise rating-scale item data with given first and second moments and a predefined correlation matrix — makeItems","text":"","code":"## define parameters  n <- 16 dfMeans <- c(2.5, 3.0, 3.0, 3.5) dfSds <- c(1.0, 1.0, 1.5, 0.75) lowerbound <- rep(1, 4) upperbound <- rep(5, 4)  corMat <- matrix(   c(     1.00, 0.30, 0.40, 0.60,     0.30, 1.00, 0.50, 0.70,     0.40, 0.50, 1.00, 0.80,     0.60, 0.70, 0.80, 1.00   ),   nrow = 4, ncol = 4 )  item_names <- c(\"Q1\", \"Q2\", \"Q3\", \"Q4\") rownames(corMat) <- item_names colnames(corMat) <- item_names  ## apply function  df <- makeItems(   n = n, means = dfMeans, sds = dfSds,   lowerbound = lowerbound, upperbound = upperbound, cormatrix = corMat ) #> Variable  1 #> reached maximum of 1024 iterations #> Variable  2 #> reached maximum of 1024 iterations #> Variable  3 #> reached maximum of 1024 iterations #> Variable  4 #> reached maximum of 1024 iterations #>  #> Arranging data to match correlations #>  #> Successfully generated correlated variables #>   ## test function  str(df) #> 'data.frame':\t16 obs. of  4 variables: #>  $ Q1: num  3 3 2 4 2 3 2 1 2 1 ... #>  $ Q2: num  4 2 2 4 3 2 2 4 4 3 ... #>  $ Q3: num  5 5 2 3 2 3 1 3 2 5 ... #>  $ Q4: num  4 4 3 4 3 3 3 3 4 4 ...  # means apply(df, 2, mean) |> round(3) #>  Q1  Q2  Q3  Q4  #> 2.5 3.0 3.0 3.5   # standard deviations apply(df, 2, sd) |> round(3) #>    Q1    Q2    Q3    Q4  #> 1.033 1.033 1.506 0.730   # correlations cor(df) |> round(3) #>       Q1    Q2    Q3    Q4 #> Q1 1.000 0.313 0.386 0.619 #> Q2 0.313 1.000 0.514 0.707 #> Q3 0.386 0.514 1.000 0.788 #> Q4 0.619 0.707 0.788 1.000"},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeItemsScale.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate scale items from a summated scale, with desired Cronbach's Alpha — makeItemsScale","title":"Generate scale items from a summated scale, with desired Cronbach's Alpha — makeItemsScale","text":"makeItemsScale() generates random dataframe scale items based predefined summated scale (created lfast() function), desired Cronbach's Alpha. scale, lowerbound, upperbound, items, alpha, variance","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeItemsScale.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate scale items from a summated scale, with desired Cronbach's Alpha — makeItemsScale","text":"","code":"makeItemsScale(   scale,   lowerbound,   upperbound,   items,   alpha = 0.8,   variance = 0.5 )"},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeItemsScale.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate scale items from a summated scale, with desired Cronbach's Alpha — makeItemsScale","text":"scale (int) vector dataframe summated rating scale. range \\(lowerbound \\times items\\) \\(upperbound \\times items\\) lowerbound (int) lower bound scale item (example: '1' '1' '5' rating) upperbound (int) upper bound scale item (example: '5' '1' '5' rating) items (positive, int) k, number columns generate alpha (posiitve, real) desired Cronbach's Alpha new dataframe items. Default = '0.8'. See @details information alpha parameter variance (positive, real) quantile select items give given summated scores. Must lie '0' '1'. Default = '0.5'. See @details information variance parameter","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeItemsScale.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate scale items from a summated scale, with desired Cronbach's Alpha — makeItemsScale","text":"dataframe 'items' columns 'length(scale)' rows","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeItemsScale.html","id":"alpha","dir":"Reference","previous_headings":"","what":"alpha","title":"Generate scale items from a summated scale, with desired Cronbach's Alpha — makeItemsScale","text":"makeItemsScale() takes value vector Likert scales produces row 'k' values average given scale value, rearranges item values within row, attempting give dataframe Likert-scale items produce predefined Cronbach's Alpha. Default value target alpha '0.8'. extreme values 'variance' parameter may reduce chances achieving desired Alpha. may need experiment little.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeItemsScale.html","id":"variance","dir":"Reference","previous_headings":"","what":"variance","title":"Generate scale items from a summated scale, with desired Cronbach's Alpha — makeItemsScale","text":"may many ways find combination integers sum specific value, combinations different levels variance: low-variance: '3 + 4 = 7' high-variance: '1 + 6 = 7' 'variance' parameter defines guidelines amount variance among item values new dataframe . example, consider summated value '9' apply makeItemsScale() function generate three items. zero variance (variance parameter = '0'), see items value, mean '3'. variance = '1', see items values give maximum variance among items. Similarly, mean value applied six items makeItemsScale() gives following combinations different values 'variance' parameter. mean value '3.5' gives following combinations. default value 'variance' '0.5' gives reasonable range item values. want 'responses' consistent choose lower variance value.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeItemsScale.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate scale items from a summated scale, with desired Cronbach's Alpha — makeItemsScale","text":"","code":"## define parameters k <- 4 lower <- 1 upper <- 5  ## scale properties n <- 64 mean <- 3.0 sd <- 0.85  ## create scale set.seed(42) meanScale <- lfast(   n = n, mean = mean, sd = sd,   lowerbound = lower, upperbound = upper,   items = k ) #> best solution in 2841 iterations summatedScale <- meanScale * k  ## create new items newItems <- makeItemsScale(   scale = summatedScale,   lowerbound = lower, upperbound = upper,   items = k ) #> generate 64 rows #> rearrange 4 values within each of 64 rows #> Complete! #> desired Cronbach's alpha = 0.8 (achieved alpha = 0.8002)  ### test new items # str(newItems) # alpha(data = newItems) |> round(2)   ## very low variance usually gives higher Cronbach's Alpha mydat_20 <- makeItemsScale(   scale = summatedScale,   lowerbound = lower, upperbound = upper,   items = k, alpha = 0.8, variance = 0.20 ) #> generate 64 rows #> rearrange 4 values within each of 64 rows #> Complete! #> desired Cronbach's alpha = 0.8 (achieved alpha = 0.8011)  ### test new data frame # str(mydat_20)  # moments <- data.frame( #   means = apply(mydat_20, MARGIN = 2, FUN = mean) |> round(3), #   sds = apply(mydat_20, MARGIN = 2, FUN = sd) |> round(3) # ) |> t()  # moments  # cor(mydat_20) |> round(2) # alpha(data = mydat_20) |> round(2)   ## default alpha (0.8) and higher variance (0.8) mydat_80 <- makeItemsScale(   scale = summatedScale,   lowerbound = lower, upperbound = upper,   items = k, variance = 0.80 ) #> generate 64 rows #> rearrange 4 values within each of 64 rows #> Complete! #> desired Cronbach's alpha = 0.8 (achieved alpha = 0.8003)  ### test new dataframe # str(mydat_80)  # moments <- data.frame( #   means = apply(mydat_80, MARGIN = 2, FUN = mean) |> round(3), #   sds = apply(mydat_80, MARGIN = 2, FUN = sd) |> round(3) # ) |> t()  # moments  # cor(mydat_80) |> round(2) # alpha(data = mydat_80) |> round(2)"},{"path":"https://winzarh.github.io/LikertMakeR/reference/makePaired.html","id":null,"dir":"Reference","previous_headings":"","what":"Synthesise a dataset from paired-sample t-test summary statistics — makePaired","title":"Synthesise a dataset from paired-sample t-test summary statistics — makePaired","text":"function makePaired() generates dataset paired-sample t-test summary statistics. makePaired() generates correlated values data replicate rating scales taken, example, experimental design. function effectively wrapper function lfast() lcor() addition t-statistic -column correlation inferred. Paired t-tests apply observations associated . example: people treatment; people rating two different objects; ratings husband & wife; etc. paired-samples t-test defined : $$ t = \\frac{\\mathrm{mean}(D)}{\\mathrm{sd}(D) / \\sqrt{n}} $$ : \\(D\\) = differences values \\(\\mathrm{mean}(D)\\) = mean differences \\(\\mathrm{sd}(D)\\) = standard deviation differences, $$ \\mathrm{sd}(D)^2 = \\mathrm{sd}(X_{\\text{}})^2 +                           \\mathrm{sd}(X_{\\text{}})^2 -                           2\\,\\mathrm{cov}(X_{\\text{}},                           X_{\\text{}}) $$ paired-sample t-test thus requires estimate covariance two sets observations. makePaired() rearranges formulae covariance inferred t-statistic.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/makePaired.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Synthesise a dataset from paired-sample t-test summary statistics — makePaired","text":"","code":"makePaired(   n,   means,   sds,   t_value,   lowerbound,   upperbound,   items = 1,   precision = 0 )"},{"path":"https://winzarh.github.io/LikertMakeR/reference/makePaired.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Synthesise a dataset from paired-sample t-test summary statistics — makePaired","text":"n (positive, integer) sample size means (real) 1:2 vector target means two /measures sds (real) 1:2 vector target standard deviations t_value (real) desired paired t-statistic lowerbound (integer) lower bound (e.g. '1' 1-5 rating scale) upperbound (integer) upper bound (e.g. '5' 1-5 rating scale) items (positive, integer) number items rating scale. Default = 1 precision (positive, real) relaxes level accuracy required. Default = 0","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/makePaired.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Synthesise a dataset from paired-sample t-test summary statistics — makePaired","text":"dataframe approximating user-specified conditions.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/makePaired.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Synthesise a dataset from paired-sample t-test summary statistics — makePaired","text":"Larger sample sizes usually result higher t-statistics, correspondingly small p-values. Small sample sizes relatively large standard deviations relatively high t-statistics can result impossible correlation values. Similarly, large sample sizes low t-statistics can result impossible correlations. , correlation outside -1:+1 range. happens, function fail ERROR message. user review input parameters insert realistic values.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/makePaired.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Synthesise a dataset from paired-sample t-test summary statistics — makePaired","text":"","code":"n <- 20 pair_m <- c(2.5, 3.0) pair_s <- c(1.0, 1.5) lower <- 1 upper <- 5 k <- 6 t <- -2.5  pairedDat <- makePaired(   n = n, means = pair_m, sds = pair_s,   t_value = t,   lowerbound = lower, upperbound = upper, items = k ) #> Initial data vectors #> reached maximum of 1024 iterations #> reached maximum of 1024 iterations #> Arranging values to conform with desired t-value #> Complete!  str(pairedDat) #> 'data.frame':\t20 obs. of  2 variables: #>  $ X1: num  3.67 3.83 1.83 1.5 4.33 ... #>  $ X2: num  5 4.5 1.17 1.17 4.83 ... cor(pairedDat) |> round(2) #>      X1   X2 #> X1 1.00 0.82 #> X2 0.82 1.00  t.test(pairedDat$X1, pairedDat$X2, paired = TRUE) #>  #> \tPaired t-test #>  #> data:  pairedDat$X1 and pairedDat$X2 #> t = -2.4863, df = 19, p-value = 0.02238 #> alternative hypothesis: true mean difference is not equal to 0 #> 95 percent confidence interval: #>  -0.90555937 -0.07777397 #> sample estimates: #> mean difference  #>      -0.4916667  #>"},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeRepeated.html","id":null,"dir":"Reference","previous_headings":"","what":"Reproduce Repeated-Measures Data from ANOVA Summary Statistics — makeRepeated","title":"Reproduce Repeated-Measures Data from ANOVA Summary Statistics — makeRepeated","text":"Constructs synthetic dataset inter-timepoint correlation matrix repeated-measures ANOVA result, based reported means, standard deviations, F-statistic. useful summary statistics available published studies.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeRepeated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reproduce Repeated-Measures Data from ANOVA Summary Statistics — makeRepeated","text":"","code":"makeRepeated(   n,   k,   means,   sds,   f_stat,   df_between = k - 1,   df_within = (n - 1) * (k - 1),   structure = c(\"cs\", \"ar1\", \"toeplitz\"),   names = paste0(\"time_\", 1:k),   items = 1,   lowerbound = 1,   upperbound = 5,   return_corr_only = FALSE,   diagnostics = FALSE,   ... )"},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeRepeated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reproduce Repeated-Measures Data from ANOVA Summary Statistics — makeRepeated","text":"n Integer. Sample size used original study. k Integer. Number repeated measures (timepoints). means Numeric vector length k. Mean values reported timepoint. sds Numeric vector length k. Standard deviations reported timepoint. f_stat Numeric. reported repeated-measures ANOVA F-statistic within-subjects factor. df_between Degrees freedom conditions (default: k - 1. df_within Degrees freedom within-subjects (default: (n - 1) * (k - 1)). structure Character. Correlation structure assume: \"cs\", \"ar1\", \"toeplitz\" (default = \"cs\"). names Character vector length k. Variable names timepoint (default: \"time_1\" \"time_k\"). items Integer. Number items used generate scale score (passed lfast). lowerbound, Integer. Lower bounds Likert-type response scales (default: 1). upperbound, Integer. upper bounds Likert-type response scales (default: 5). return_corr_only Logical. TRUE, return estimated correlation matrix. diagnostics Logical. TRUE, include diagnostic summaries feasible F-statistic range effect sizes. ... Reserved future use.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeRepeated.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reproduce Repeated-Measures Data from ANOVA Summary Statistics — makeRepeated","text":"named list components: data data frame simulated repeated-measures responses (unless return_corr_only = TRUE). correlation_matrix estimated inter-timepoint correlation matrix. structure correlation structure assumed. achieved_f F-statistic produced estimated rho value (diagnostics = TRUE). feasible_f_range Minimum maximum achievable F-values chosen structure (shown diagnostics requested). recommended_f Conservative, moderate, strong F-statistic suggestions similar designs. effect_size_raw Unstandardised effect size across timepoints. effect_size_standardised Effect size standardised average variance.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeRepeated.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reproduce Repeated-Measures Data from ANOVA Summary Statistics — makeRepeated","text":"function estimates average correlation repeated measures matching reported F-statistic, one three assumed correlation structures: \"cs\" (Compound Symmetry): Default. Assumes timepoints equally correlated. Common standard RM-ANOVA settings. \"ar1\" (First-Order Autoregressive): Assumes correlations decay exponentially time lag. \"toeplitz\" (Linearly Decreasing): Assumes correlation declines linearly time lag - middle ground \"cs\" \"ar1\". function generates data frame synthetic item-scale ratings using lfast, adjusts match estimated correlation structure using lcor. Set return_corr_only = TRUE extract estimated correlation matrix.","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeRepeated.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reproduce Repeated-Measures Data from ANOVA Summary Statistics — makeRepeated","text":"","code":"set.seed(42)  out1 <- makeRepeated(   n = 64,   k = 3,   means = c(3.1, 3.5, 3.9),   sds = c(1.0, 1.1, 1.0),   items = 4,   f_stat = 4.87,   structure = \"cs\",   diagnostics = FALSE ) #> best solution in 1837 iterations #> best solution in 492 iterations #> best solution in 2136 iterations  head(out1$data) #>   time_1 time_2 time_3 #> 1   3.75   4.25   3.50 #> 2   2.25   4.00   3.75 #> 3   3.75   4.50   3.75 #> 4   1.50   4.25   4.25 #> 5   3.00   3.50   4.25 #> 6   3.25   4.00   4.00 out1$correlation_matrix #>            time_1     time_2     time_3 #> time_1  1.0000000 -0.3100743 -0.3100743 #> time_2 -0.3100743  1.0000000 -0.3100743 #> time_3 -0.3100743 -0.3100743  1.0000000  out2 <- makeRepeated(   n = 32, k = 4,   means = c(2.75, 3.5, 4.0, 4.4),   sds = c(0.8, 1.0, 1.2, 1.0),   f_stat = 16,   structure = \"ar1\",   items = 5,   lowerbound = 1, upperbound = 7,   return_corr_only = FALSE,   diagnostics = TRUE ) #> best solution in 299 iterations #> reached maximum of 1024 iterations #> reached maximum of 1024 iterations #> reached maximum of 1024 iterations  print(out2) #> $data #>    time_1 time_2 time_3 time_4 #> 1     3.4    3.2    1.8    4.6 #> 2     4.8    3.2    2.6    3.6 #> 3     3.0    2.4    4.2    5.2 #> 4     4.2    3.8    6.0    5.4 #> 5     2.2    3.0    1.6    2.8 #> 6     3.8    3.4    4.8    5.2 #> 7     2.0    2.2    3.4    4.4 #> 8     2.0    5.0    3.4    5.6 #> 9     1.6    2.8    4.8    4.8 #> 10    2.2    2.6    2.8    5.8 #> 11    2.8    3.2    3.0    2.2 #> 12    3.4    4.2    3.2    3.8 #> 13    2.4    2.4    3.8    6.4 #> 14    3.2    5.8    5.6    5.4 #> 15    3.2    4.0    4.2    6.0 #> 16    3.6    5.0    5.0    4.6 #> 17    2.2    3.6    4.0    5.0 #> 18    1.8    3.0    4.6    4.0 #> 19    1.8    2.4    4.0    3.2 #> 20    2.0    2.2    3.6    4.0 #> 21    4.0    3.6    4.4    3.2 #> 22    2.2    3.2    6.0    5.4 #> 23    2.2    2.4    5.2    4.0 #> 24    2.4    2.8    4.8    4.6 #> 25    2.4    4.6    4.6    3.4 #> 26    2.2    2.6    2.0    3.2 #> 27    2.0    4.0    3.6    3.8 #> 28    3.4    5.4    5.4    5.0 #> 29    2.6    4.6    4.0    4.2 #> 30    3.2    3.6    3.6    4.4 #> 31    2.4    2.8    2.2    3.4 #> 32    3.4    4.8    5.8    4.0 #>  #> $correlation_matrix #>            time_1    time_2    time_3     time_4 #> time_1 1.00000000 0.3910032 0.1528835 0.05977794 #> time_2 0.39100319 1.0000000 0.3910032 0.15288350 #> time_3 0.15288350 0.3910032 1.0000000 0.39100319 #> time_4 0.05977794 0.1528835 0.3910032 1.00000000 #>  #> $structure #> [1] \"ar1\" #>  #> $feasible_f_range #>       min       max  #>  9.353034 39.481390  #>  #> $recommended_f #> $recommended_f$conservative #> [1] 10.21 #>  #> $recommended_f$moderate #> [1] 11.91 #>  #> $recommended_f$strong #> [1] 30.29 #>  #>  #> $achieved_f #> [1] 15.99983 #>  #> $effect_size_raw #> [1] 0.3792188 #>  #> $effect_size_standardised #> [1] 0.3717831 #>    out3 <- makeRepeated(   n = 64, k = 4,   means = c(2.0, 2.25, 2.75, 3.0),   sds = c(0.8, 0.9, 1.0, 0.9),   items = 4,   f_stat = 24,   # structure = \"toeplitz\",   diagnostics = TRUE ) #> best solution in 3541 iterations #> best solution in 2048 iterations #> reached maximum of 4096 iterations #> best solution in 676 iterations  str(out3) #> List of 8 #>  $ data                    :'data.frame':\t64 obs. of  4 variables: #>   ..$ time_1: num [1:64] 3.25 1.25 2.25 4.25 3.5 2 1.25 3 2.25 2.5 ... #>   ..$ time_2: num [1:64] 3.5 1 2 3.5 1.5 2 1.25 1.75 3 2.75 ... #>   ..$ time_3: num [1:64] 3 1.5 4 3.25 3.5 3 2.25 2.75 4.5 3.5 ... #>   ..$ time_4: num [1:64] 4 1.25 3.5 2.75 3.75 3 2.75 3.25 3.75 3 ... #>  $ correlation_matrix      : num [1:4, 1:4] 1 0.489 0.489 0.489 0.489 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:4] \"time_1\" \"time_2\" \"time_3\" \"time_4\" #>   .. ..$ : chr [1:4] \"time_1\" \"time_2\" \"time_3\" \"time_4\" #>  $ structure               : chr \"cs\" #>  $ feasible_f_range        : Named num [1:2] 9.27 61.35 #>   ..- attr(*, \"names\")= chr [1:2] \"min\" \"max\" #>  $ recommended_f           :List of 3 #>   ..$ conservative: num 11.6 #>   ..$ moderate    : num 16.1 #>   ..$ strong      : num 46.3 #>  $ achieved_f              : num 24 #>  $ effect_size_raw         : num 0.156 #>  $ effect_size_standardised: num 0.192"},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeScales.html","id":null,"dir":"Reference","previous_headings":"","what":"Synthesise rating-scale data with given first and second moments and a predefined correlation matrix — makeScales","title":"Synthesise rating-scale data with given first and second moments and a predefined correlation matrix — makeScales","text":"makeScales() generates dataframe random discrete values data replicate rating scale, correlated close predefined correlation matrix. makeScales() wrapper function : lfast(), generates dataframe best fits desired moments, lcor(), rearranges values column dataframe closely match desired correlation matrix.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeScales.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Synthesise rating-scale data with given first and second moments and a predefined correlation matrix — makeScales","text":"","code":"makeScales(n, means, sds, lowerbound = 1, upperbound = 5, items = 1, cormatrix)"},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeScales.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Synthesise rating-scale data with given first and second moments and a predefined correlation matrix — makeScales","text":"n (positive, int) sample-size - number observations means (real) target means: vector length k mean values scale item sds (positive, real) target standard deviations: vector length k standard deviation values scale item lowerbound (positive, int) vector length k (rows & columns correlation matrix) values lower bound scale item (e.g. '1' 1-5 rating scale). Default = 1. upperbound (positive, int) vector length k (rows & columns correlation matrix) values upper bound scale item (e.g. '5' 1-5 rating scale). Default = 5. items (positive, int) vector length k number items scale. Default = 1. cormatrix (real, matrix) target correlation matrix: square symmetric positive-semi-definite matrix values ranging -1 +1, '1' diagonal.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeScales.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Synthesise rating-scale data with given first and second moments and a predefined correlation matrix — makeScales","text":"dataframe rating-scale values","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeScales.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Synthesise rating-scale data with given first and second moments and a predefined correlation matrix — makeScales","text":"","code":"## Example 1: four correlated items (questions)  ### define parameters  n <- 16 dfMeans <- c(2.5, 3.0, 3.0, 3.5) dfSds <- c(1.0, 1.0, 1.5, 0.75) lowerbound <- rep(1, 4) upperbound <- rep(5, 4)  corMat <- matrix(   c(     1.00, 0.30, 0.40, 0.60,     0.30, 1.00, 0.50, 0.70,     0.40, 0.50, 1.00, 0.80,     0.60, 0.70, 0.80, 1.00   ),   nrow = 4, ncol = 4 )  scale_names <- c(\"Q1\", \"Q2\", \"Q3\", \"Q4\") rownames(corMat) <- scale_names colnames(corMat) <- scale_names  ### apply function  df1 <- makeScales(   n = n, means = dfMeans, sds = dfSds,   lowerbound = lowerbound, upperbound = upperbound, cormatrix = corMat ) #> Variable  1 #> reached maximum of 1024 iterations #> Variable  2 #> reached maximum of 1024 iterations #> Variable  3 #> reached maximum of 1024 iterations #> Variable  4 #> reached maximum of 1024 iterations #>  #> Arranging data to match correlations #>  #> Successfully generated correlated variables #>   ### test function  str(df1) #> 'data.frame':\t16 obs. of  4 variables: #>  $ Q1: num  3 4 3 2 1 3 2 1 2 2 ... #>  $ Q2: num  4 4 3 4 2 3 2 1 4 2 ... #>  $ Q3: num  3 5 5 1 1 4 1 2 4 2 ... #>  $ Q4: num  4 4 4 3 2 4 3 3 4 3 ...  #### means apply(df1, 2, mean) |> round(3) #>  Q1  Q2  Q3  Q4  #> 2.5 3.0 3.0 3.5   #### standard deviations apply(df1, 2, sd) |> round(3) #>    Q1    Q2    Q3    Q4  #> 1.033 1.033 1.506 0.730   #### correlations cor(df1) |> round(3) #>       Q1    Q2    Q3    Q4 #> Q1 1.000 0.313 0.386 0.530 #> Q2 0.313 1.000 0.514 0.707 #> Q3 0.386 0.514 1.000 0.788 #> Q4 0.530 0.707 0.788 1.000    ## Example 2: five correlated Likert scales  ### a study on employee engagement and organizational climate:  # Job Satisfaction (JS)  # Organizational Commitment (OC)  # Perceived Supervisor Support (PSS)  # Work Engagement (WE)  # Turnover Intention (TI) (reverse-related to others).  ### define parameters  n <- 128 dfMeans <- c(3.8, 3.6, 3.7, 3.9, 2.2) dfSds <-   c(0.7, 0.8, 0.7, 0.6, 0.9) lowerbound <- rep(1, 5) upperbound <- rep(5, 5) items <- c(4, 4, 3, 3, 3)  corMat <- matrix(   c(     1.00, 0.72, 0.58, 0.65, -0.55,     0.72, 1.00, 0.54, 0.60, -0.60,     0.58, 0.54, 1.00, 0.57, -0.45,     0.65, 0.60, 0.57, 1.00, -0.50,     -0.55, -0.60, -0.45, -0.50, 1.00    ),  nrow = 5, ncol = 5 )  scale_names <- c(\"JS\", \"OC\", \"PSS\", \"WE\", \"TI\") rownames(corMat) <- scale_names colnames(corMat) <- scale_names  ### apply function  df2 <- makeScales(   n = n, means = dfMeans, sds = dfSds,   lowerbound = lowerbound, upperbound = upperbound,   items = items, cormatrix = corMat ) #> Variable  1 #> best solution in 88 iterations #> Variable  2 #> best solution in 1334 iterations #> Variable  3 #> best solution in 1443 iterations #> Variable  4 #> best solution in 623 iterations #> Variable  5 #> best solution in 703 iterations #>  #> Arranging data to match correlations #>  #> Successfully generated correlated variables #>   ### test function  str(df2) #> 'data.frame':\t128 obs. of  5 variables: #>  $ JS : num  4.25 3.5 2.75 3.25 2.5 2.5 4 2.25 4.5 3.5 ... #>  $ OC : num  4.25 3.5 2 3 2.75 3.5 3.5 1.25 4.5 4 ... #>  $ PSS: num  4.33 4 3.33 3 2.33 ... #>  $ WE : num  4.67 3.67 3.33 4 2.33 ... #>  $ TI : num  1.33 2 4 1.67 2 ...  #### means apply(df2, 2, mean) |> round(3) #>    JS    OC   PSS    WE    TI  #> 3.799 3.602 3.701 3.901 2.201   #### standard deviations apply(df2, 2, sd) |> round(3) #>    JS    OC   PSS    WE    TI  #> 0.699 0.800 0.701 0.599 0.898   #### correlations cor(df2) |> round(3) #>         JS     OC   PSS     WE     TI #> JS   1.000  0.720  0.58  0.650 -0.549 #> OC   0.720  1.000  0.54  0.600 -0.601 #> PSS  0.580  0.540  1.00  0.570 -0.450 #> WE   0.650  0.600  0.57  1.000 -0.499 #> TI  -0.549 -0.601 -0.45 -0.499  1.000"},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeScalesRegression.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Data from Multiple-Regression Summary Statistics — makeScalesRegression","title":"Generate Data from Multiple-Regression Summary Statistics — makeScalesRegression","text":"Generates synthetic rating-scale data replicates reported regression results. function useful reproducing analyses published research summary statistics (standardised regression coefficients R-squared) reported.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeScalesRegression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Data from Multiple-Regression Summary Statistics — makeScalesRegression","text":"","code":"makeScalesRegression(   n,   beta_std,   r_squared,   iv_cormatrix = NULL,   iv_cor_mean = 0.3,   iv_cor_variance = 0.01,   iv_cor_range = c(-0.7, 0.7),   iv_means,   iv_sds,   dv_mean,   dv_sd,   lowerbound_iv,   upperbound_iv,   lowerbound_dv,   upperbound_dv,   items_iv = 1,   items_dv = 1,   var_names = NULL,   tolerance = 0.005 )"},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeScalesRegression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Data from Multiple-Regression Summary Statistics — makeScalesRegression","text":"n Integer. Sample size beta_std Numeric vector standardised regression coefficients (length k) r_squared Numeric. R-squared regression (-1 1) iv_cormatrix k x k correlation matrix independent variables. missing (NULL), optimised. iv_cor_mean Numeric. Mean correlation among IVs optimising (ignored iv_cormatrix provided). Default = 0.3 iv_cor_variance Numeric. Variance correlations optimising (ignored iv_cormatrix provided). Default = 0.01 iv_cor_range Numeric vector length 2. Min max constraints correlations optimising. Default = c(-0.7, 0.7) iv_means Numeric vector means IVs (length k) iv_sds Numeric vector standard deviations IVs (length k) dv_mean Numeric. Mean dependent variable dv_sd Numeric. Standard deviation dependent variable lowerbound_iv Numeric vector lower bounds IV scale (single value ) upperbound_iv Numeric vector upper bounds IV scale (single value ) lowerbound_dv Numeric. Lower bound DV scale upperbound_dv Numeric. Upper bound DV scale items_iv Integer vector number items per IV scale (single value ). Default = 1 items_dv Integer. Number items DV scale. Default = 1 var_names Character vector variable names (length k+1: IVs DV) tolerance Numeric. Acceptable deviation target R-squared (default 0.005)","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeScalesRegression.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Data from Multiple-Regression Summary Statistics — makeScalesRegression","text":"list containing: data Generated dataframe k IVs 1 DV target_stats List target statistics provided achieved_stats List achieved statistics generated data diagnostics Comparison target vs achieved iv_dv_cors Calculated correlations IVs DV full_cormatrix complete (k+1) x (k+1) correlation matrix used optimisation_info IV correlations optimised, details optimisation","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeScalesRegression.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate Data from Multiple-Regression Summary Statistics — makeScalesRegression","text":"Generate regression data summary statistics function can operate two modes: Mode 1: IV correlation matrix provided iv_cormatrix provided, function uses given correlation structure among independent variables calculates implied IV-DV correlations regression coefficients. Mode 2: optimisation (IV correlation matrix provided) iv_cormatrix = NULL, function optimises find plausible correlation structure among independent variables matches reported regression statistics. Initial correlations sampled using Fisher's z-transformation ensure proper distribution, iteratively adjusted match target R-squared. function generates Likert-scale data (individual items) using lfast() variable specified moments, correlates using lcor(). Generated data verified running regression comparing achieved statistics targets.","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/reference/makeScalesRegression.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Data from Multiple-Regression Summary Statistics — makeScalesRegression","text":"","code":"# Example 1: With provided IV correlation matrix set.seed(123) iv_corr <- matrix(c(1.0, 0.3, 0.3, 1.0), nrow = 2)  result1 <- makeScalesRegression(   n = 64,   beta_std = c(0.4, 0.3),   r_squared = 0.35,   iv_cormatrix = iv_corr,   iv_means = c(3.0, 3.5),   iv_sds = c(1.0, 0.9),   dv_mean = 3.8,   dv_sd = 1.1,   lowerbound_iv = 1,   upperbound_iv = 5,   lowerbound_dv = 1,   upperbound_dv = 5,   items_iv = 4,   items_dv = 4,   var_names = c(\"Attitude\", \"Intention\", \"Behaviour\") ) #> Warning: Predicted R-squared (0.3220) differs from target (0.3500) by 0.0280, #>         which exceeds tolerance (0.0050). #>          #> Input statistics may be inconsistent. #> best solution in 397 iterations #> best solution in 1507 iterations #> best solution in 162 iterations  print(result1) #> $data #>    Attitude Intention Behaviour #> 1      3.00      1.75      1.50 #> 2      4.50      5.00      4.00 #> 3      3.00      2.75      5.00 #> 4      3.25      3.75      4.50 #> 5      1.25      3.25      4.50 #> 6      3.00      2.75      4.75 #> 7      1.25      3.00      3.50 #> 8      1.75      4.00      3.25 #> 9      3.25      3.00      2.25 #> 10     1.75      3.00      3.25 #> 11     2.50      2.25      2.50 #> 12     2.75      4.50      4.75 #> 13     1.00      4.50      1.75 #> 14     2.25      3.25      3.25 #> 15     2.75      3.50      3.25 #> 16     3.25      3.50      5.00 #> 17     3.25      2.75      4.25 #> 18     2.50      2.50      2.00 #> 19     2.25      4.75      4.50 #> 20     4.50      4.00      5.00 #> 21     2.50      4.75      3.75 #> 22     4.25      3.25      5.00 #> 23     2.75      2.50      2.25 #> 24     2.50      3.25      2.50 #> 25     2.75      1.75      3.50 #> 26     3.00      4.00      4.75 #> 27     4.25      3.75      5.00 #> 28     2.75      2.50      2.50 #> 29     1.50      2.25      1.75 #> 30     3.00      3.00      3.00 #> 31     4.50      4.75      5.00 #> 32     3.50      2.00      4.50 #> 33     4.25      3.50      2.75 #> 34     4.75      4.00      4.75 #> 35     2.25      2.75      3.75 #> 36     1.50      3.50      1.75 #> 37     3.75      5.00      5.00 #> 38     1.50      4.50      3.50 #> 39     3.75      4.75      5.00 #> 40     2.25      2.25      4.25 #> 41     4.50      3.50      4.50 #> 42     3.25      3.25      4.75 #> 43     4.00      4.75      5.00 #> 44     2.25      3.75      1.50 #> 45     3.00      4.75      4.50 #> 46     4.00      4.00      4.50 #> 47     2.75      3.00      3.00 #> 48     4.50      4.75      4.75 #> 49     1.50      3.00      5.00 #> 50     3.25      3.75      4.75 #> 51     2.00      1.75      2.25 #> 52     2.50      4.00      4.00 #> 53     4.00      4.50      3.00 #> 54     2.75      3.25      4.00 #> 55     4.00      5.00      3.75 #> 56     4.50      3.25      4.00 #> 57     2.50      3.00      3.25 #> 58     4.50      4.00      5.00 #> 59     1.50      3.75      4.50 #> 60     4.50      2.50      4.50 #> 61     3.25      3.00      4.25 #> 62     3.50      4.25      4.50 #> 63     2.00      2.75      2.00 #> 64     3.25      4.75      5.00 #>  #> $target_stats #> $target_stats$beta_std #> [1] 0.4 0.3 #>  #> $target_stats$r_squared #> [1] 0.35 #>  #> $target_stats$iv_dv_cors #>  Attitude Intention  #>      0.49      0.42  #>  #> $target_stats$iv_means #> [1] 3.0 3.5 #>  #> $target_stats$iv_sds #> [1] 1.0 0.9 #>  #> $target_stats$dv_mean #> [1] 3.8 #>  #> $target_stats$dv_sd #> [1] 1.1 #>  #> $target_stats$iv_cormatrix #>      [,1] [,2] #> [1,]  1.0  0.3 #> [2,]  0.3  1.0 #>  #>  #> $achieved_stats #> $achieved_stats$beta_std #>  Attitude Intention  #> 0.4002625 0.2999110  #>  #> $achieved_stats$r_squared #> [1] 0.3219144 #>  #> $achieved_stats$iv_dv_cors #>  Attitude Intention  #> 0.4899008 0.4195427  #>  #> $achieved_stats$iv_means #>  Attitude Intention  #>       3.0       3.5  #>  #> $achieved_stats$iv_sds #>  Attitude Intention  #> 1.0009916 0.9019379  #>  #> $achieved_stats$dv_mean #> [1] 3.800781 #>  #> $achieved_stats$dv_sd #> [1] 1.098502 #>  #> $achieved_stats$full_cormatrix #>            Attitude Intention Behaviour #> Attitude  1.0000000 0.2988831 0.4899008 #> Intention 0.2988831 1.0000000 0.4195427 #> Behaviour 0.4899008 0.4195427 1.0000000 #>  #>  #> $diagnostics #>         Statistic Target  Achieved    Difference   Pct_Error #> 1   Beta_Attitude   0.40 0.4002625  2.625344e-04  0.06563359 #> 2  Beta_Intention   0.30 0.2999110 -8.901289e-05 -0.02967096 #> 3       R_squared   0.35 0.3219144 -2.808559e-02 -8.02445369 #> 4   r_Attitude_DV   0.49 0.4899008 -9.915414e-05 -0.02023554 #> 5  r_Intention_DV   0.42 0.4195427 -4.573246e-04 -0.10888680 #> 6   Mean_Attitude   3.00 3.0000000  0.000000e+00  0.00000000 #> 7  Mean_Intention   3.50 3.5000000  0.000000e+00  0.00000000 #> 8  Mean_Behaviour   3.80 3.8007812  7.812500e-04  0.02055921 #> 9     SD_Attitude   1.00 1.0009916  9.915719e-04  0.09915719 #> 10   SD_Intention   0.90 0.9019379  1.937949e-03  0.21532764 #> 11   SD_Behaviour   1.10 1.0985016 -1.498416e-03 -0.13621967 #>  #> $iv_dv_cors #>  Attitude Intention  #>      0.49      0.42  #>  #> $full_cormatrix #>           Attitude Intention Behaviour #> Attitude      1.00      0.30      0.49 #> Intention     0.30      1.00      0.42 #> Behaviour     0.49      0.42      1.00 #>  #> $optimisation_info #> NULL #>  #> $call #> makeScalesRegression(n = 64, beta_std = c(0.4, 0.3), r_squared = 0.35,  #>     iv_cormatrix = iv_corr, iv_means = c(3, 3.5), iv_sds = c(1,  #>         0.9), dv_mean = 3.8, dv_sd = 1.1, lowerbound_iv = 1,  #>     upperbound_iv = 5, lowerbound_dv = 1, upperbound_dv = 5,  #>     items_iv = 4, items_dv = 4, var_names = c(\"Attitude\", \"Intention\",  #>         \"Behaviour\")) #>  #> attr(,\"class\") #> [1] \"makeScalesRegression\" \"list\"                 head(result1$data) #>   Attitude Intention Behaviour #> 1     3.00      1.75      1.50 #> 2     4.50      5.00      4.00 #> 3     3.00      2.75      5.00 #> 4     3.25      3.75      4.50 #> 5     1.25      3.25      4.50 #> 6     3.00      2.75      4.75   # Example 2: With optimisation (no IV correlation matrix) set.seed(456) result2 <- makeScalesRegression(   n = 128,   beta_std = c(0.3, 0.25, 0.2),   r_squared = 0.40,   iv_cormatrix = NULL, # Will be optimised   iv_cor_mean = 0.3,   iv_cor_variance = 0.02,   iv_means = c(3.0, 3.2, 2.8),   iv_sds = c(1.0, 0.9, 1.1),   dv_mean = 3.5,   dv_sd = 1.0,   lowerbound_iv = 1,   upperbound_iv = 5,   lowerbound_dv = 1,   upperbound_dv = 5,   items_iv = 4,   items_dv = 5 ) #> IV correlation matrix not provided. #>              #> Optimising to find plausible structure... #> Optimisation converged after 7 iterations #>        #> (R-sq target: 0.4000, achieved in optimisation: 0.4020) #> best solution in 5083 iterations #> best solution in 669 iterations #> best solution in 1675 iterations #> best solution in 423 iterations  # View optimised correlation matrix print(result2$target_stats$iv_cormatrix) #>           [,1]      [,2]      [,3] #> [1,] 1.0000000 0.4117389 0.6615179 #> [2,] 0.4117389 1.0000000 0.6832584 #> [3,] 0.6615179 0.6832584 1.0000000 print(result2$optimisation_info) #> $converged #> [1] TRUE #>  #> $iterations #> [1] 7 #>  #> $achieved_r_squared_in_optimisation #> [1] 0.4019688 #>  #> $iv_cor_mean_used #> [1] 0.3 #>  #> $iv_cor_variance_used #> [1] 0.02 #>  #> $iv_cor_range_used #> [1] -0.7  0.7 #>"},{"path":"https://winzarh.github.io/LikertMakeR/reference/print.makeScalesRegression.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for makeScalesRegression objects — print.makeScalesRegression","title":"Print method for makeScalesRegression objects — print.makeScalesRegression","text":"Print method makeScalesRegression objects","code":""},{"path":"https://winzarh.github.io/LikertMakeR/reference/print.makeScalesRegression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for makeScalesRegression objects — print.makeScalesRegression","text":"","code":"# S3 method for class 'makeScalesRegression' print(x, ...)"},{"path":"https://winzarh.github.io/LikertMakeR/reference/print.makeScalesRegression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for makeScalesRegression objects — print.makeScalesRegression","text":"x object class \"makeScalesRegression\" ... Additional arguments (currently unused)","code":""},{"path":[]},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/news/index.html","id":"improvements-1-3-0","dir":"Changelog","previous_headings":"","what":"Improvements","title":"LikertMakeR 1.3.0 (2025-10-18)","text":"New makeScalesRegression() function : Generates synthetic rating-scale data replicates reported regression results, returns data frame provides requested statistical properties correlation matrix summary moments data frame, plus diagnostic statistics, including comparison target values achieved values.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/news/index.html","id":"maintenance-1-3-0","dir":"Changelog","previous_headings":"","what":"Maintenance","title":"LikertMakeR 1.3.0 (2025-10-18)","text":"new vignette new function makeScalesRegression().","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/news/index.html","id":"improvements-1-2-0","dir":"Changelog","previous_headings":"","what":"Improvements","title":"LikertMakeR 1.2.0 (2025-10-10)","text":"New makeRepeated() function : takes summary statistics reported typical repeated-measures ANOVA study, returns correlation matrix vectors repeated measures data frame based correlation matrix summary moments, plus diagnostic statistics, including possible F-statistics based information provided. #lfast_validation# vignette shows #LikertMaker# remarkably good job replicating real rating-scale data.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/news/index.html","id":"maintenance-1-2-0","dir":"Changelog","previous_headings":"","what":"Maintenance","title":"LikertMakeR 1.2.0 (2025-10-10)","text":"Vignettes large many images, CRAN files include #LikertMakeR_vignette# file. Two vignettes validate lfast() makeCorrLoadings() appear package website.","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/news/index.html","id":"improvements-1-1-0","dir":"Changelog","previous_headings":"","what":"Improvements","title":"LikertMakeR 1.1.0 (2025-05-26)","text":"new makePaired() function: takes summary statistics paired-sample t-test produces data frame rating-scale data deliver summary statistics lcor() function rewrite: previous version used systematic swapping values column minimise difference data correlation target correlation matrix. algorithm effect causing extreme values column highly-correlated (lowly correlated applicable), leaving middle-values relatively uncorrelated. property probably noticeable cases apparent range scale values great.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/news/index.html","id":"maintenance-1-1-0","dir":"Changelog","previous_headings":"","what":"Maintenance","title":"LikertMakeR 1.1.0 (2025-05-26)","text":"Vignettes minor updates.","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/news/index.html","id":"improvements-1-0-2","dir":"Changelog","previous_headings":"","what":"Improvements","title":"LikertMakeR 1.0.2 (2025-04-25)","text":"test examples updated.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/news/index.html","id":"maintenance-1-0-2","dir":"Changelog","previous_headings":"","what":"Maintenance","title":"LikertMakeR 1.0.2 (2025-04-25)","text":"Vignettes updated.","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/news/index.html","id":"improvements-1-0-1","dir":"Changelog","previous_headings":"","what":"Improvements","title":"LikertMakeR 1.0.1 (2025-04-07)","text":"Vignettes now properly registered included build. LikertMakeR vignette makeCorrLoadings validation Updated DESCRIPTION metadata comply CRAN requirements.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/news/index.html","id":"maintenance-1-0-1","dir":"Changelog","previous_headings":"","what":"Maintenance","title":"LikertMakeR 1.0.1 (2025-04-07)","text":"Switched vignette engine knitr::rmarkdown better compatibility CRAN development tools.","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/news/index.html","id":"makecorrloadings-function-added-1-0-0","dir":"Changelog","previous_headings":"","what":"makeCorrLoadings() function added","title":"LikertMakeR 1.0.0 (2025-04-03)","text":"makeCorrLoadings() generates correlation matrix inter-item correlations based item factor loadings might seen Exploratory Factor Analysis (EFA) Structural Equation Model (SEM). correlation matrix can applied  function generate synthetic data predefined factor structures.","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/news/index.html","id":"update-version-number-to-correct-majorminorpatch-format-1-0-0","dir":"Changelog","previous_headings":"","what":"update version number to correct major.minor.patch format","title":"LikertMakeR 1.0.0 (2025-01-08)","text":"update V 0.4.5. new numbered submission CRAN","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/news/index.html","id":"makepaired-function-added-0-4-5","dir":"Changelog","previous_headings":"","what":"makePaired() function added","title":"LikertMakeR 0.4.5 (2025-01-07)","text":"makePaired() generates dataframe two paired vectors emulate data paired-sample t-test","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/news/index.html","id":"target-cronbachs-alpha-added-to-makeitemsscale-function-0-4-0","dir":"Changelog","previous_headings":"","what":"target Cronbach’s Alpha added to makeItemsScale() function","title":"LikertMakeR 0.4.0 (2024-11-17)","text":"generated scale items now defined target Cronbach’s Alpha, well variance within scale item. latest version adds little randomness selection candidate row vectors.","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/news/index.html","id":"more-randomness-in-swaps-task-to-makecorralpha-function-0-3-0","dir":"Changelog","previous_headings":"","what":"more randomness in swaps task to makeCorrAlpha() function","title":"LikertMakeR 0.3.0 (2024-05-18)","text":"correlation matrix usually values sorted lowest highest. happens less often","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/news/index.html","id":"added-precision-parameter-to-makecorralpha-function-0-2-6","dir":"Changelog","previous_headings":"","what":"added ‘precision’ parameter to makeCorrAlpha() function","title":"LikertMakeR 0.2.6 (2024-05-11)","text":"‘precision’ adds random variation around target Cronbach’s Alpha. Default = ‘0’ (variation giving Alpha exact two decimal places)","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/news/index.html","id":"added-correlatescales-function-0-2-5","dir":"Changelog","previous_headings":"","what":"added correlateScales() function","title":"LikertMakeR 0.2.5 (2024-04-20)","text":"Create dataframe correlated scales different dataframes scale items","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/news/index.html","id":"added-makeitemsscale-function-0-2-2","dir":"Changelog","previous_headings":"","what":"added makeItemsScale() function","title":"LikertMakeR 0.2.2 (2024-03-31)","text":"Generate rating-scale items given summated scale","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/news/index.html","id":"for-submission-to-cran-0-2-0","dir":"Changelog","previous_headings":"","what":"For submission to CRAN","title":"LikertMakeR 0.2.0 (2024-03-02)","text":"Faster accurate functions: lcor() & lfast() replace old lcor() & lfast() previous lcor_C() & lfast_R()","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/news/index.html","id":"added-a-new-functions-makecorralpha-makeitems-alpha-eigenvalues-0-1-9","dir":"Changelog","previous_headings":"","what":"Added a new functions: makeCorrAlpha(), makeItems(), alpha(), eigenvalues()","title":"LikertMakeR 0.1.9 (2024-02-11)","text":"makeCorrAlpha() constructs random correlation matrix given dimensions predefined Cronbach’s Alpha. makeItems() generates synthetic rating-scale data predefined first second moments predefined correlation matrix alpha() calculate Cronbach’s Alpha given correlation matrix given dataframe eigenvalues() calculates eigenvalues correlation matrix optional scree plot","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/news/index.html","id":"added-a-new-function-lcor_c-0-1-7","dir":"Changelog","previous_headings":"","what":"Added a new function: lcor_C()","title":"LikertMakeR 0.1.7 (2024-02-02)","text":"lcor_C() C++ implementation lcor() function. run considerably faster lcor(). ’m confident lcor_C() works well better lcor(), shall replace lcor() C++ implementation update CRAN.","code":""},{"path":"https://winzarh.github.io/LikertMakeR/news/index.html","id":"likertmaker-016-2024-01-18","dir":"Changelog","previous_headings":"","what":"LikertMakeR 0.1.6 (2024-01-18)","title":"LikertMakeR 0.1.6 (2024-01-18)","text":"Made code examples tidy - makes code nanoseconds faster Added -line comments. setting C++ mods make lcor() faster, introduce make_items() function.","code":""},{"path":[]},{"path":"https://winzarh.github.io/LikertMakeR/news/index.html","id":"initial-cran-release-0-1-5","dir":"Changelog","previous_headings":"","what":"Initial CRAN release","title":"LikertMakeR 0.1.5 (2022-12-20)","text":"Added references DESCRIPTION file expanded citations vignettes Reduced runtime setting target zero instead -Inf. Specified one thread instead attempting Parallel","code":""}]
